{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1H6Wd9fLljBF6Q2gEkAyb7i7BdLAqcvNs",
      "authorship_tag": "ABX9TyP8NkStGWYFMk+4Zfa3yRiI"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# LOKALER NEWSLETTER GENERATOR - PROOF OF CONCEPT\n",
        "\n",
        "Automatische Erstellung von lokalen Newslettern/Artikeln pro Ort\n",
        "Tech Stack: Claude, Perplexity, Firecrawl, Google Gemini 2.5 Flash\n"
      ],
      "metadata": {
        "id": "e26pG0lvYU4_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "id": "M8GX-Ir1YPH9",
        "outputId": "3aa88db6-b2f9-486d-adf9-51e11483d761"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üì¶ Installiere firecrawl-py...\n",
            "üì¶ Installiere google-generativeai...\n",
            "üì¶ Installiere anthropic...\n",
            "üì¶ Installiere requests...\n",
            "üì¶ Installiere pandas...\n",
            "üì¶ Installiere asyncio...\n",
            "üì¶ Installiere nest-asyncio...\n",
            "üì¶ Installiere ipywidgets...\n",
            "üì¶ Installiere python-dotenv...\n",
            "‚úÖ Alle Requirements installiert!\n",
            "üöÄ Setup komplett - alle Libraries geladen!\n"
          ]
        }
      ],
      "source": [
        "# =============================================================================\n",
        "# ZELLE 0: Requirements\n",
        "# =============================================================================\n",
        "# @title Requirements Installation\n",
        "import subprocess\n",
        "import sys\n",
        "\n",
        "def install_requirements():\n",
        "    \"\"\"Installiert alle ben√∂tigten Packages\"\"\"\n",
        "    requirements = [\n",
        "        \"firecrawl-py\",\n",
        "        \"google-generativeai\",\n",
        "        \"anthropic\",\n",
        "        \"requests\",\n",
        "        \"pandas\",\n",
        "        \"asyncio\",\n",
        "        \"nest-asyncio\",\n",
        "        \"ipywidgets\",\n",
        "        \"python-dotenv\"\n",
        "    ]\n",
        "\n",
        "    for package in requirements:\n",
        "        print(f\"üì¶ Installiere {package}...\")\n",
        "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
        "\n",
        "    print(\"‚úÖ Alle Requirements installiert!\")\n",
        "\n",
        "# Installation ausf√ºhren\n",
        "install_requirements()\n",
        "\n",
        "# Standard Imports\n",
        "import asyncio\n",
        "import json\n",
        "import time\n",
        "import requests\n",
        "from datetime import datetime\n",
        "import pandas as pd\n",
        "from google.colab import userdata\n",
        "import nest_asyncio\n",
        "\n",
        "# Async Support f√ºr Colab\n",
        "nest_asyncio.apply()\n",
        "\n",
        "print(\"üöÄ Setup komplett - alle Libraries geladen!\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# ZELLE 0b: Google Drive Setup + Ordnerstruktur\n",
        "# =============================================================================\n",
        "# @title Google Drive Mount + Newsletter System Ordnerstruktur anlegen\n",
        "\n",
        "import os\n",
        "from pathlib import Path\n",
        "from google.colab import drive\n",
        "import yaml\n",
        "import json\n",
        "from datetime import datetime\n",
        "\n",
        "def setup_google_drive():\n",
        "    \"\"\"Mounted Google Drive und erstellt Newsletter System Ordnerstruktur\"\"\"\n",
        "\n",
        "    # Google Drive mounten\n",
        "    print(\"üîó Mounte Google Drive...\")\n",
        "    drive.mount('/content/drive')\n",
        "    print(\"‚úÖ Google Drive erfolgreich gemounted\")\n",
        "\n",
        "    # Base Path definieren\n",
        "    base_path = Path(\"/content/drive/MyDrive/Newsletter_System\")\n",
        "\n",
        "    # Ordnerstruktur erstellen\n",
        "    folders = [\n",
        "        \"configs\",\n",
        "        \"data/sessions\",\n",
        "        \"data/sessions/archive\",\n",
        "        \"templates\",\n",
        "        \"logs\"\n",
        "    ]\n",
        "\n",
        "    print(f\"üìÅ Erstelle Newsletter System Struktur: {base_path}\")\n",
        "\n",
        "    # Hauptordner erstellen\n",
        "    base_path.mkdir(exist_ok=True)\n",
        "\n",
        "    # Unterordner erstellen\n",
        "    for folder in folders:\n",
        "        folder_path = base_path / folder\n",
        "        folder_path.mkdir(parents=True, exist_ok=True)\n",
        "        print(f\"  ‚úÖ {folder}\")\n",
        "\n",
        "    # Erstelle README f√ºr Dokumentation\n",
        "    readme_content = \"\"\"# Newsletter System - Google Drive Storage\n",
        "\n",
        "## Ordnerstruktur:\n",
        "\n",
        "### `/configs/`\n",
        "- `locations.yaml` - Stadt-spezifische Konfigurationen\n",
        "- `categories.yaml` - Kategorie-Templates und Suchstrategien\n",
        "- `api_settings.yaml` - API-spezifische Parameter\n",
        "\n",
        "### `/data/sessions/`\n",
        "- Session-basierte Datensammlung\n",
        "- Format: `YYYY-MM-DD_location_HH-MM/`\n",
        "- Jede Session enth√§lt: raw_responses/, processed_content/, final_newsletter\n",
        "\n",
        "### `/templates/`\n",
        "- Newsletter-Templates\n",
        "- Prompt-Templates f√ºr verschiedene APIs\n",
        "\n",
        "### `/logs/`\n",
        "- System-Logs und Error-Tracking\n",
        "\n",
        "## Erstellungszeit:\n",
        "\"\"\" + datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "\n",
        "    readme_path = base_path / \"README.md\"\n",
        "    with open(readme_path, \"w\", encoding=\"utf-8\") as f:\n",
        "        f.write(readme_content)\n",
        "\n",
        "    print(f\"üìÑ README erstellt: {readme_path}\")\n",
        "\n",
        "    return base_path\n",
        "\n",
        "def create_initial_configs(base_path):\n",
        "    \"\"\"Erstellt initiale YAML-Konfigurationsdateien\"\"\"\n",
        "\n",
        "    configs_path = base_path / \"configs\"\n",
        "\n",
        "    # 1. LOCATIONS.YAML\n",
        "    locations_config = {\n",
        "        \"m√ºnchen\": {\n",
        "            \"official_names\": [\"M√ºnchen\", \"Munich\", \"Muenchen\"],\n",
        "            \"url_slug\": \"muenchen\",\n",
        "            \"official_domains\": [\"muenchen.de\", \"stadtwerke-muenchen.de\", \"mvg.de\"],\n",
        "            \"timezone\": \"Europe/Berlin\",\n",
        "            \"region_context\": \"Bayern Deutschland\",\n",
        "            \"population\": 1500000,\n",
        "            \"type\": \"landeshauptstadt\"\n",
        "        },\n",
        "        \"berlin\": {\n",
        "            \"official_names\": [\"Berlin\"],\n",
        "            \"url_slug\": \"berlin\",\n",
        "            \"official_domains\": [\"berlin.de\", \"bvg.de\"],\n",
        "            \"timezone\": \"Europe/Berlin\",\n",
        "            \"region_context\": \"Deutschland Hauptstadt\",\n",
        "            \"population\": 3700000,\n",
        "            \"type\": \"hauptstadt\"\n",
        "        },\n",
        "        \"hamburg\": {\n",
        "            \"official_names\": [\"Hamburg\"],\n",
        "            \"url_slug\": \"hamburg\",\n",
        "            \"official_domains\": [\"hamburg.de\", \"hvv.de\"],\n",
        "            \"timezone\": \"Europe/Berlin\",\n",
        "            \"region_context\": \"Norddeutschland\",\n",
        "            \"population\": 1900000,\n",
        "            \"type\": \"hansestadt\"\n",
        "        }\n",
        "    }\n",
        "\n",
        "    locations_file = configs_path / \"locations.yaml\"\n",
        "    with open(locations_file, \"w\", encoding=\"utf-8\") as f:\n",
        "        yaml.dump(locations_config, f, allow_unicode=True, default_flow_style=False)\n",
        "\n",
        "    print(f\"‚úÖ Locations Config: {locations_file}\")\n",
        "\n",
        "    # 2. CATEGORIES.YAML\n",
        "    categories_config = {\n",
        "        \"wetter\": {\n",
        "            \"priority\": \"high\",\n",
        "            \"time_sensitivity\": \"today\",\n",
        "            \"description\": \"Aktuelle Wettervorhersage und Wetterwarnungen\",\n",
        "            \"search_templates\": {\n",
        "                \"claude_web\": \"aktuelles Wetter {location} heute {date_context} Deutschland Vorhersage\",\n",
        "                \"perplexity\": \"Wetter Vorhersage {location} {date_context} Deutschland aktuell\",\n",
        "                \"firecrawl_search\": \"Wetter {location} heute Vorhersage Deutschland\"\n",
        "            },\n",
        "            \"fallback_urls\": [\n",
        "                \"https://www.wetter.com/deutschland/{location_slug}\",\n",
        "                \"https://www.wetteronline.de/wetter/{location_slug}\"\n",
        "            ],\n",
        "            \"keywords\": [\"Wetter\", \"Temperatur\", \"Regen\", \"Sonne\", \"Vorhersage\"]\n",
        "        },\n",
        "\n",
        "        \"verkehr\": {\n",
        "            \"priority\": \"high\",\n",
        "            \"time_sensitivity\": \"current\",\n",
        "            \"description\": \"Aktuelle Verkehrslage, St√∂rungen und √ñPNV-Infos\",\n",
        "            \"search_templates\": {\n",
        "                \"claude_web\": \"Verkehrslage {location} aktuell St√∂rungen Staus {date_context}\",\n",
        "                \"perplexity\": \"aktuelle Verkehrsst√∂rungen {location} √ñPNV Staus {date_context}\",\n",
        "                \"firecrawl_search\": \"Verkehr {location} St√∂rungen aktuell\"\n",
        "            },\n",
        "            \"fallback_urls\": [\n",
        "                \"https://www.verkehr.nrw/verkehrslage/{location_slug}\",\n",
        "                \"https://www.adac.de/verkehr/verkehrsinformationen/\"\n",
        "            ],\n",
        "            \"keywords\": [\"Verkehr\", \"Stau\", \"√ñPNV\", \"St√∂rung\", \"Umleitung\"]\n",
        "        },\n",
        "\n",
        "        \"events\": {\n",
        "            \"priority\": \"medium\",\n",
        "            \"time_sensitivity\": \"today_tomorrow\",\n",
        "            \"description\": \"Lokale Veranstaltungen, Konzerte, Kultur\",\n",
        "            \"search_templates\": {\n",
        "                \"claude_web\": \"Veranstaltungen Events {location} {date_context} heute morgen\",\n",
        "                \"perplexity\": \"Events Konzerte Ausstellungen {location} {date_context}\",\n",
        "                \"firecrawl_search\": \"Veranstaltungen {location} heute Events\"\n",
        "            },\n",
        "            \"scrape_urls\": [\n",
        "                \"https://www.{location_slug}.de/veranstaltungen\",\n",
        "                \"https://www.eventbrite.de/d/germany--{location_slug}/events/\"\n",
        "            ],\n",
        "            \"keywords\": [\"Event\", \"Konzert\", \"Ausstellung\", \"Theater\", \"Festival\"]\n",
        "        },\n",
        "\n",
        "        \"nachrichten\": {\n",
        "            \"priority\": \"high\",\n",
        "            \"time_sensitivity\": \"today\",\n",
        "            \"description\": \"Lokale Nachrichten und wichtige Meldungen\",\n",
        "            \"search_templates\": {\n",
        "                \"claude_web\": \"lokale Nachrichten {location} {date_context} heute aktuell\",\n",
        "                \"perplexity\": \"{location} News Nachrichten lokal {date_context}\",\n",
        "                \"firecrawl_search\": \"{location} Nachrichten heute lokal\"\n",
        "            },\n",
        "            \"scrape_urls\": [\n",
        "                \"https://www.{location_slug}.de/aktuelles\",\n",
        "                \"https://www.sueddeutsche.de/{location_slug}\"\n",
        "            ],\n",
        "            \"keywords\": [\"Nachrichten\", \"News\", \"Meldung\", \"aktuell\", \"lokal\"]\n",
        "        },\n",
        "\n",
        "        \"rathaus\": {\n",
        "            \"priority\": \"medium\",\n",
        "            \"time_sensitivity\": \"today\",\n",
        "            \"description\": \"Offizielle Mitteilungen der Stadtverwaltung\",\n",
        "            \"primary_method\": \"scrape\",\n",
        "            \"scrape_urls\": [\n",
        "                \"https://www.{location_slug}.de/rathaus\",\n",
        "                \"https://www.{location_slug}.de/aktuelles\",\n",
        "                \"https://www.stadt-{location_slug}.de\"\n",
        "            ],\n",
        "            \"search_templates\": {\n",
        "                \"claude_web\": \"Rathaus {location} Mitteilungen Bekanntmachungen {date_context}\",\n",
        "                \"perplexity\": \"{location} Stadtverwaltung Rathaus Mitteilungen {date_context}\",\n",
        "                \"firecrawl_search\": \"Rathaus {location} Mitteilungen heute\"\n",
        "            },\n",
        "            \"keywords\": [\"Rathaus\", \"Stadtverwaltung\", \"Bekanntmachung\", \"Mitteilung\"]\n",
        "        },\n",
        "\n",
        "        \"schulen\": {\n",
        "            \"priority\": \"low\",\n",
        "            \"time_sensitivity\": \"today\",\n",
        "            \"description\": \"Schulnachrichten und Bildungsinfos\",\n",
        "            \"search_templates\": {\n",
        "                \"claude_web\": \"Schulen {location} Mitteilungen Unterrichtsausfall {date_context}\",\n",
        "                \"perplexity\": \"{location} Schulnachrichten Bildung {date_context}\",\n",
        "                \"firecrawl_search\": \"Schulen {location} Mitteilungen\"\n",
        "            },\n",
        "            \"keywords\": [\"Schule\", \"Bildung\", \"Unterricht\", \"Mitteilung\"]\n",
        "        },\n",
        "\n",
        "        \"vereine\": {\n",
        "            \"priority\": \"low\",\n",
        "            \"time_sensitivity\": \"today_tomorrow\",\n",
        "            \"description\": \"Vereinsaktivit√§ten und lokale Gemeinschaft\",\n",
        "            \"search_templates\": {\n",
        "                \"claude_web\": \"Vereine {location} Aktivit√§ten Termine {date_context}\",\n",
        "                \"perplexity\": \"{location} Vereine Events Aktivit√§ten {date_context}\",\n",
        "                \"firecrawl_search\": \"Vereine {location} Termine heute\"\n",
        "            },\n",
        "            \"keywords\": [\"Verein\", \"Gemeinschaft\", \"Aktivit√§t\", \"Termin\"]\n",
        "        },\n",
        "\n",
        "        \"sport\": {\n",
        "            \"priority\": \"medium\",\n",
        "            \"time_sensitivity\": \"today\",\n",
        "            \"description\": \"Lokale Sportergebnisse und Sportveranstaltungen\",\n",
        "            \"search_templates\": {\n",
        "                \"claude_web\": \"{location} Sport Ergebnisse Spiele {date_context} lokal\",\n",
        "                \"perplexity\": \"Sport {location} Ergebnisse Vereine {date_context}\",\n",
        "                \"firecrawl_search\": \"{location} Sport heute Ergebnisse\"\n",
        "            },\n",
        "            \"keywords\": [\"Sport\", \"Spiel\", \"Ergebnis\", \"Verein\", \"Mannschaft\"]\n",
        "        }\n",
        "    }\n",
        "\n",
        "    categories_file = configs_path / \"categories.yaml\"\n",
        "    with open(categories_file, \"w\", encoding=\"utf-8\") as f:\n",
        "        yaml.dump(categories_config, f, allow_unicode=True, default_flow_style=False)\n",
        "\n",
        "    print(f\"‚úÖ Categories Config: {categories_file}\")\n",
        "\n",
        "    # 3. API_SETTINGS.YAML\n",
        "    api_settings_config = {\n",
        "        \"claude\": {\n",
        "            \"model\": \"claude-3-5-haiku-latest\",\n",
        "            \"max_tokens\": 2000,\n",
        "            \"web_search\": {\n",
        "                \"max_uses\": 5,\n",
        "                \"user_location\": {\n",
        "                    \"type\": \"approximate\",\n",
        "                    \"country\": \"DE\",\n",
        "                    \"timezone\": \"Europe/Berlin\"\n",
        "                }\n",
        "            }\n",
        "        },\n",
        "\n",
        "        \"perplexity\": {\n",
        "            \"model\": \"sonar-pro\",\n",
        "            \"temperature\": 0.2,\n",
        "            \"top_p\": 0.9,\n",
        "            \"extra_body\": {\n",
        "                \"search_mode\": \"web\",\n",
        "                \"return_images\": False,\n",
        "                \"return_related_questions\": False,\n",
        "                \"web_search_options\": {\n",
        "                    \"search_context_size\": \"medium\",\n",
        "                    \"user_location\": {\"country\": \"DE\"}\n",
        "                }\n",
        "            }\n",
        "        },\n",
        "\n",
        "        \"firecrawl\": {\n",
        "            \"default_formats\": [\"markdown\", \"links\"],\n",
        "            \"location\": {\n",
        "                \"country\": \"DE\",\n",
        "                \"languages\": [\"de-DE\"]\n",
        "            },\n",
        "            \"search_limits\": {\n",
        "                \"default\": 5,\n",
        "                \"wetter\": 3,\n",
        "                \"verkehr\": 4,\n",
        "                \"events\": 5\n",
        "            },\n",
        "            \"scrape_timeout\": 30000\n",
        "        },\n",
        "\n",
        "        \"gemini\": {\n",
        "            \"model\": \"gemini-2.0-flash-exp\",\n",
        "            \"temperature\": 0.3,\n",
        "            \"max_output_tokens\": 2000\n",
        "        }\n",
        "    }\n",
        "\n",
        "    api_settings_file = configs_path / \"api_settings.yaml\"\n",
        "    with open(api_settings_file, \"w\", encoding=\"utf-8\") as f:\n",
        "        yaml.dump(api_settings_config, f, allow_unicode=True, default_flow_style=False)\n",
        "\n",
        "    print(f\"‚úÖ API Settings Config: {api_settings_file}\")\n",
        "\n",
        "    return {\n",
        "        \"locations\": locations_file,\n",
        "        \"categories\": categories_file,\n",
        "        \"api_settings\": api_settings_file\n",
        "    }\n",
        "\n",
        "def test_config_access(config_files):\n",
        "    \"\"\"Testet das Laden der erstellten Konfigurationsdateien\"\"\"\n",
        "\n",
        "    print(\"\\nüß™ TESTE CONFIG-ZUGRIFF\")\n",
        "    print(\"=\" * 40)\n",
        "\n",
        "    try:\n",
        "        # Teste Locations Config\n",
        "        with open(config_files[\"locations\"], \"r\", encoding=\"utf-8\") as f:\n",
        "            locations = yaml.safe_load(f)\n",
        "\n",
        "        print(f\"üìç Locations geladen: {list(locations.keys())}\")\n",
        "        print(f\"   M√ºnchen Domains: {locations['m√ºnchen']['official_domains']}\")\n",
        "\n",
        "        # Teste Categories Config\n",
        "        with open(config_files[\"categories\"], \"r\", encoding=\"utf-8\") as f:\n",
        "            categories = yaml.safe_load(f)\n",
        "\n",
        "        print(f\"üìã Kategorien geladen: {list(categories.keys())}\")\n",
        "        print(f\"   Wetter Priority: {categories['wetter']['priority']}\")\n",
        "        print(f\"   Events Template: {categories['events']['search_templates']['claude_web']}\")\n",
        "\n",
        "        # Teste API Settings Config\n",
        "        with open(config_files[\"api_settings\"], \"r\", encoding=\"utf-8\") as f:\n",
        "            api_settings = yaml.safe_load(f)\n",
        "\n",
        "        print(f\"üîß APIs konfiguriert: {list(api_settings.keys())}\")\n",
        "        print(f\"   Claude Model: {api_settings['claude']['model']}\")\n",
        "\n",
        "        print(\"‚úÖ Alle Config-Dateien erfolgreich lesbar!\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Config Test Fehler: {e}\")\n",
        "\n",
        "# =============================================================================\n",
        "# AUSF√úHRUNG\n",
        "# =============================================================================\n",
        "\n",
        "print(\"üöÄ STARTE GOOGLE DRIVE SETUP\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "try:\n",
        "    # 1. Google Drive Setup\n",
        "    base_path = setup_google_drive()\n",
        "    print(f\"‚úÖ Base Path: {base_path}\")\n",
        "\n",
        "    # 2. Config-Dateien erstellen\n",
        "    print(f\"\\nüìù ERSTELLE KONFIGURATIONSDATEIEN\")\n",
        "    config_files = create_initial_configs(base_path)\n",
        "\n",
        "    # 3. Config-Zugriff testen\n",
        "    test_config_access(config_files)\n",
        "\n",
        "    print(f\"\\nüéâ SETUP KOMPLETT!\")\n",
        "    print(f\"üìÅ Newsletter System bereit unter: {base_path}\")\n",
        "    print(f\"üìã {len(config_files)} Konfigurationsdateien erstellt\")\n",
        "\n",
        "    # Global verf√ºgbar machen\n",
        "    NEWSLETTER_SYSTEM_PATH = str(base_path)\n",
        "    print(f\"üåê Global verf√ºgbar: NEWSLETTER_SYSTEM_PATH\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Setup Fehler: {e}\")\n",
        "    import traceback\n",
        "    print(f\"üîç Traceback: {traceback.format_exc()}\")\n",
        "\n",
        "print(\"=\" * 50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "id": "SdDUHbfdh-h5",
        "outputId": "c6153a47-d4f5-43a6-dd7c-ac2556009b22"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üöÄ STARTE GOOGLE DRIVE SETUP\n",
            "==================================================\n",
            "üîó Mounte Google Drive...\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "‚úÖ Google Drive erfolgreich gemounted\n",
            "üìÅ Erstelle Newsletter System Struktur: /content/drive/MyDrive/Newsletter_System\n",
            "  ‚úÖ configs\n",
            "  ‚úÖ data/sessions\n",
            "  ‚úÖ data/sessions/archive\n",
            "  ‚úÖ templates\n",
            "  ‚úÖ logs\n",
            "üìÑ README erstellt: /content/drive/MyDrive/Newsletter_System/README.md\n",
            "‚úÖ Base Path: /content/drive/MyDrive/Newsletter_System\n",
            "\n",
            "üìù ERSTELLE KONFIGURATIONSDATEIEN\n",
            "‚úÖ Locations Config: /content/drive/MyDrive/Newsletter_System/configs/locations.yaml\n",
            "‚úÖ Categories Config: /content/drive/MyDrive/Newsletter_System/configs/categories.yaml\n",
            "‚úÖ API Settings Config: /content/drive/MyDrive/Newsletter_System/configs/api_settings.yaml\n",
            "\n",
            "üß™ TESTE CONFIG-ZUGRIFF\n",
            "========================================\n",
            "üìç Locations geladen: ['berlin', 'hamburg', 'm√ºnchen']\n",
            "   M√ºnchen Domains: ['muenchen.de', 'stadtwerke-muenchen.de', 'mvg.de']\n",
            "üìã Kategorien geladen: ['events', 'nachrichten', 'rathaus', 'schulen', 'sport', 'vereine', 'verkehr', 'wetter']\n",
            "   Wetter Priority: high\n",
            "   Events Template: Veranstaltungen Events {location} {date_context} heute morgen\n",
            "üîß APIs konfiguriert: ['claude', 'firecrawl', 'gemini', 'perplexity']\n",
            "   Claude Model: claude-3-5-haiku-latest\n",
            "‚úÖ Alle Config-Dateien erfolgreich lesbar!\n",
            "\n",
            "üéâ SETUP KOMPLETT!\n",
            "üìÅ Newsletter System bereit unter: /content/drive/MyDrive/Newsletter_System\n",
            "üìã 3 Konfigurationsdateien erstellt\n",
            "üåê Global verf√ºgbar: NEWSLETTER_SYSTEM_PATH\n",
            "==================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# ZELLE 0c: ConfigManager Implementation\n",
        "# =============================================================================\n",
        "# @title ConfigManager - Zentrale Konfigurationsverwaltung f√ºr Newsletter System\n",
        "\n",
        "import yaml\n",
        "import json\n",
        "from pathlib import Path\n",
        "from datetime import datetime, timedelta\n",
        "import re\n",
        "\n",
        "class ConfigManager:\n",
        "    \"\"\"Zentrale Verwaltung aller Konfigurationen f√ºr das Newsletter System\"\"\"\n",
        "\n",
        "    def __init__(self, base_path=None):\n",
        "        \"\"\"\n",
        "        Initialisiert ConfigManager mit Pfad zum Newsletter System\n",
        "\n",
        "        Args:\n",
        "            base_path: Pfad zum Newsletter System (default: aus Global)\n",
        "        \"\"\"\n",
        "        if base_path is None:\n",
        "            if 'NEWSLETTER_SYSTEM_PATH' in globals():\n",
        "                self.base_path = Path(NEWSLETTER_SYSTEM_PATH)\n",
        "            else:\n",
        "                raise ValueError(\"NEWSLETTER_SYSTEM_PATH nicht gefunden. F√ºhre zuerst Zelle 0b aus!\")\n",
        "        else:\n",
        "            self.base_path = Path(base_path)\n",
        "\n",
        "        self.configs_path = self.base_path / \"configs\"\n",
        "\n",
        "        # Konfigurationen laden\n",
        "        self.locations = {}\n",
        "        self.categories = {}\n",
        "        self.api_settings = {}\n",
        "\n",
        "        self.load_all_configs()\n",
        "\n",
        "    def load_all_configs(self):\n",
        "        \"\"\"L√§dt alle YAML-Konfigurationsdateien\"\"\"\n",
        "        try:\n",
        "            # Locations laden\n",
        "            locations_file = self.configs_path / \"locations.yaml\"\n",
        "            if locations_file.exists():\n",
        "                with open(locations_file, \"r\", encoding=\"utf-8\") as f:\n",
        "                    self.locations = yaml.safe_load(f)\n",
        "                print(f\"‚úÖ Locations geladen: {len(self.locations)} Orte\")\n",
        "\n",
        "            # Categories laden\n",
        "            categories_file = self.configs_path / \"categories.yaml\"\n",
        "            if categories_file.exists():\n",
        "                with open(categories_file, \"r\", encoding=\"utf-8\") as f:\n",
        "                    self.categories = yaml.safe_load(f)\n",
        "                print(f\"‚úÖ Categories geladen: {len(self.categories)} Kategorien\")\n",
        "\n",
        "            # API Settings laden\n",
        "            api_file = self.configs_path / \"api_settings.yaml\"\n",
        "            if api_file.exists():\n",
        "                with open(api_file, \"r\", encoding=\"utf-8\") as f:\n",
        "                    self.api_settings = yaml.safe_load(f)\n",
        "                print(f\"‚úÖ API Settings geladen: {len(self.api_settings)} APIs\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Fehler beim Laden der Configs: {e}\")\n",
        "            raise\n",
        "\n",
        "    # =========================================================================\n",
        "    # LOCATION MANAGEMENT\n",
        "    # =========================================================================\n",
        "\n",
        "    def get_location_config(self, location):\n",
        "        \"\"\"\n",
        "        Gibt Konfiguration f√ºr einen Ort zur√ºck\n",
        "\n",
        "        Args:\n",
        "            location: Ortsname (case-insensitive)\n",
        "\n",
        "        Returns:\n",
        "            dict: Location config oder None\n",
        "        \"\"\"\n",
        "        location_key = location.lower()\n",
        "        return self.locations.get(location_key)\n",
        "\n",
        "    def get_location_names(self, location):\n",
        "        \"\"\"Gibt alle Namen-Varianten f√ºr einen Ort zur√ºck\"\"\"\n",
        "        config = self.get_location_config(location)\n",
        "        if config:\n",
        "            return config.get(\"official_names\", [location])\n",
        "        return [location]\n",
        "\n",
        "    def get_location_domains(self, location):\n",
        "        \"\"\"Gibt offizielle Domains f√ºr einen Ort zur√ºck\"\"\"\n",
        "        config = self.get_location_config(location)\n",
        "        if config:\n",
        "            return config.get(\"official_domains\", [])\n",
        "        return []\n",
        "\n",
        "    def get_url_slug(self, location):\n",
        "        \"\"\"Gibt URL-kompatible Schreibweise f√ºr Ort zur√ºck\"\"\"\n",
        "        config = self.get_location_config(location)\n",
        "        if config:\n",
        "            return config.get(\"url_slug\", location.lower())\n",
        "        return location.lower()\n",
        "\n",
        "    # =========================================================================\n",
        "    # CATEGORY MANAGEMENT\n",
        "    # =========================================================================\n",
        "\n",
        "    def get_category_config(self, category):\n",
        "        \"\"\"\n",
        "        Gibt Konfiguration f√ºr eine Kategorie zur√ºck\n",
        "\n",
        "        Args:\n",
        "            category: Kategoriename (case-insensitive)\n",
        "\n",
        "        Returns:\n",
        "            dict: Category config oder None\n",
        "        \"\"\"\n",
        "        category_key = category.lower()\n",
        "        return self.categories.get(category_key)\n",
        "\n",
        "    def get_category_priority(self, category):\n",
        "        \"\"\"Gibt Priorit√§t einer Kategorie zur√ºck\"\"\"\n",
        "        config = self.get_category_config(category)\n",
        "        if config:\n",
        "            return config.get(\"priority\", \"medium\")\n",
        "        return \"medium\"\n",
        "\n",
        "    def get_category_method(self, category):\n",
        "        \"\"\"Bestimmt beste Methode f√ºr eine Kategorie\"\"\"\n",
        "        config = self.get_category_config(category)\n",
        "        if config:\n",
        "            # Explizit definierte Methode\n",
        "            if \"primary_method\" in config:\n",
        "                return config[\"primary_method\"]\n",
        "\n",
        "            # Scrape wenn URLs vorhanden\n",
        "            if \"scrape_urls\" in config and config[\"scrape_urls\"]:\n",
        "                return \"scrape\"\n",
        "\n",
        "            # Sonst Search\n",
        "            return \"search\"\n",
        "        return \"search\"\n",
        "\n",
        "    # =========================================================================\n",
        "    # TEMPLATE SYSTEM\n",
        "    # =========================================================================\n",
        "\n",
        "    def get_search_template(self, category, api, location):\n",
        "        \"\"\"\n",
        "        Gibt konfigurierten Search-Template f√ºr Kategorie/API/Location zur√ºck\n",
        "\n",
        "        Args:\n",
        "            category: Kategoriename\n",
        "            api: API-Name (\"claude_web\", \"perplexity\", \"firecrawl_search\")\n",
        "            location: Ortsname\n",
        "\n",
        "        Returns:\n",
        "            str: Fertig konfigurierte Query\n",
        "        \"\"\"\n",
        "        # Kategorie-Config laden\n",
        "        cat_config = self.get_category_config(category)\n",
        "        if not cat_config:\n",
        "            return f\"{category} {location}\"  # Fallback\n",
        "\n",
        "        # Template f√ºr API finden\n",
        "        templates = cat_config.get(\"search_templates\", {})\n",
        "        template = templates.get(api)\n",
        "\n",
        "        if not template:\n",
        "            # Fallback: ersten verf√ºgbaren Template nehmen\n",
        "            if templates:\n",
        "                template = list(templates.values())[0]\n",
        "            else:\n",
        "                return f\"{category} {location}\"\n",
        "\n",
        "        # Template mit Location-Daten anreichern\n",
        "        enriched_template = self.enrich_template(template, location)\n",
        "\n",
        "        return enriched_template\n",
        "\n",
        "    def enrich_template(self, template, location):\n",
        "        \"\"\"\n",
        "        Ersetzt Platzhalter in Templates mit konkreten Werten\n",
        "\n",
        "        Args:\n",
        "            template: Template-String mit Platzhaltern\n",
        "            location: Ortsname\n",
        "\n",
        "        Returns:\n",
        "            str: Template mit ersetzten Platzhaltern\n",
        "        \"\"\"\n",
        "        # Location-Daten holen\n",
        "        location_config = self.get_location_config(location)\n",
        "\n",
        "        replacements = {\n",
        "            \"{location}\": location,\n",
        "            \"{location_slug}\": self.get_url_slug(location),\n",
        "            \"{region_context}\": location_config.get(\"region_context\", \"Deutschland\") if location_config else \"Deutschland\"\n",
        "        }\n",
        "\n",
        "        # Datum-Platzhalter (wird sp√§ter von TimeContextManager √ºbernommen)\n",
        "        replacements[\"{date_context}\"] = \"heute\"\n",
        "\n",
        "        # Ersetze alle Platzhalter\n",
        "        enriched = template\n",
        "        for placeholder, value in replacements.items():\n",
        "            enriched = enriched.replace(placeholder, value)\n",
        "\n",
        "        return enriched\n",
        "\n",
        "    def get_scrape_urls(self, category, location):\n",
        "        \"\"\"\n",
        "        Gibt Scrape-URLs f√ºr Kategorie/Location zur√ºck\n",
        "\n",
        "        Args:\n",
        "            category: Kategoriename\n",
        "            location: Ortsname\n",
        "\n",
        "        Returns:\n",
        "            list: Liste der URLs zum Scrapen\n",
        "        \"\"\"\n",
        "        cat_config = self.get_category_config(category)\n",
        "        if not cat_config:\n",
        "            return []\n",
        "\n",
        "        urls = cat_config.get(\"scrape_urls\", [])\n",
        "\n",
        "        # URLs mit Location-Daten anreichern\n",
        "        enriched_urls = []\n",
        "        for url in urls:\n",
        "            enriched_url = self.enrich_template(url, location)\n",
        "            enriched_urls.append(enriched_url)\n",
        "\n",
        "        return enriched_urls\n",
        "\n",
        "    # =========================================================================\n",
        "    # API SETTINGS\n",
        "    # =========================================================================\n",
        "\n",
        "    def get_api_config(self, api):\n",
        "        \"\"\"\n",
        "        Gibt Konfiguration f√ºr eine API zur√ºck\n",
        "\n",
        "        Args:\n",
        "            api: API-Name (\"claude\", \"perplexity\", \"firecrawl\", \"gemini\")\n",
        "\n",
        "        Returns:\n",
        "            dict: API config oder leeres dict\n",
        "        \"\"\"\n",
        "        return self.api_settings.get(api, {})\n",
        "\n",
        "    def get_api_limits(self, api, category=None):\n",
        "        \"\"\"Gibt API-spezifische Limits zur√ºck\"\"\"\n",
        "        api_config = self.get_api_config(api)\n",
        "\n",
        "        if api == \"firecrawl\" and category:\n",
        "            limits = api_config.get(\"search_limits\", {})\n",
        "            return limits.get(category, limits.get(\"default\", 5))\n",
        "\n",
        "        return api_config.get(\"limit\", 5)\n",
        "\n",
        "    # =========================================================================\n",
        "    # NEWSLETTER WORKFLOW HELPERS\n",
        "    # =========================================================================\n",
        "\n",
        "    def get_newsletter_categories(self, priority_filter=None):\n",
        "        \"\"\"\n",
        "        Gibt Kategorien f√ºr Newsletter zur√ºck, optional gefiltert nach Priorit√§t\n",
        "\n",
        "        Args:\n",
        "            priority_filter: \"high\", \"medium\", \"low\" oder None f√ºr alle\n",
        "\n",
        "        Returns:\n",
        "            list: Kategorienamen sortiert nach Priorit√§t\n",
        "        \"\"\"\n",
        "        if priority_filter:\n",
        "            filtered_categories = [\n",
        "                name for name, config in self.categories.items()\n",
        "                if config.get(\"priority\") == priority_filter\n",
        "            ]\n",
        "        else:\n",
        "            filtered_categories = list(self.categories.keys())\n",
        "\n",
        "        # Sortiere nach Priorit√§t: high > medium > low\n",
        "        priority_order = {\"high\": 0, \"medium\": 1, \"low\": 2}\n",
        "\n",
        "        def priority_key(category):\n",
        "            config = self.get_category_config(category)\n",
        "            priority = config.get(\"priority\", \"medium\") if config else \"medium\"\n",
        "            return priority_order.get(priority, 1)\n",
        "\n",
        "        return sorted(filtered_categories, key=priority_key)\n",
        "\n",
        "    def create_newsletter_plan(self, location, categories=None):\n",
        "        \"\"\"\n",
        "        Erstellt Datensammlung-Plan f√ºr Newsletter\n",
        "\n",
        "        Args:\n",
        "            location: Ortsname\n",
        "            categories: Liste der Kategorien oder None f√ºr alle high/medium\n",
        "\n",
        "        Returns:\n",
        "            dict: Detaillierter Plan mit Queries und Methoden\n",
        "        \"\"\"\n",
        "        if categories is None:\n",
        "            categories = self.get_newsletter_categories(priority_filter=\"high\")\n",
        "            categories.extend(self.get_newsletter_categories(priority_filter=\"medium\"))\n",
        "\n",
        "        plan = {\n",
        "            \"location\": location,\n",
        "            \"location_config\": self.get_location_config(location),\n",
        "            \"timestamp\": datetime.now().isoformat(),\n",
        "            \"categories\": {}\n",
        "        }\n",
        "\n",
        "        for category in categories:\n",
        "            cat_config = self.get_category_config(category)\n",
        "            if not cat_config:\n",
        "                continue\n",
        "\n",
        "            method = self.get_category_method(category)\n",
        "\n",
        "            if method == \"search\":\n",
        "                # Search-Queries f√ºr alle APIs\n",
        "                search_queries = {}\n",
        "                for api in [\"claude_web\", \"perplexity\", \"firecrawl_search\"]:\n",
        "                    query = self.get_search_template(category, api, location)\n",
        "                    search_queries[api] = query\n",
        "\n",
        "                plan[\"categories\"][category] = {\n",
        "                    \"method\": \"search\",\n",
        "                    \"priority\": cat_config.get(\"priority\", \"medium\"),\n",
        "                    \"queries\": search_queries,\n",
        "                    \"limit\": self.get_api_limits(\"firecrawl\", category)\n",
        "                }\n",
        "\n",
        "            elif method == \"scrape\":\n",
        "                # Scrape-URLs\n",
        "                urls = self.get_scrape_urls(category, location)\n",
        "\n",
        "                plan[\"categories\"][category] = {\n",
        "                    \"method\": \"scrape\",\n",
        "                    \"priority\": cat_config.get(\"priority\", \"medium\"),\n",
        "                    \"urls\": urls\n",
        "                }\n",
        "\n",
        "        return plan\n",
        "\n",
        "    # =========================================================================\n",
        "    # DEBUGGING & INFO\n",
        "    # =========================================================================\n",
        "\n",
        "    def get_system_info(self):\n",
        "        \"\"\"Gibt Systeminfo zur√ºck\"\"\"\n",
        "        return {\n",
        "            \"base_path\": str(self.base_path),\n",
        "            \"locations_count\": len(self.locations),\n",
        "            \"categories_count\": len(self.categories),\n",
        "            \"apis_count\": len(self.api_settings),\n",
        "            \"available_locations\": list(self.locations.keys()),\n",
        "            \"available_categories\": list(self.categories.keys()),\n",
        "            \"configured_apis\": list(self.api_settings.keys())\n",
        "        }\n",
        "\n",
        "# =============================================================================\n",
        "# INITIALISIERUNG UND TESTS\n",
        "# =============================================================================\n",
        "\n",
        "# ConfigManager initialisieren\n",
        "try:\n",
        "    config_manager = ConfigManager()\n",
        "    print(\"‚úÖ ConfigManager initialisiert\")\n",
        "\n",
        "    # System Info\n",
        "    info = config_manager.get_system_info()\n",
        "    print(f\"üìä System Info: {info['locations_count']} Locations, {info['categories_count']} Categories, {info['apis_count']} APIs\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå ConfigManager Initialisierung fehlgeschlagen: {e}\")\n",
        "    config_manager = None\n",
        "\n",
        "# =============================================================================\n",
        "# DIREKTER TEST\n",
        "# =============================================================================\n",
        "\n",
        "if config_manager:\n",
        "    print(\"\\nüß™ TESTE CONFIGMANAGER\")\n",
        "    print(\"=\" * 40)\n",
        "\n",
        "    try:\n",
        "        # Test 1: Location Lookup\n",
        "        print(\"üìç Test 1: Location Config\")\n",
        "        location_config = config_manager.get_location_config(\"m√ºnchen\")\n",
        "        print(f\"  M√ºnchen Domains: {config_manager.get_location_domains('m√ºnchen')}\")\n",
        "        print(f\"  URL Slug: {config_manager.get_url_slug('M√ºnchen')}\")\n",
        "\n",
        "        # Test 2: Search Templates\n",
        "        print(f\"\\nüîç Test 2: Search Templates\")\n",
        "        wetter_query_claude = config_manager.get_search_template(\"wetter\", \"claude_web\", \"M√ºnchen\")\n",
        "        wetter_query_perplexity = config_manager.get_search_template(\"wetter\", \"perplexity\", \"M√ºnchen\")\n",
        "        print(f\"  Claude Wetter: {wetter_query_claude}\")\n",
        "        print(f\"  Perplexity Wetter: {wetter_query_perplexity}\")\n",
        "\n",
        "        # Test 3: Scrape URLs\n",
        "        print(f\"\\nüï∑Ô∏è Test 3: Scrape URLs\")\n",
        "        rathaus_urls = config_manager.get_scrape_urls(\"rathaus\", \"m√ºnchen\")\n",
        "        events_urls = config_manager.get_scrape_urls(\"events\", \"m√ºnchen\")\n",
        "        print(f\"  Rathaus URLs: {rathaus_urls}\")\n",
        "        print(f\"  Events URLs: {events_urls}\")\n",
        "\n",
        "        # Test 4: API Settings\n",
        "        print(f\"\\nüîß Test 4: API Settings\")\n",
        "        claude_config = config_manager.get_api_config(\"claude\")\n",
        "        firecrawl_limits = config_manager.get_api_limits(\"firecrawl\", \"wetter\")\n",
        "        print(f\"  Claude Model: {claude_config.get('model', 'N/A')}\")\n",
        "        print(f\"  Firecrawl Wetter Limit: {firecrawl_limits}\")\n",
        "\n",
        "        # Test 5: Newsletter Plan\n",
        "        print(f\"\\nüì∞ Test 5: Newsletter Plan\")\n",
        "        newsletter_plan = config_manager.create_newsletter_plan(\"m√ºnchen\", [\"wetter\", \"events\"])\n",
        "        print(f\"  Plan Location: {newsletter_plan['location']}\")\n",
        "        print(f\"  Plan Kategorien: {list(newsletter_plan['categories'].keys())}\")\n",
        "\n",
        "        for cat_name, cat_plan in newsletter_plan['categories'].items():\n",
        "            print(f\"  {cat_name}: {cat_plan['method']} ({cat_plan['priority']} priority)\")\n",
        "            if cat_plan['method'] == 'search':\n",
        "                print(f\"    Claude Query: {cat_plan['queries']['claude_web']}\")\n",
        "\n",
        "        print(f\"\\n‚úÖ Alle ConfigManager Tests erfolgreich!\")\n",
        "\n",
        "    except Exception as test_error:\n",
        "        print(f\"‚ùå ConfigManager Test Fehler: {test_error}\")\n",
        "        import traceback\n",
        "        print(f\"üîç Traceback: {traceback.format_exc()}\")\n",
        "\n",
        "print(\"=\" * 40)\n",
        "print(\"‚úÖ ConfigManager Setup komplett\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "id": "xzjjS6BTif7I",
        "outputId": "d6b800bc-d029-42c8-b656-a3f81773eac4"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Locations geladen: 3 Orte\n",
            "‚úÖ Categories geladen: 8 Kategorien\n",
            "‚úÖ API Settings geladen: 4 APIs\n",
            "‚úÖ ConfigManager initialisiert\n",
            "üìä System Info: 3 Locations, 8 Categories, 4 APIs\n",
            "\n",
            "üß™ TESTE CONFIGMANAGER\n",
            "========================================\n",
            "üìç Test 1: Location Config\n",
            "  M√ºnchen Domains: ['muenchen.de', 'stadtwerke-muenchen.de', 'mvg.de']\n",
            "  URL Slug: muenchen\n",
            "\n",
            "üîç Test 2: Search Templates\n",
            "  Claude Wetter: aktuelles Wetter M√ºnchen heute heute Deutschland Vorhersage\n",
            "  Perplexity Wetter: Wetter Vorhersage M√ºnchen heute Deutschland aktuell\n",
            "\n",
            "üï∑Ô∏è Test 3: Scrape URLs\n",
            "  Rathaus URLs: ['https://www.muenchen.de/rathaus', 'https://www.muenchen.de/aktuelles', 'https://www.stadt-muenchen.de']\n",
            "  Events URLs: ['https://www.muenchen.de/veranstaltungen', 'https://www.eventbrite.de/d/germany--muenchen/events/']\n",
            "\n",
            "üîß Test 4: API Settings\n",
            "  Claude Model: claude-3-5-haiku-latest\n",
            "  Firecrawl Wetter Limit: 3\n",
            "\n",
            "üì∞ Test 5: Newsletter Plan\n",
            "  Plan Location: m√ºnchen\n",
            "  Plan Kategorien: ['wetter', 'events']\n",
            "  wetter: search (high priority)\n",
            "    Claude Query: aktuelles Wetter m√ºnchen heute heute Deutschland Vorhersage\n",
            "  events: scrape (medium priority)\n",
            "\n",
            "‚úÖ Alle ConfigManager Tests erfolgreich!\n",
            "========================================\n",
            "‚úÖ ConfigManager Setup komplett\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# ZELLE 0d: TimeContextManager Implementation\n",
        "# =============================================================================\n",
        "# @title TimeContextManager - Intelligente Datums-Verarbeitung f√ºr Newsletter APIs\n",
        "\n",
        "from datetime import datetime, timedelta, time\n",
        "import pytz\n",
        "from typing import Dict, List, Optional\n",
        "import locale\n",
        "\n",
        "class TimeContextManager:\n",
        "    \"\"\"\n",
        "    Intelligente Datums- und Zeit-Kontextualisierung f√ºr Newsletter APIs\n",
        "    Stellt sicher, dass alle Suchanfragen zeitlich korrekt kontextualisiert sind\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, location=\"m√ºnchen\"):\n",
        "        \"\"\"\n",
        "        Initialisiert TimeContextManager\n",
        "\n",
        "        Args:\n",
        "            location: Standard-Ort f√ºr Timezone (default: m√ºnchen)\n",
        "        \"\"\"\n",
        "        self.location = location\n",
        "\n",
        "        # Deutsche Zeitzone setzen\n",
        "        self.timezone = pytz.timezone(\"Europe/Berlin\")\n",
        "\n",
        "        # Aktuelle Zeit in deutscher Zeitzone\n",
        "        self.now = datetime.now(self.timezone)\n",
        "\n",
        "        # Basis-Zeiten berechnen\n",
        "        self._calculate_time_references()\n",
        "\n",
        "        # Deutsche Locale f√ºr Wochentage/Monate (falls verf√ºgbar)\n",
        "        try:\n",
        "            locale.setlocale(locale.LC_TIME, 'de_DE.UTF-8')\n",
        "        except:\n",
        "            try:\n",
        "                locale.setlocale(locale.LC_TIME, 'German')\n",
        "            except:\n",
        "                pass  # Fallback zu English\n",
        "\n",
        "        print(f\"‚è∞ TimeContextManager initialisiert f√ºr {self.now.strftime('%A, %d.%m.%Y %H:%M')} (Zeitzone: {self.timezone})\")\n",
        "\n",
        "    def _calculate_time_references(self):\n",
        "        \"\"\"Berechnet alle relevanten Zeit-Referenzen\"\"\"\n",
        "\n",
        "        # Basis-Tage\n",
        "        self.heute = self.now.date()\n",
        "        self.gestern = self.heute - timedelta(days=1)\n",
        "        self.morgen = self.heute + timedelta(days=1)\n",
        "        self.√ºbermorgen = self.heute + timedelta(days=2)\n",
        "\n",
        "        # Wochenbezug\n",
        "        self.wochenstart = self.heute - timedelta(days=self.heute.weekday())  # Montag\n",
        "        self.wochenende_start = self.wochenstart + timedelta(days=5)  # Samstag\n",
        "        self.wochenende_end = self.wochenstart + timedelta(days=6)    # Sonntag\n",
        "\n",
        "        # Monatsbezug\n",
        "        self.monatsstart = self.heute.replace(day=1)\n",
        "\n",
        "        # String-Repr√§sentationen\n",
        "        self.heute_str = self.heute.strftime(\"%d.%m.%Y\")\n",
        "        self.gestern_str = self.gestern.strftime(\"%d.%m.%Y\")\n",
        "        self.morgen_str = self.morgen.strftime(\"%d.%m.%Y\")\n",
        "\n",
        "        # Wochentage\n",
        "        self.heute_wochentag = self.heute.strftime(\"%A\")\n",
        "        self.morgen_wochentag = self.morgen.strftime(\"%A\")\n",
        "\n",
        "        # Zeit des Tages\n",
        "        current_hour = self.now.hour\n",
        "        if current_hour < 6:\n",
        "            self.tageszeit = \"nacht\"\n",
        "        elif current_hour < 12:\n",
        "            self.tageszeit = \"morgen\"\n",
        "        elif current_hour < 18:\n",
        "            self.tageszeit = \"nachmittag\"\n",
        "        else:\n",
        "            self.tageszeit = \"abend\"\n",
        "\n",
        "    # =========================================================================\n",
        "    # ZEIT-KONTEXT GENERIERUNG\n",
        "    # =========================================================================\n",
        "\n",
        "    def get_time_context(self, timeframe=\"heute\", api=\"generic\"):\n",
        "        \"\"\"\n",
        "        Generiert zeitlichen Kontext f√ºr verschiedene Timeframes und APIs\n",
        "\n",
        "        Args:\n",
        "            timeframe: \"heute\", \"morgen\", \"gestern\", \"wochenende\", \"aktuell\", \"current\"\n",
        "            api: \"claude_web\", \"perplexity\", \"firecrawl\", \"generic\"\n",
        "\n",
        "        Returns:\n",
        "            dict: Zeit-Kontext mit verschiedenen Formaten\n",
        "        \"\"\"\n",
        "        context = {\n",
        "            \"timeframe\": timeframe,\n",
        "            \"api\": api,\n",
        "            \"timestamp\": self.now.isoformat(),\n",
        "            \"german_keywords\": [],\n",
        "            \"english_keywords\": [],\n",
        "            \"date_strings\": [],\n",
        "            \"api_parameters\": {}\n",
        "        }\n",
        "\n",
        "        if timeframe == \"heute\":\n",
        "            context.update({\n",
        "                \"german_keywords\": [\"heute\", \"aktuell\", \"momentan\", f\"am {self.heute_wochentag}\"],\n",
        "                \"english_keywords\": [\"today\", \"current\", \"now\", \"currently\"],\n",
        "                \"date_strings\": [self.heute_str, self.heute.strftime(\"%Y-%m-%d\")],\n",
        "                \"human_readable\": f\"heute ({self.heute_str})\"\n",
        "            })\n",
        "\n",
        "        elif timeframe == \"morgen\":\n",
        "            context.update({\n",
        "                \"german_keywords\": [\"morgen\", f\"am {self.morgen_wochentag}\", \"morgiger Tag\"],\n",
        "                \"english_keywords\": [\"tomorrow\", f\"on {self.morgen.strftime('%A')}\"],\n",
        "                \"date_strings\": [self.morgen_str, self.morgen.strftime(\"%Y-%m-%d\")],\n",
        "                \"human_readable\": f\"morgen ({self.morgen_str})\"\n",
        "            })\n",
        "\n",
        "        elif timeframe == \"gestern\":\n",
        "            context.update({\n",
        "                \"german_keywords\": [\"gestern\", \"am gestrigen Tag\"],\n",
        "                \"english_keywords\": [\"yesterday\"],\n",
        "                \"date_strings\": [self.gestern_str, self.gestern.strftime(\"%Y-%m-%d\")],\n",
        "                \"human_readable\": f\"gestern ({self.gestern_str})\"\n",
        "            })\n",
        "\n",
        "        elif timeframe == \"wochenende\":\n",
        "            context.update({\n",
        "                \"german_keywords\": [\"Wochenende\", \"Samstag Sonntag\", \"am Wochenende\"],\n",
        "                \"english_keywords\": [\"weekend\", \"Saturday Sunday\"],\n",
        "                \"date_strings\": [\n",
        "                    self.wochenende_start.strftime(\"%d.%m.%Y\"),\n",
        "                    self.wochenende_end.strftime(\"%d.%m.%Y\")\n",
        "                ],\n",
        "                \"human_readable\": f\"Wochenende ({self.wochenende_start.strftime('%d.%m.')} - {self.wochenende_end.strftime('%d.%m.%Y')})\"\n",
        "            })\n",
        "\n",
        "        elif timeframe in [\"aktuell\", \"current\"]:\n",
        "            context.update({\n",
        "                \"german_keywords\": [\"aktuell\", \"momentan\", \"zur Zeit\", \"gerade\", \"live\"],\n",
        "                \"english_keywords\": [\"current\", \"now\", \"currently\", \"live\", \"real-time\"],\n",
        "                \"date_strings\": [self.heute_str],\n",
        "                \"human_readable\": f\"aktuell ({self.tageszeit}, {self.heute_str})\"\n",
        "            })\n",
        "\n",
        "        # API-spezifische Parameter hinzuf√ºgen\n",
        "        context[\"api_parameters\"] = self._get_api_specific_parameters(timeframe, api)\n",
        "\n",
        "        return context\n",
        "\n",
        "    def _get_api_specific_parameters(self, timeframe, api):\n",
        "        \"\"\"Generiert API-spezifische Zeit-Parameter\"\"\"\n",
        "\n",
        "        params = {}\n",
        "\n",
        "        if api == \"firecrawl\":\n",
        "            # Firecrawl Search tbs Parameter\n",
        "            if timeframe == \"heute\":\n",
        "                params[\"tbs\"] = \"qdr:d\"  # Past 24 hours\n",
        "            elif timeframe == \"gestern\":\n",
        "                params[\"tbs\"] = \"qdr:d\"  # Past 24 hours (wird gestern mit abdecken)\n",
        "            elif timeframe == \"wochenende\":\n",
        "                params[\"tbs\"] = \"qdr:w\"  # Past week\n",
        "            elif timeframe in [\"aktuell\", \"current\"]:\n",
        "                params[\"tbs\"] = \"qdr:h\"  # Past hour\n",
        "\n",
        "        elif api == \"perplexity\":\n",
        "            # Perplexity hat bessere Ergebnisse mit expliziten Datums-Keywords\n",
        "            if timeframe == \"heute\":\n",
        "                params[\"date_hint\"] = f\"today {self.heute_str}\"\n",
        "            elif timeframe == \"morgen\":\n",
        "                params[\"date_hint\"] = f\"tomorrow {self.morgen_str}\"\n",
        "            elif timeframe == \"gestern\":\n",
        "                params[\"date_hint\"] = f\"yesterday {self.gestern_str}\"\n",
        "\n",
        "        elif api == \"claude_web\":\n",
        "            # Claude Web Search funktioniert gut mit nat√ºrlichen Keywords\n",
        "            if timeframe in [\"aktuell\", \"current\"]:\n",
        "                params[\"freshness_hint\"] = \"latest news current status\"\n",
        "            elif timeframe == \"heute\":\n",
        "                params[\"freshness_hint\"] = \"today news updates\"\n",
        "\n",
        "        return params\n",
        "\n",
        "    # =========================================================================\n",
        "    # TEMPLATE-INTEGRATION\n",
        "    # =========================================================================\n",
        "\n",
        "    def inject_time_context(self, template, timeframe=\"heute\", api=\"generic\"):\n",
        "        \"\"\"\n",
        "        Ersetzt {date_context} Platzhalter in Templates mit zeitlichem Kontext\n",
        "\n",
        "        Args:\n",
        "            template: Template-String mit {date_context} Platzhalter\n",
        "            timeframe: Gew√ºnschter Zeitbezug\n",
        "            api: Ziel-API f√ºr optimierte Formatierung\n",
        "\n",
        "        Returns:\n",
        "            str: Template mit ersetztem Zeit-Kontext\n",
        "        \"\"\"\n",
        "        time_context = self.get_time_context(timeframe, api)\n",
        "\n",
        "        # W√§hle passende Keywords basierend auf API\n",
        "        if api in [\"claude_web\", \"perplexity\"]:\n",
        "            # F√ºr diese APIs funktionieren deutsche Keywords gut\n",
        "            time_keywords = \" \".join(time_context[\"german_keywords\"][:2])  # Erste 2 Keywords\n",
        "        else:\n",
        "            # F√ºr andere APIs einfacher Ansatz\n",
        "            time_keywords = time_context[\"human_readable\"]\n",
        "\n",
        "        # Ersetze Platzhalter\n",
        "        enriched_template = template.replace(\"{date_context}\", time_keywords)\n",
        "\n",
        "        return enriched_template\n",
        "\n",
        "    def get_contextual_search_query(self, base_query, timeframe=\"heute\", api=\"generic\", location=None):\n",
        "        \"\"\"\n",
        "        Erstellt vollst√§ndig kontextualisierte Suchanfrage\n",
        "\n",
        "        Args:\n",
        "            base_query: Basis-Suchanfrage\n",
        "            timeframe: Zeitlicher Kontext\n",
        "            api: Ziel-API\n",
        "            location: Ort (optional)\n",
        "\n",
        "        Returns:\n",
        "            dict: Vollst√§ndige Query mit Metadaten\n",
        "        \"\"\"\n",
        "        time_context = self.get_time_context(timeframe, api)\n",
        "\n",
        "        # Zeit-Keywords hinzuf√ºgen\n",
        "        time_keywords = \" \".join(time_context[\"german_keywords\"][:2])\n",
        "\n",
        "        # Query zusammensetzen\n",
        "        if location:\n",
        "            contextual_query = f\"{base_query} {location} {time_keywords} Deutschland\"\n",
        "        else:\n",
        "            contextual_query = f\"{base_query} {time_keywords}\"\n",
        "\n",
        "        return {\n",
        "            \"query\": contextual_query,\n",
        "            \"base_query\": base_query,\n",
        "            \"time_context\": time_context,\n",
        "            \"location\": location,\n",
        "            \"timestamp\": self.now.isoformat(),\n",
        "            \"api_parameters\": time_context[\"api_parameters\"]\n",
        "        }\n",
        "\n",
        "    # =========================================================================\n",
        "    # KATEGORIE-SPEZIFISCHE ZEIT-LOGIK\n",
        "    # =========================================================================\n",
        "\n",
        "    def get_optimal_timeframe_for_category(self, category):\n",
        "        \"\"\"\n",
        "        Bestimmt optimalen Zeitrahmen f√ºr verschiedene Newsletter-Kategorien\n",
        "\n",
        "        Args:\n",
        "            category: Newsletter-Kategorie\n",
        "\n",
        "        Returns:\n",
        "            str: Optimaler timeframe f√ºr diese Kategorie\n",
        "        \"\"\"\n",
        "        category_time_mapping = {\n",
        "            \"wetter\": \"heute\",           # Wetter ist heute-fokussiert\n",
        "            \"verkehr\": \"aktuell\",        # Verkehr sollte real-time sein\n",
        "            \"events\": \"heute\",           # Events f√ºr heute/morgen\n",
        "            \"nachrichten\": \"heute\",      # Aktuelle Nachrichten\n",
        "            \"rathaus\": \"heute\",          # Aktuelle Bekanntmachungen\n",
        "            \"schulen\": \"heute\",          # Schulnachrichten f√ºr heute\n",
        "            \"vereine\": \"wochenende\",     # Vereinsaktivit√§ten oft am Wochenende\n",
        "            \"sport\": \"heute\"             # Sportergebnisse von heute\n",
        "        }\n",
        "\n",
        "        return category_time_mapping.get(category.lower(), \"heute\")\n",
        "\n",
        "    def is_relevant_timeframe(self, category, timeframe):\n",
        "        \"\"\"\n",
        "        Pr√ºft ob ein Zeitrahmen f√ºr eine Kategorie sinnvoll ist\n",
        "\n",
        "        Args:\n",
        "            category: Newsletter-Kategorie\n",
        "            timeframe: Zu pr√ºfender Zeitrahmen\n",
        "\n",
        "        Returns:\n",
        "            bool: True wenn Kombination sinnvoll ist\n",
        "        \"\"\"\n",
        "        relevant_combinations = {\n",
        "            \"wetter\": [\"heute\", \"morgen\"],\n",
        "            \"verkehr\": [\"aktuell\", \"heute\"],\n",
        "            \"events\": [\"heute\", \"morgen\", \"wochenende\"],\n",
        "            \"nachrichten\": [\"heute\", \"gestern\"],\n",
        "            \"rathaus\": [\"heute\", \"gestern\"],\n",
        "            \"schulen\": [\"heute\"],\n",
        "            \"vereine\": [\"heute\", \"wochenende\"],\n",
        "            \"sport\": [\"heute\", \"gestern\"]\n",
        "        }\n",
        "\n",
        "        return timeframe in relevant_combinations.get(category.lower(), [\"heute\"])\n",
        "\n",
        "    # =========================================================================\n",
        "    # NEWSLETTER WORKFLOW INTEGRATION\n",
        "    # =========================================================================\n",
        "\n",
        "    def create_time_aware_newsletter_plan(self, config_manager, location, categories=None):\n",
        "        \"\"\"\n",
        "        Erweitert ConfigManager Newsletter-Plan um zeitlichen Kontext\n",
        "\n",
        "        Args:\n",
        "            config_manager: ConfigManager Instance\n",
        "            location: Ortsname\n",
        "            categories: Liste der Kategorien\n",
        "\n",
        "        Returns:\n",
        "            dict: Zeit-bewusster Newsletter Plan\n",
        "        \"\"\"\n",
        "        # Basis-Plan vom ConfigManager holen\n",
        "        base_plan = config_manager.create_newsletter_plan(location, categories)\n",
        "\n",
        "        # Plan um Zeit-Kontext erweitern\n",
        "        time_aware_plan = base_plan.copy()\n",
        "        time_aware_plan[\"time_context\"] = {\n",
        "            \"created_at\": self.now.isoformat(),\n",
        "            \"timezone\": str(self.timezone),\n",
        "            \"reference_date\": self.heute_str,\n",
        "            \"tageszeit\": self.tageszeit\n",
        "        }\n",
        "\n",
        "        # Kategorien um Zeit-Kontext erweitern\n",
        "        for category, cat_plan in time_aware_plan[\"categories\"].items():\n",
        "            optimal_timeframe = self.get_optimal_timeframe_for_category(category)\n",
        "\n",
        "            cat_plan[\"timeframe\"] = optimal_timeframe\n",
        "            cat_plan[\"time_context\"] = self.get_time_context(optimal_timeframe)\n",
        "\n",
        "            # Queries um Zeit-Kontext erweitern\n",
        "            if \"queries\" in cat_plan:\n",
        "                enhanced_queries = {}\n",
        "                for api, query in cat_plan[\"queries\"].items():\n",
        "                    enhanced_query = self.inject_time_context(\n",
        "                        query,\n",
        "                        optimal_timeframe,\n",
        "                        api.replace(\"_web\", \"\").replace(\"_search\", \"\")  # API-Namen normalisieren\n",
        "                    )\n",
        "                    enhanced_queries[api] = enhanced_query\n",
        "\n",
        "                cat_plan[\"queries\"] = enhanced_queries\n",
        "                cat_plan[\"original_queries\"] = cat_plan.get(\"queries\", {})\n",
        "\n",
        "        return time_aware_plan\n",
        "\n",
        "    # =========================================================================\n",
        "    # UTILITY METHODS\n",
        "    # =========================================================================\n",
        "\n",
        "    def get_current_time_info(self):\n",
        "        \"\"\"Gibt aktuelle Zeit-Informationen zur√ºck\"\"\"\n",
        "        return {\n",
        "            \"current_datetime\": self.now.isoformat(),\n",
        "            \"date\": self.heute_str,\n",
        "            \"weekday\": self.heute_wochentag,\n",
        "            \"time_of_day\": self.tageszeit,\n",
        "            \"timezone\": str(self.timezone),\n",
        "            \"hour\": self.now.hour,\n",
        "            \"is_weekend\": self.heute.weekday() >= 5\n",
        "        }\n",
        "\n",
        "    def format_for_newsletter(self, timeframe=\"heute\"):\n",
        "        \"\"\"Formatiert Zeit-Kontext f√ºr Newsletter-Ausgabe\"\"\"\n",
        "        time_context = self.get_time_context(timeframe)\n",
        "        return time_context[\"human_readable\"]\n",
        "\n",
        "# =============================================================================\n",
        "# INITIALISIERUNG UND TESTS\n",
        "# =============================================================================\n",
        "\n",
        "# TimeContextManager initialisieren\n",
        "try:\n",
        "    time_manager = TimeContextManager(location=\"m√ºnchen\")\n",
        "    print(\"‚úÖ TimeContextManager initialisiert\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå TimeContextManager Initialisierung fehlgeschlagen: {e}\")\n",
        "    time_manager = None\n",
        "\n",
        "# =============================================================================\n",
        "# DIREKTER TEST\n",
        "# =============================================================================\n",
        "\n",
        "if time_manager:\n",
        "    print(\"\\nüß™ TESTE TIMECONTEXTMANAGER\")\n",
        "    print(\"=\" * 50)\n",
        "\n",
        "    try:\n",
        "        # Test 1: Aktuelle Zeit-Info\n",
        "        print(\"‚è∞ Test 1: Aktuelle Zeit-Info\")\n",
        "        time_info = time_manager.get_current_time_info()\n",
        "        print(f\"  Datum: {time_info['date']}\")\n",
        "        print(f\"  Wochentag: {time_info['weekday']}\")\n",
        "        print(f\"  Tageszeit: {time_info['time_of_day']} ({time_info['hour']}:00)\")\n",
        "        print(f\"  Wochenende: {time_info['is_weekend']}\")\n",
        "\n",
        "        # Test 2: Zeit-Kontexte\n",
        "        print(f\"\\nüìÖ Test 2: Zeit-Kontexte\")\n",
        "        for timeframe in [\"heute\", \"morgen\", \"aktuell\", \"wochenende\"]:\n",
        "            context = time_manager.get_time_context(timeframe, \"claude_web\")\n",
        "            print(f\"  {timeframe}: {context['human_readable']}\")\n",
        "            print(f\"    Keywords: {', '.join(context['german_keywords'][:3])}\")\n",
        "\n",
        "        # Test 3: Template-Injection\n",
        "        print(f\"\\nüî§ Test 3: Template Zeit-Injection\")\n",
        "        test_template = \"Wetter {location} {date_context} Deutschland Vorhersage\"\n",
        "        for api in [\"claude_web\", \"perplexity\", \"firecrawl\"]:\n",
        "            enriched = time_manager.inject_time_context(test_template, \"heute\", api)\n",
        "            print(f\"  {api}: {enriched}\")\n",
        "\n",
        "        # Test 4: Kategorie-spezifische Zeitrahmen\n",
        "        print(f\"\\nüéØ Test 4: Kategorie-spezifische Zeitrahmen\")\n",
        "        categories = [\"wetter\", \"verkehr\", \"events\", \"sport\"]\n",
        "        for category in categories:\n",
        "            optimal_time = time_manager.get_optimal_timeframe_for_category(category)\n",
        "            print(f\"  {category}: {optimal_time}\")\n",
        "\n",
        "        # Test 5: Kontextuelle Suchanfrage\n",
        "        print(f\"\\nüîç Test 5: Kontextuelle Suchanfrage\")\n",
        "        contextual_query = time_manager.get_contextual_search_query(\n",
        "            \"Wetter Vorhersage\",\n",
        "            \"heute\",\n",
        "            \"perplexity\",\n",
        "            \"M√ºnchen\"\n",
        "        )\n",
        "        print(f\"  Base Query: {contextual_query['base_query']}\")\n",
        "        print(f\"  Contextual Query: {contextual_query['query']}\")\n",
        "        print(f\"  API Parameters: {contextual_query['api_parameters']}\")\n",
        "\n",
        "        # Test 6: Integration mit ConfigManager\n",
        "        if 'config_manager' in globals() and config_manager:\n",
        "            print(f\"\\nüîó Test 6: ConfigManager Integration\")\n",
        "            time_aware_plan = time_manager.create_time_aware_newsletter_plan(\n",
        "                config_manager,\n",
        "                \"m√ºnchen\",\n",
        "                [\"wetter\", \"events\"]\n",
        "            )\n",
        "\n",
        "            print(f\"  Plan Zeitkontext: {time_aware_plan['time_context']['reference_date']}\")\n",
        "            for cat_name, cat_plan in time_aware_plan[\"categories\"].items():\n",
        "                print(f\"  {cat_name}:\")\n",
        "                print(f\"    Timeframe: {cat_plan['timeframe']}\")\n",
        "                if 'queries' in cat_plan:\n",
        "                    claude_query = cat_plan['queries'].get('claude_web', 'N/A')\n",
        "                    print(f\"    Claude Query: {claude_query}\")\n",
        "\n",
        "        print(f\"\\n‚úÖ Alle TimeContextManager Tests erfolgreich!\")\n",
        "\n",
        "    except Exception as test_error:\n",
        "        print(f\"‚ùå TimeContextManager Test Fehler: {test_error}\")\n",
        "        import traceback\n",
        "        print(f\"üîç Traceback: {traceback.format_exc()}\")\n",
        "\n",
        "print(\"=\" * 50)\n",
        "print(\"‚úÖ TimeContextManager Setup komplett\\n\")"
      ],
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Vk7bj5UjISG",
        "outputId": "f713ea53-915e-47f0-9ea8-ac3852497a75"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚è∞ TimeContextManager initialisiert f√ºr Sunday, 20.07.2025 15:35 (Zeitzone: Europe/Berlin)\n",
            "‚úÖ TimeContextManager initialisiert\n",
            "\n",
            "üß™ TESTE TIMECONTEXTMANAGER\n",
            "==================================================\n",
            "‚è∞ Test 1: Aktuelle Zeit-Info\n",
            "  Datum: 20.07.2025\n",
            "  Wochentag: Sunday\n",
            "  Tageszeit: nachmittag (15:00)\n",
            "  Wochenende: True\n",
            "\n",
            "üìÖ Test 2: Zeit-Kontexte\n",
            "  heute: heute (20.07.2025)\n",
            "    Keywords: heute, aktuell, momentan\n",
            "  morgen: morgen (21.07.2025)\n",
            "    Keywords: morgen, am Monday, morgiger Tag\n",
            "  aktuell: aktuell (nachmittag, 20.07.2025)\n",
            "    Keywords: aktuell, momentan, zur Zeit\n",
            "  wochenende: Wochenende (19.07. - 20.07.2025)\n",
            "    Keywords: Wochenende, Samstag Sonntag, am Wochenende\n",
            "\n",
            "üî§ Test 3: Template Zeit-Injection\n",
            "  claude_web: Wetter {location} heute aktuell Deutschland Vorhersage\n",
            "  perplexity: Wetter {location} heute aktuell Deutschland Vorhersage\n",
            "  firecrawl: Wetter {location} heute (20.07.2025) Deutschland Vorhersage\n",
            "\n",
            "üéØ Test 4: Kategorie-spezifische Zeitrahmen\n",
            "  wetter: heute\n",
            "  verkehr: aktuell\n",
            "  events: heute\n",
            "  sport: heute\n",
            "\n",
            "üîç Test 5: Kontextuelle Suchanfrage\n",
            "  Base Query: Wetter Vorhersage\n",
            "  Contextual Query: Wetter Vorhersage M√ºnchen heute aktuell Deutschland\n",
            "  API Parameters: {'date_hint': 'today 20.07.2025'}\n",
            "\n",
            "üîó Test 6: ConfigManager Integration\n",
            "  Plan Zeitkontext: 20.07.2025\n",
            "  wetter:\n",
            "    Timeframe: heute\n",
            "    Claude Query: aktuelles Wetter m√ºnchen heute heute Deutschland Vorhersage\n",
            "  events:\n",
            "    Timeframe: heute\n",
            "\n",
            "‚úÖ Alle TimeContextManager Tests erfolgreich!\n",
            "==================================================\n",
            "‚úÖ TimeContextManager Setup komplett\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# ZELLE 0e: DataPersistenceManager Implementation\n",
        "# =============================================================================\n",
        "# @title DataPersistenceManager - Strukturierte Speicherung in Google Drive\n",
        "\n",
        "import json\n",
        "import os\n",
        "from pathlib import Path\n",
        "from datetime import datetime\n",
        "import hashlib\n",
        "import uuid\n",
        "from typing import Dict, List, Optional, Any\n",
        "import pandas as pd\n",
        "\n",
        "class DataPersistenceManager:\n",
        "    \"\"\"\n",
        "    Strukturierte Speicherung aller Newsletter-Daten in Google Drive\n",
        "    Erm√∂glicht Nachvollziehbarkeit, Audit-Trails und Fact-Checking\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, location, session_id=None, base_path=None):\n",
        "        \"\"\"\n",
        "        Initialisiert DataPersistenceManager f√ºr eine Location/Session\n",
        "\n",
        "        Args:\n",
        "            location: Ortsname f√ºr Newsletter\n",
        "            session_id: Eindeutige Session-ID (wird auto-generiert falls None)\n",
        "            base_path: Basis-Pfad zum Newsletter System\n",
        "        \"\"\"\n",
        "        self.location = location.lower()\n",
        "\n",
        "        # Base Path bestimmen\n",
        "        if base_path is None:\n",
        "            if 'NEWSLETTER_SYSTEM_PATH' in globals():\n",
        "                self.base_path = Path(NEWSLETTER_SYSTEM_PATH)\n",
        "            else:\n",
        "                raise ValueError(\"NEWSLETTER_SYSTEM_PATH nicht gefunden. F√ºhre zuerst Zelle 0b aus!\")\n",
        "        else:\n",
        "            self.base_path = Path(base_path)\n",
        "\n",
        "        # Session ID generieren oder verwenden\n",
        "        if session_id is None:\n",
        "            timestamp = datetime.now().strftime('%Y-%m-%d_%H-%M')\n",
        "            self.session_id = f\"{timestamp}_{self.location}\"\n",
        "        else:\n",
        "            self.session_id = session_id\n",
        "\n",
        "        # Session-Pfad erstellen\n",
        "        self.session_path = self.base_path / \"data\" / \"sessions\" / self.session_id\n",
        "\n",
        "        # Ordnerstruktur f√ºr Session erstellen\n",
        "        self._create_session_structure()\n",
        "\n",
        "        # Session-Metadaten\n",
        "        self.session_meta = {\n",
        "            \"session_id\": self.session_id,\n",
        "            \"location\": location,\n",
        "            \"created_at\": datetime.now().isoformat(),\n",
        "            \"timezone\": \"Europe/Berlin\",\n",
        "            \"status\": \"active\",\n",
        "            \"api_calls\": 0,\n",
        "            \"categories_processed\": [],\n",
        "            \"total_content_items\": 0,\n",
        "            \"newsletter_generated\": False\n",
        "        }\n",
        "\n",
        "        # Content Registry f√ºr Session\n",
        "        self.content_registry = []\n",
        "        self.api_call_counter = 0\n",
        "\n",
        "        print(f\"üíæ DataPersistenceManager initialisiert\")\n",
        "        print(f\"üìÅ Session: {self.session_id}\")\n",
        "        print(f\"üìç Location: {location}\")\n",
        "        print(f\"üóÇÔ∏è Session Path: {self.session_path}\")\n",
        "\n",
        "    def _create_session_structure(self):\n",
        "        \"\"\"Erstellt Ordnerstruktur f√ºr aktuelle Session\"\"\"\n",
        "\n",
        "        # Hauptordner\n",
        "        self.session_path.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "        # Unterordner erstellen\n",
        "        folders = [\n",
        "            \"raw_responses\",           # Original API-Responses\n",
        "            \"processed_content\",       # Verarbeitete Inhalte pro Kategorie\n",
        "            \"queries\",                 # Verwendete Queries und Templates\n",
        "            \"metadata\",               # Content-Metadaten und Mappings\n",
        "            \"final_newsletter\",       # Finaler Newsletter in verschiedenen Formaten\n",
        "            \"logs\",                   # Session-spezifische Logs\n",
        "            \"fact_check\"              # F√ºr sp√§tere Fact-Check Funktionen\n",
        "        ]\n",
        "\n",
        "        for folder in folders:\n",
        "            folder_path = self.session_path / folder\n",
        "            folder_path.mkdir(exist_ok=True)\n",
        "\n",
        "        print(f\"‚úÖ Session-Struktur erstellt: {len(folders)} Ordner\")\n",
        "\n",
        "    # =========================================================================\n",
        "    # RAW RESPONSE SPEICHERUNG\n",
        "    # =========================================================================\n",
        "\n",
        "    def save_raw_response(self, source, response, query=None, category=None, metadata=None):\n",
        "        \"\"\"\n",
        "        Speichert originale API-Response f√ºr Nachvollziehbarkeit\n",
        "\n",
        "        Args:\n",
        "            source: API-Quelle (\"claude_search\", \"perplexity\", \"firecrawl_scrape\", etc.)\n",
        "            response: Original API-Response (dict, object, oder string)\n",
        "            query: Verwendete Query (optional)\n",
        "            category: Newsletter-Kategorie (optional)\n",
        "            metadata: Zus√§tzliche Metadaten (optional)\n",
        "\n",
        "        Returns:\n",
        "            str: Dateiname der gespeicherten Response\n",
        "        \"\"\"\n",
        "        self.api_call_counter += 1\n",
        "        call_id = f\"{self.api_call_counter:03d}\"\n",
        "\n",
        "        # Filename generieren\n",
        "        timestamp = datetime.now().strftime('%H-%M-%S')\n",
        "        if category:\n",
        "            filename = f\"{call_id}_{source}_{category}_{timestamp}.json\"\n",
        "        else:\n",
        "            filename = f\"{call_id}_{source}_{timestamp}.json\"\n",
        "\n",
        "        filepath = self.session_path / \"raw_responses\" / filename\n",
        "\n",
        "        # Response-Daten strukturieren\n",
        "        response_data = {\n",
        "            \"call_id\": call_id,\n",
        "            \"timestamp\": datetime.now().isoformat(),\n",
        "            \"source\": source,\n",
        "            \"category\": category,\n",
        "            \"query\": query,\n",
        "            \"metadata\": metadata or {},\n",
        "            \"response\": self._serialize_response(response)\n",
        "        }\n",
        "\n",
        "        # Als JSON speichern\n",
        "        try:\n",
        "            with open(filepath, 'w', encoding='utf-8') as f:\n",
        "                json.dump(response_data, f, indent=2, ensure_ascii=False, default=str)\n",
        "\n",
        "            print(f\"üíæ Raw Response gespeichert: {filename}\")\n",
        "\n",
        "            # Session-Meta aktualisieren\n",
        "            self.session_meta[\"api_calls\"] = self.api_call_counter\n",
        "\n",
        "            return filename\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Fehler beim Speichern von Raw Response: {e}\")\n",
        "            return None\n",
        "\n",
        "    def _serialize_response(self, response):\n",
        "        \"\"\"Konvertiert verschiedene Response-Formate zu serialisierbaren Daten\"\"\"\n",
        "\n",
        "        if isinstance(response, (dict, list, str, int, float, bool)):\n",
        "            return response\n",
        "\n",
        "        # Objekt mit Attributen\n",
        "        elif hasattr(response, '__dict__'):\n",
        "            try:\n",
        "                return {\n",
        "                    \"_type\": str(type(response)),\n",
        "                    \"_attributes\": {k: self._serialize_response(v) for k, v in response.__dict__.items()}\n",
        "                }\n",
        "            except:\n",
        "                return {\"_type\": str(type(response)), \"_str\": str(response)}\n",
        "\n",
        "        # Fallback: String-Repr√§sentation\n",
        "        else:\n",
        "            return {\"_type\": str(type(response)), \"_str\": str(response)}\n",
        "\n",
        "    # =========================================================================\n",
        "    # PROCESSED CONTENT SPEICHERUNG\n",
        "    # =========================================================================\n",
        "\n",
        "    def save_processed_content(self, category, content, content_type=\"markdown\", metadata=None):\n",
        "        \"\"\"\n",
        "        Speichert verarbeiteten Content pro Kategorie\n",
        "\n",
        "        Args:\n",
        "            category: Newsletter-Kategorie\n",
        "            content: Verarbeiteter Content\n",
        "            content_type: Format (\"markdown\", \"json\", \"text\")\n",
        "            metadata: Content-Metadaten\n",
        "\n",
        "        Returns:\n",
        "            str: Pfad zur gespeicherten Datei\n",
        "        \"\"\"\n",
        "        timestamp = datetime.now().strftime('%H-%M-%S')\n",
        "\n",
        "        # Dateiname basierend auf Typ\n",
        "        if content_type == \"markdown\":\n",
        "            filename = f\"{category}_{timestamp}.md\"\n",
        "        elif content_type == \"json\":\n",
        "            filename = f\"{category}_{timestamp}.json\"\n",
        "        else:\n",
        "            filename = f\"{category}_{timestamp}.txt\"\n",
        "\n",
        "        filepath = self.session_path / \"processed_content\" / filename\n",
        "\n",
        "        try:\n",
        "            # Content je nach Typ speichern\n",
        "            if content_type == \"markdown\" or content_type == \"text\":\n",
        "                with open(filepath, 'w', encoding='utf-8') as f:\n",
        "                    if isinstance(content, str):\n",
        "                        f.write(content)\n",
        "                    else:\n",
        "                        f.write(str(content))\n",
        "\n",
        "            elif content_type == \"json\":\n",
        "                with open(filepath, 'w', encoding='utf-8') as f:\n",
        "                    json.dump(content, f, indent=2, ensure_ascii=False, default=str)\n",
        "\n",
        "            # Metadaten-Datei erstellen\n",
        "            if metadata:\n",
        "                meta_filepath = self.session_path / \"metadata\" / f\"{category}_{timestamp}_meta.json\"\n",
        "                with open(meta_filepath, 'w', encoding='utf-8') as f:\n",
        "                    json.dump(metadata, f, indent=2, ensure_ascii=False, default=str)\n",
        "\n",
        "            print(f\"üìÑ Processed Content gespeichert: {filename}\")\n",
        "\n",
        "            # Content Registry aktualisieren\n",
        "            content_item = {\n",
        "                \"category\": category,\n",
        "                \"filename\": filename,\n",
        "                \"filepath\": str(filepath),\n",
        "                \"content_type\": content_type,\n",
        "                \"timestamp\": datetime.now().isoformat(),\n",
        "                \"size_chars\": len(content) if isinstance(content, str) else 0,\n",
        "                \"has_metadata\": metadata is not None\n",
        "            }\n",
        "            self.content_registry.append(content_item)\n",
        "\n",
        "            # Session-Meta aktualisieren\n",
        "            if category not in self.session_meta[\"categories_processed\"]:\n",
        "                self.session_meta[\"categories_processed\"].append(category)\n",
        "            self.session_meta[\"total_content_items\"] = len(self.content_registry)\n",
        "\n",
        "            return str(filepath)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Fehler beim Speichern von Processed Content: {e}\")\n",
        "            return None\n",
        "\n",
        "    # =========================================================================\n",
        "    # QUERY TRACKING\n",
        "    # =========================================================================\n",
        "\n",
        "    def save_query_log(self, category, api, original_query, enhanced_query, time_context=None):\n",
        "        \"\"\"\n",
        "        Speichert Query-Historie f√ºr Nachvollziehbarkeit\n",
        "\n",
        "        Args:\n",
        "            category: Newsletter-Kategorie\n",
        "            api: Verwendete API\n",
        "            original_query: Original Template\n",
        "            enhanced_query: Final verwendete Query\n",
        "            time_context: Zeit-Kontext Information\n",
        "\n",
        "        Returns:\n",
        "            str: Query-Log ID\n",
        "        \"\"\"\n",
        "        query_id = str(uuid.uuid4())[:8]\n",
        "        timestamp = datetime.now()\n",
        "\n",
        "        query_log = {\n",
        "            \"query_id\": query_id,\n",
        "            \"timestamp\": timestamp.isoformat(),\n",
        "            \"category\": category,\n",
        "            \"api\": api,\n",
        "            \"original_query\": original_query,\n",
        "            \"enhanced_query\": enhanced_query,\n",
        "            \"time_context\": time_context,\n",
        "            \"location\": self.location\n",
        "        }\n",
        "\n",
        "        # Query-Log speichern\n",
        "        filename = f\"queries_{timestamp.strftime('%H-%M-%S')}_{category}_{api}.json\"\n",
        "        filepath = self.session_path / \"queries\" / filename\n",
        "\n",
        "        try:\n",
        "            with open(filepath, 'w', encoding='utf-8') as f:\n",
        "                json.dump(query_log, f, indent=2, ensure_ascii=False, default=str)\n",
        "\n",
        "            print(f\"üîç Query-Log gespeichert: {query_id}\")\n",
        "            return query_id\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Fehler beim Speichern von Query-Log: {e}\")\n",
        "            return None\n",
        "\n",
        "    # =========================================================================\n",
        "    # NEWSLETTER SPEICHERUNG\n",
        "    # =========================================================================\n",
        "\n",
        "    def save_final_newsletter(self, newsletter_content, format=\"markdown\", metadata=None):\n",
        "        \"\"\"\n",
        "        Speichert finalen Newsletter\n",
        "\n",
        "        Args:\n",
        "            newsletter_content: Newsletter-Inhalt\n",
        "            format: Ausgabeformat (\"markdown\", \"html\", \"json\")\n",
        "            metadata: Newsletter-Metadaten\n",
        "\n",
        "        Returns:\n",
        "            str: Pfad zur Newsletter-Datei\n",
        "        \"\"\"\n",
        "        timestamp = datetime.now().strftime('%Y-%m-%d_%H-%M')\n",
        "\n",
        "        # Filename basierend auf Format\n",
        "        if format == \"markdown\":\n",
        "            filename = f\"newsletter_{self.location}_{timestamp}.md\"\n",
        "        elif format == \"html\":\n",
        "            filename = f\"newsletter_{self.location}_{timestamp}.html\"\n",
        "        elif format == \"json\":\n",
        "            filename = f\"newsletter_{self.location}_{timestamp}.json\"\n",
        "        else:\n",
        "            filename = f\"newsletter_{self.location}_{timestamp}.txt\"\n",
        "\n",
        "        filepath = self.session_path / \"final_newsletter\" / filename\n",
        "\n",
        "        try:\n",
        "            # Newsletter speichern\n",
        "            if format in [\"markdown\", \"html\", \"text\"]:\n",
        "                with open(filepath, 'w', encoding='utf-8') as f:\n",
        "                    f.write(newsletter_content)\n",
        "            elif format == \"json\":\n",
        "                with open(filepath, 'w', encoding='utf-8') as f:\n",
        "                    json.dump(newsletter_content, f, indent=2, ensure_ascii=False, default=str)\n",
        "\n",
        "            # Newsletter-Metadaten speichern\n",
        "            if metadata:\n",
        "                meta_filepath = self.session_path / \"final_newsletter\" / f\"newsletter_meta_{timestamp}.json\"\n",
        "                with open(meta_filepath, 'w', encoding='utf-8') as f:\n",
        "                    json.dump(metadata, f, indent=2, ensure_ascii=False, default=str)\n",
        "\n",
        "            print(f\"üì∞ Newsletter gespeichert: {filename}\")\n",
        "\n",
        "            # Session-Meta aktualisieren\n",
        "            self.session_meta[\"newsletter_generated\"] = True\n",
        "            self.session_meta[\"newsletter_file\"] = filename\n",
        "\n",
        "            return str(filepath)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Fehler beim Speichern des Newsletters: {e}\")\n",
        "            return None\n",
        "\n",
        "    # =========================================================================\n",
        "    # SESSION MANAGEMENT\n",
        "    # =========================================================================\n",
        "\n",
        "    def save_session_meta(self):\n",
        "        \"\"\"Speichert Session-Metadaten\"\"\"\n",
        "        meta_filepath = self.session_path / \"session_meta.json\"\n",
        "\n",
        "        # Session-Meta mit aktuellen Werten aktualisieren\n",
        "        self.session_meta.update({\n",
        "            \"last_updated\": datetime.now().isoformat(),\n",
        "            \"status\": \"completed\" if self.session_meta[\"newsletter_generated\"] else \"active\"\n",
        "        })\n",
        "\n",
        "        try:\n",
        "            with open(meta_filepath, 'w', encoding='utf-8') as f:\n",
        "                json.dump(self.session_meta, f, indent=2, ensure_ascii=False, default=str)\n",
        "\n",
        "            print(f\"üìä Session-Meta gespeichert: {self.session_id}\")\n",
        "            return str(meta_filepath)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Fehler beim Speichern der Session-Meta: {e}\")\n",
        "            return None\n",
        "\n",
        "    def get_session_summary(self):\n",
        "        \"\"\"Gibt Session-Zusammenfassung zur√ºck\"\"\"\n",
        "        return {\n",
        "            \"session_id\": self.session_id,\n",
        "            \"location\": self.location,\n",
        "            \"created_at\": self.session_meta[\"created_at\"],\n",
        "            \"api_calls\": self.session_meta[\"api_calls\"],\n",
        "            \"categories_processed\": self.session_meta[\"categories_processed\"],\n",
        "            \"total_content_items\": self.session_meta[\"total_content_items\"],\n",
        "            \"newsletter_generated\": self.session_meta[\"newsletter_generated\"],\n",
        "            \"session_path\": str(self.session_path)\n",
        "        }\n",
        "\n",
        "    # =========================================================================\n",
        "    # CONTENT RETRIEVAL\n",
        "    # =========================================================================\n",
        "\n",
        "    def get_content_for_category(self, category):\n",
        "        \"\"\"L√§dt gespeicherten Content f√ºr eine Kategorie\"\"\"\n",
        "        category_content = []\n",
        "\n",
        "        for item in self.content_registry:\n",
        "            if item[\"category\"] == category:\n",
        "                try:\n",
        "                    filepath = Path(item[\"filepath\"])\n",
        "                    if filepath.exists():\n",
        "                        if item[\"content_type\"] == \"json\":\n",
        "                            with open(filepath, 'r', encoding='utf-8') as f:\n",
        "                                content = json.load(f)\n",
        "                        else:\n",
        "                            with open(filepath, 'r', encoding='utf-8') as f:\n",
        "                                content = f.read()\n",
        "\n",
        "                        category_content.append({\n",
        "                            \"content\": content,\n",
        "                            \"metadata\": item\n",
        "                        })\n",
        "                except Exception as e:\n",
        "                    print(f\"‚ùå Fehler beim Laden von {item['filename']}: {e}\")\n",
        "\n",
        "        return category_content\n",
        "\n",
        "    def get_all_raw_responses(self):\n",
        "        \"\"\"L√§dt alle Raw API-Responses f√ºr Analyse\"\"\"\n",
        "        raw_responses = []\n",
        "        raw_path = self.session_path / \"raw_responses\"\n",
        "\n",
        "        if raw_path.exists():\n",
        "            for file in raw_path.glob(\"*.json\"):\n",
        "                try:\n",
        "                    with open(file, 'r', encoding='utf-8') as f:\n",
        "                        response_data = json.load(f)\n",
        "                        raw_responses.append(response_data)\n",
        "                except Exception as e:\n",
        "                    print(f\"‚ùå Fehler beim Laden von {file.name}: {e}\")\n",
        "\n",
        "        return raw_responses\n",
        "\n",
        "    # =========================================================================\n",
        "    # CLEANUP & ARCHIVAL\n",
        "    # =========================================================================\n",
        "\n",
        "    def finalize_session(self):\n",
        "        \"\"\"Schlie√üt Session ab und archiviert\"\"\"\n",
        "        print(f\"üèÅ Finalisiere Session: {self.session_id}\")\n",
        "\n",
        "        # Session-Meta aktualisieren\n",
        "        self.session_meta[\"status\"] = \"completed\"\n",
        "        self.session_meta[\"completed_at\"] = datetime.now().isoformat()\n",
        "\n",
        "        # Finale Session-Meta speichern\n",
        "        self.save_session_meta()\n",
        "\n",
        "        # Session-Summary erstellen\n",
        "        summary = self.get_session_summary()\n",
        "\n",
        "        print(f\"üìä SESSION ABGESCHLOSSEN\")\n",
        "        print(f\"   API Calls: {summary['api_calls']}\")\n",
        "        print(f\"   Kategorien: {len(summary['categories_processed'])}\")\n",
        "        print(f\"   Content Items: {summary['total_content_items']}\")\n",
        "        print(f\"   Newsletter: {'‚úÖ' if summary['newsletter_generated'] else '‚ùå'}\")\n",
        "\n",
        "        return summary\n",
        "\n",
        "# =============================================================================\n",
        "# DEMO UND TESTS\n",
        "# =============================================================================\n",
        "\n",
        "# Demo DataPersistenceManager\n",
        "print(\"üß™ TESTE DATAPERSISTENCEMANAGER\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "try:\n",
        "    # Test-Session erstellen\n",
        "    test_location = \"m√ºnchen\"\n",
        "    persistence_manager = DataPersistenceManager(test_location)\n",
        "\n",
        "    print(f\"\\nüìä Session Summary:\")\n",
        "    summary = persistence_manager.get_session_summary()\n",
        "    for key, value in summary.items():\n",
        "        print(f\"  {key}: {value}\")\n",
        "\n",
        "    # Test 1: Raw Response speichern\n",
        "    print(f\"\\nüíæ Test 1: Raw Response Speichern\")\n",
        "    mock_response = {\n",
        "        \"data\": [\n",
        "            {\"title\": \"M√ºnchen Wetter heute\", \"url\": \"wetter.com\", \"content\": \"Sonnig, 25¬∞C\"},\n",
        "            {\"title\": \"Verkehr M√ºnchen\", \"url\": \"adac.de\", \"content\": \"A9 Stau\"}\n",
        "        ],\n",
        "        \"status\": \"success\"\n",
        "    }\n",
        "\n",
        "    saved_file = persistence_manager.save_raw_response(\n",
        "        source=\"firecrawl_search\",\n",
        "        response=mock_response,\n",
        "        query=\"M√ºnchen Wetter heute\",\n",
        "        category=\"wetter\",\n",
        "        metadata={\"api_version\": \"v1\", \"limit\": 3}\n",
        "    )\n",
        "\n",
        "    # Test 2: Processed Content speichern\n",
        "    print(f\"\\nüìÑ Test 2: Processed Content Speichern\")\n",
        "    processed_content = \"\"\"# Wetter in M√ºnchen\n",
        "\n",
        "## Heute\n",
        "- Sonnig und warm\n",
        "- Temperatur: 25¬∞C\n",
        "- Wind: 5 km/h\n",
        "\n",
        "## Vorhersage\n",
        "- Morgen: Teilweise bew√∂lkt\n",
        "- √úbermorgen: Regen m√∂glich\n",
        "\"\"\"\n",
        "\n",
        "    content_file = persistence_manager.save_processed_content(\n",
        "        category=\"wetter\",\n",
        "        content=processed_content,\n",
        "        content_type=\"markdown\",\n",
        "        metadata={\"sources\": 2, \"confidence\": \"high\"}\n",
        "    )\n",
        "\n",
        "    # Test 3: Query Log speichern\n",
        "    print(f\"\\nüîç Test 3: Query Log Speichern\")\n",
        "    query_id = persistence_manager.save_query_log(\n",
        "        category=\"wetter\",\n",
        "        api=\"claude_web\",\n",
        "        original_query=\"Wetter {location} {date_context}\",\n",
        "        enhanced_query=\"Wetter M√ºnchen heute aktuell Deutschland\",\n",
        "        time_context={\"timeframe\": \"heute\", \"date\": \"2025-07-20\"}\n",
        "    )\n",
        "\n",
        "    # Test 4: Newsletter speichern\n",
        "    print(f\"\\nüì∞ Test 4: Newsletter Speichern\")\n",
        "    mock_newsletter = \"\"\"# M√ºnchen Newsletter - 20.07.2025\n",
        "\n",
        "## Wetter\n",
        "Heute sonnig und warm mit 25¬∞C.\n",
        "\n",
        "## Verkehr\n",
        "Stau auf der A9 Richtung N√ºrnberg.\n",
        "\n",
        "## Events\n",
        "Sommerfest im Englischen Garten.\n",
        "\"\"\"\n",
        "\n",
        "    newsletter_file = persistence_manager.save_final_newsletter(\n",
        "        newsletter_content=mock_newsletter,\n",
        "        format=\"markdown\",\n",
        "        metadata={\n",
        "            \"generated_at\": datetime.now().isoformat(),\n",
        "            \"categories\": [\"wetter\", \"verkehr\", \"events\"],\n",
        "            \"word_count\": 25\n",
        "        }\n",
        "    )\n",
        "\n",
        "    # Test 5: Content retrieval\n",
        "    print(f\"\\nüìÇ Test 5: Content Retrieval\")\n",
        "    wetter_content = persistence_manager.get_content_for_category(\"wetter\")\n",
        "    print(f\"  Wetter Content Items: {len(wetter_content)}\")\n",
        "\n",
        "    raw_responses = persistence_manager.get_all_raw_responses()\n",
        "    print(f\"  Raw Responses: {len(raw_responses)}\")\n",
        "\n",
        "    # Test 6: Session finalisieren\n",
        "    print(f\"\\nüèÅ Test 6: Session Finalisieren\")\n",
        "    final_summary = persistence_manager.finalize_session()\n",
        "\n",
        "    print(f\"\\n‚úÖ Alle DataPersistenceManager Tests erfolgreich!\")\n",
        "    print(f\"üìÅ Session gespeichert unter: {persistence_manager.session_path}\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå DataPersistenceManager Test Fehler: {e}\")\n",
        "    import traceback\n",
        "    print(f\"üîç Traceback: {traceback.format_exc()}\")\n",
        "\n",
        "print(\"=\" * 50)\n",
        "print(\"‚úÖ DataPersistenceManager Setup komplett\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "id": "4iBb_WOHkDt9",
        "outputId": "3d980bf8-dac6-475d-ce66-312d4ee8c098"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üß™ TESTE DATAPERSISTENCEMANAGER\n",
            "==================================================\n",
            "‚úÖ Session-Struktur erstellt: 7 Ordner\n",
            "üíæ DataPersistenceManager initialisiert\n",
            "üìÅ Session: 2025-07-20_13-35_m√ºnchen\n",
            "üìç Location: m√ºnchen\n",
            "üóÇÔ∏è Session Path: /content/drive/MyDrive/Newsletter_System/data/sessions/2025-07-20_13-35_m√ºnchen\n",
            "\n",
            "üìä Session Summary:\n",
            "  session_id: 2025-07-20_13-35_m√ºnchen\n",
            "  location: m√ºnchen\n",
            "  created_at: 2025-07-20T13:35:42.087764\n",
            "  api_calls: 0\n",
            "  categories_processed: []\n",
            "  total_content_items: 0\n",
            "  newsletter_generated: False\n",
            "  session_path: /content/drive/MyDrive/Newsletter_System/data/sessions/2025-07-20_13-35_m√ºnchen\n",
            "\n",
            "üíæ Test 1: Raw Response Speichern\n",
            "üíæ Raw Response gespeichert: 001_firecrawl_search_wetter_13-35-42.json\n",
            "\n",
            "üìÑ Test 2: Processed Content Speichern\n",
            "üìÑ Processed Content gespeichert: wetter_13-35-42.md\n",
            "\n",
            "üîç Test 3: Query Log Speichern\n",
            "üîç Query-Log gespeichert: ed4b39b4\n",
            "\n",
            "üì∞ Test 4: Newsletter Speichern\n",
            "üì∞ Newsletter gespeichert: newsletter_m√ºnchen_2025-07-20_13-35.md\n",
            "\n",
            "üìÇ Test 5: Content Retrieval\n",
            "  Wetter Content Items: 1\n",
            "  Raw Responses: 1\n",
            "\n",
            "üèÅ Test 6: Session Finalisieren\n",
            "üèÅ Finalisiere Session: 2025-07-20_13-35_m√ºnchen\n",
            "üìä Session-Meta gespeichert: 2025-07-20_13-35_m√ºnchen\n",
            "üìä SESSION ABGESCHLOSSEN\n",
            "   API Calls: 1\n",
            "   Kategorien: 1\n",
            "   Content Items: 1\n",
            "   Newsletter: ‚úÖ\n",
            "\n",
            "‚úÖ Alle DataPersistenceManager Tests erfolgreich!\n",
            "üìÅ Session gespeichert unter: /content/drive/MyDrive/Newsletter_System/data/sessions/2025-07-20_13-35_m√ºnchen\n",
            "==================================================\n",
            "‚úÖ DataPersistenceManager Setup komplett\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# ZELLE 1: API Configuration\n",
        "# =============================================================================\n",
        "# @title API Keys Setup\n",
        "class APIConfig:\n",
        "    \"\"\"Zentrale API-Konfiguration mit Google Colab Secrets\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.firecrawl_key = None\n",
        "        self.claude_key = None\n",
        "        self.perplexity_key = None\n",
        "        self.gemini_key = None\n",
        "        self.groq_key = None\n",
        "\n",
        "    def load_keys(self):\n",
        "        \"\"\"L√§dt alle API Keys aus Google Colab Secrets\"\"\"\n",
        "        try:\n",
        "            self.firecrawl_key = userdata.get('FIRECRAWL_API')\n",
        "            self.claude_key = userdata.get('ANTHROPIC_API')\n",
        "            self.perplexity_key = userdata.get('PERPLEXITY_API_KEY')\n",
        "            self.gemini_key = userdata.get('GOOGLE_API_KEY')\n",
        "            self.groq_key = userdata.get('GROQ_API')\n",
        "\n",
        "            print(\"‚úÖ API Keys erfolgreich geladen:\")\n",
        "            print(f\"üï∑Ô∏è Firecrawl: {'‚úì' if self.firecrawl_key else '‚ùå'}\")\n",
        "            print(f\"ü§ñ Claude (Anthropic): {'‚úì' if self.claude_key else '‚ùå'}\")\n",
        "            print(f\"üîç Perplexity: {'‚úì' if self.perplexity_key else '‚ùå'}\")\n",
        "            print(f\"‚ú® Gemini (Google): {'‚úì' if self.gemini_key else '‚ùå'}\")\n",
        "            print(f\"‚ö° Groq: {'‚úì' if self.groq_key else '‚ùå'}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Fehler beim Laden der API Keys: {e}\")\n",
        "            print(\"üí° Tipp: Keys in Google Colab Secrets hinterlegen!\")\n",
        "\n",
        "    def get_keys_status(self):\n",
        "        \"\"\"Gibt Status aller Keys zur√ºck\"\"\"\n",
        "        return {\n",
        "            'firecrawl': bool(self.firecrawl_key),\n",
        "            'claude': bool(self.claude_key),\n",
        "            'perplexity': bool(self.perplexity_key),\n",
        "            'gemini': bool(self.gemini_key),\n",
        "            'groq': bool(self.groq_key)\n",
        "        }\n",
        "\n",
        "# API Config initialisieren\n",
        "api_config = APIConfig()\n",
        "api_config.load_keys()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aKzGp-mwYlqf",
        "outputId": "c83bc692-1151-4576-c6ff-76782f4682e0"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ API Keys erfolgreich geladen:\n",
            "üï∑Ô∏è Firecrawl: ‚úì\n",
            "ü§ñ Claude (Anthropic): ‚úì\n",
            "üîç Perplexity: ‚úì\n",
            "‚ú® Gemini (Google): ‚úì\n",
            "‚ö° Groq: ‚úì\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# ZELLE 2: Firecrawl Worker - Foundation-System Integration\n",
        "# =============================================================================\n",
        "# @title Firecrawl Worker - Mit ConfigManager + TimeContext + DataPersistence\n",
        "from firecrawl import FirecrawlApp, ScrapeOptions\n",
        "\n",
        "class FirecrawlWorkerV2:\n",
        "    \"\"\"\n",
        "    Firecrawl Worker V2 - Vollst√§ndig integriert mit Foundation-System\n",
        "    - ConfigManager f√ºr intelligente Queries\n",
        "    - TimeContextManager f√ºr Datums-Bewusstsein\n",
        "    - DataPersistenceManager f√ºr Audit-Trail\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, api_key, config_manager=None, time_manager=None, persistence_manager=None):\n",
        "        \"\"\"\n",
        "        Initialisiert Firecrawl Worker V2\n",
        "\n",
        "        Args:\n",
        "            api_key: Firecrawl API Key\n",
        "            config_manager: ConfigManager Instance\n",
        "            time_manager: TimeContextManager Instance\n",
        "            persistence_manager: DataPersistenceManager Instance\n",
        "        \"\"\"\n",
        "        self.app = FirecrawlApp(api_key=api_key)\n",
        "\n",
        "        # Foundation-System Integration\n",
        "        self.config_manager = config_manager\n",
        "        self.time_manager = time_manager\n",
        "        self.persistence_manager = persistence_manager\n",
        "\n",
        "        # Legacy Support falls Foundation nicht verf√ºgbar\n",
        "        self.has_foundation = all([config_manager, time_manager, persistence_manager])\n",
        "\n",
        "        # Worker State\n",
        "        self.results = {\n",
        "            \"search\": [],\n",
        "            \"scrape\": [],\n",
        "            \"crawl\": []\n",
        "        }\n",
        "\n",
        "        print(f\"‚úÖ Firecrawl Worker V2 initialisiert\")\n",
        "        print(f\"üèóÔ∏è Foundation Integration: {'‚úÖ' if self.has_foundation else '‚ùå'}\")\n",
        "\n",
        "        if self.has_foundation:\n",
        "            # API-Config aus ConfigManager holen\n",
        "            self.api_config = self.config_manager.get_api_config(\"firecrawl\")\n",
        "            self.default_location = self.api_config.get(\"location\", {\"country\": \"DE\", \"languages\": [\"de-DE\"]})\n",
        "            print(f\"‚öôÔ∏è API Config geladen: {len(self.api_config)} Parameter\")\n",
        "        else:\n",
        "            print(\"‚ö†Ô∏è L√§uft im Legacy-Modus ohne Foundation-System\")\n",
        "\n",
        "    # =========================================================================\n",
        "    # SEARCH - Foundation-System Integration\n",
        "    # =========================================================================\n",
        "\n",
        "    def search_with_foundation(self, category, location, timeframe=\"heute\", limit=None):\n",
        "        \"\"\"\n",
        "        Intelligente Search mit Foundation-System Integration\n",
        "\n",
        "        Args:\n",
        "            category: Newsletter-Kategorie (z.B. \"wetter\", \"events\")\n",
        "            location: Ortsname\n",
        "            timeframe: Zeitrahmen (default: optimal f√ºr Kategorie)\n",
        "            limit: Anzahl Ergebnisse (default: aus Config)\n",
        "\n",
        "        Returns:\n",
        "            dict: Strukturierte Search-Ergebnisse mit Metadaten\n",
        "        \"\"\"\n",
        "        if not self.has_foundation:\n",
        "            print(\"‚ùå Foundation-System erforderlich f√ºr diese Methode\")\n",
        "            return None\n",
        "\n",
        "        try:\n",
        "            # 1. Optimal Timeframe bestimmen\n",
        "            if timeframe == \"heute\":  # Auto-detect\n",
        "                timeframe = self.time_manager.get_optimal_timeframe_for_category(category)\n",
        "\n",
        "            # 2. Search Template aus Config holen\n",
        "            search_template = self.config_manager.get_search_template(category, \"firecrawl_search\", location)\n",
        "\n",
        "            # 3. Template mit Zeit-Kontext anreichern\n",
        "            enhanced_query = self.time_manager.inject_time_context(search_template, timeframe, \"firecrawl\")\n",
        "\n",
        "            # 4. API-Limits aus Config\n",
        "            if limit is None:\n",
        "                limit = self.config_manager.get_api_limits(\"firecrawl\", category)\n",
        "\n",
        "            # 5. Query Log speichern\n",
        "            query_id = self.persistence_manager.save_query_log(\n",
        "                category=category,\n",
        "                api=\"firecrawl_search\",\n",
        "                original_query=search_template,\n",
        "                enhanced_query=enhanced_query,\n",
        "                time_context=self.time_manager.get_time_context(timeframe, \"firecrawl\")\n",
        "            )\n",
        "\n",
        "            print(f\"üîç Firecrawl Search: {category} in {location}\")\n",
        "            print(f\"üìù Enhanced Query: {enhanced_query}\")\n",
        "            print(f\"‚è∞ Timeframe: {timeframe}\")\n",
        "            print(f\"üìä Limit: {limit}\")\n",
        "\n",
        "            # 6. Firecrawl Search durchf√ºhren\n",
        "            search_result = self.app.search(\n",
        "                query=enhanced_query,\n",
        "                limit=limit\n",
        "            )\n",
        "\n",
        "            # 7. Raw Response speichern\n",
        "            raw_filename = self.persistence_manager.save_raw_response(\n",
        "                source=\"firecrawl_search\",\n",
        "                response=search_result,\n",
        "                query=enhanced_query,\n",
        "                category=category,\n",
        "                metadata={\n",
        "                    \"query_id\": query_id,\n",
        "                    \"timeframe\": timeframe,\n",
        "                    \"location\": location,\n",
        "                    \"limit\": limit\n",
        "                }\n",
        "            )\n",
        "\n",
        "            # 8. Response verarbeiten\n",
        "            if hasattr(search_result, 'data') and search_result.data:\n",
        "                processed_result = {\n",
        "                    \"method\": \"search\",\n",
        "                    \"category\": category,\n",
        "                    \"location\": location,\n",
        "                    \"timeframe\": timeframe,\n",
        "                    \"query_id\": query_id,\n",
        "                    \"raw_filename\": raw_filename,\n",
        "                    \"results_count\": len(search_result.data),\n",
        "                    \"results\": search_result.data,\n",
        "                    \"timestamp\": datetime.now().isoformat()\n",
        "                }\n",
        "\n",
        "                self.results[\"search\"].append(processed_result)\n",
        "\n",
        "                print(f\"‚úÖ {len(search_result.data)} Suchergebnisse erhalten\")\n",
        "\n",
        "                # 9. Processed Content als Markdown speichern\n",
        "                markdown_content = self._format_search_results_as_markdown(processed_result)\n",
        "                content_filename = self.persistence_manager.save_processed_content(\n",
        "                    category=category,\n",
        "                    content=markdown_content,\n",
        "                    content_type=\"markdown\",\n",
        "                    metadata={\n",
        "                        \"query_id\": query_id,\n",
        "                        \"source\": \"firecrawl_search\",\n",
        "                        \"results_count\": len(search_result.data)\n",
        "                    }\n",
        "                )\n",
        "\n",
        "                processed_result[\"content_filename\"] = content_filename\n",
        "\n",
        "                # Preview anzeigen\n",
        "                for i, result in enumerate(search_result.data[:2]):\n",
        "                    if isinstance(result, dict):\n",
        "                        title = result.get('title', 'Kein Titel')\n",
        "                        url = result.get('url', 'Keine URL')\n",
        "                        print(f\"  {i+1}. {title[:60]}...\")\n",
        "                        print(f\"     üîó {url}\")\n",
        "\n",
        "                return processed_result\n",
        "            else:\n",
        "                print(\"‚ùå Keine Suchergebnisse erhalten\")\n",
        "                return None\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Firecrawl Search Fehler: {e}\")\n",
        "\n",
        "            # Fehler auch in Persistence speichern\n",
        "            if self.persistence_manager:\n",
        "                error_log = {\n",
        "                    \"error\": str(e),\n",
        "                    \"category\": category,\n",
        "                    \"location\": location,\n",
        "                    \"query\": enhanced_query if 'enhanced_query' in locals() else \"N/A\"\n",
        "                }\n",
        "                self.persistence_manager.save_raw_response(\n",
        "                    source=\"firecrawl_search_error\",\n",
        "                    response=error_log,\n",
        "                    category=category\n",
        "                )\n",
        "\n",
        "            return None\n",
        "\n",
        "    def _format_search_results_as_markdown(self, result):\n",
        "        \"\"\"Formatiert Search-Ergebnisse als Markdown f√ºr Speicherung\"\"\"\n",
        "\n",
        "        markdown = f\"# {result['category'].title()} - {result['location'].title()}\\n\\n\"\n",
        "        markdown += f\"**Generiert:** {result['timestamp']}\\n\"\n",
        "        markdown += f\"**Timeframe:** {result['timeframe']}\\n\"\n",
        "        markdown += f\"**Ergebnisse:** {result['results_count']}\\n\"\n",
        "        markdown += f\"**Query ID:** {result['query_id']}\\n\\n\"\n",
        "\n",
        "        markdown += \"## Suchergebnisse\\n\\n\"\n",
        "\n",
        "        for i, item in enumerate(result['results'], 1):\n",
        "            if isinstance(item, dict):\n",
        "                title = item.get('title', 'Kein Titel')\n",
        "                url = item.get('url', 'Keine URL')\n",
        "                description = item.get('description', 'Keine Beschreibung')\n",
        "\n",
        "                markdown += f\"### {i}. {title}\\n\\n\"\n",
        "                markdown += f\"**URL:** {url}\\n\\n\"\n",
        "\n",
        "                if description:\n",
        "                    markdown += f\"**Beschreibung:** {description}\\n\\n\"\n",
        "\n",
        "                # Content falls verf√ºgbar (bei Scraping)\n",
        "                if item.get('markdown'):\n",
        "                    content_preview = item['markdown'][:300] + \"...\" if len(item['markdown']) > 300 else item['markdown']\n",
        "                    markdown += f\"**Content Preview:**\\n```\\n{content_preview}\\n```\\n\\n\"\n",
        "\n",
        "                markdown += \"---\\n\\n\"\n",
        "\n",
        "        return markdown\n",
        "\n",
        "    # =========================================================================\n",
        "    # SCRAPE - Foundation-System Integration\n",
        "    # =========================================================================\n",
        "\n",
        "    def scrape_with_foundation(self, category, location, urls=None):\n",
        "        \"\"\"\n",
        "        Intelligente Scrape mit Foundation-System Integration\n",
        "\n",
        "        Args:\n",
        "            category: Newsletter-Kategorie\n",
        "            location: Ortsname\n",
        "            urls: URLs zum Scrapen (default: aus Config)\n",
        "\n",
        "        Returns:\n",
        "            dict: Strukturierte Scrape-Ergebnisse\n",
        "        \"\"\"\n",
        "        if not self.has_foundation:\n",
        "            print(\"‚ùå Foundation-System erforderlich f√ºr diese Methode\")\n",
        "            return None\n",
        "\n",
        "        try:\n",
        "            # 1. URLs aus Config holen falls nicht angegeben\n",
        "            if urls is None:\n",
        "                urls = self.config_manager.get_scrape_urls(category, location)\n",
        "\n",
        "            if not urls:\n",
        "                print(f\"‚ùå Keine Scrape-URLs f√ºr {category} in {location} konfiguriert\")\n",
        "                return None\n",
        "\n",
        "            # 2. Query Log f√ºr Scrape-Aktion\n",
        "            query_id = self.persistence_manager.save_query_log(\n",
        "                category=category,\n",
        "                api=\"firecrawl_scrape\",\n",
        "                original_query=f\"Scrape URLs for {category}\",\n",
        "                enhanced_query=f\"Scraping {len(urls)} URLs: {', '.join(urls[:2])}{'...' if len(urls) > 2 else ''}\",\n",
        "                time_context=self.time_manager.get_current_time_info()\n",
        "            )\n",
        "\n",
        "            print(f\"üï∑Ô∏è Firecrawl Scrape: {category} in {location}\")\n",
        "            print(f\"üìÑ URLs: {len(urls)}\")\n",
        "\n",
        "            scraped_data = []\n",
        "\n",
        "            # 3. URLs einzeln scrapen\n",
        "            for i, url in enumerate(urls):\n",
        "                try:\n",
        "                    print(f\"  üìÑ Scraping {i+1}/{len(urls)}: {url}\")\n",
        "\n",
        "                    scrape_result = self.app.scrape_url(\n",
        "                        url=url,\n",
        "                        formats=['markdown', 'links']\n",
        "                    )\n",
        "\n",
        "                    # Raw Response speichern\n",
        "                    raw_filename = self.persistence_manager.save_raw_response(\n",
        "                        source=\"firecrawl_scrape\",\n",
        "                        response=scrape_result,\n",
        "                        query=url,\n",
        "                        category=category,\n",
        "                        metadata={\n",
        "                            \"query_id\": query_id,\n",
        "                            \"url_index\": i,\n",
        "                            \"location\": location\n",
        "                        }\n",
        "                    )\n",
        "\n",
        "                    # Response verarbeiten\n",
        "                    if hasattr(scrape_result, 'markdown') and scrape_result.markdown:\n",
        "                        scraped_item = {\n",
        "                            \"url\": url,\n",
        "                            \"content\": scrape_result.markdown,\n",
        "                            \"links\": getattr(scrape_result, 'links', []),\n",
        "                            \"metadata\": getattr(scrape_result, 'metadata', {}),\n",
        "                            \"title\": getattr(scrape_result, 'title', ''),\n",
        "                            \"description\": getattr(scrape_result, 'description', ''),\n",
        "                            \"raw_filename\": raw_filename,\n",
        "                            \"timestamp\": datetime.now().isoformat()\n",
        "                        }\n",
        "                        scraped_data.append(scraped_item)\n",
        "\n",
        "                        print(f\"    ‚úÖ {len(scrape_result.markdown)} Zeichen Content\")\n",
        "                    else:\n",
        "                        print(f\"    ‚ùå Kein Content von {url}\")\n",
        "\n",
        "                except Exception as url_error:\n",
        "                    print(f\"    ‚ùå Fehler bei {url}: {url_error}\")\n",
        "                    continue\n",
        "\n",
        "            # 4. Ergebnisse strukturieren\n",
        "            if scraped_data:\n",
        "                processed_result = {\n",
        "                    \"method\": \"scrape\",\n",
        "                    \"category\": category,\n",
        "                    \"location\": location,\n",
        "                    \"query_id\": query_id,\n",
        "                    \"urls_count\": len(urls),\n",
        "                    \"successful_scrapes\": len(scraped_data),\n",
        "                    \"scraped_data\": scraped_data,\n",
        "                    \"timestamp\": datetime.now().isoformat()\n",
        "                }\n",
        "\n",
        "                self.results[\"scrape\"].append(processed_result)\n",
        "\n",
        "                # 5. Processed Content als Markdown speichern\n",
        "                markdown_content = self._format_scrape_results_as_markdown(processed_result)\n",
        "                content_filename = self.persistence_manager.save_processed_content(\n",
        "                    category=category,\n",
        "                    content=markdown_content,\n",
        "                    content_type=\"markdown\",\n",
        "                    metadata={\n",
        "                        \"query_id\": query_id,\n",
        "                        \"source\": \"firecrawl_scrape\",\n",
        "                        \"urls_scraped\": len(scraped_data)\n",
        "                    }\n",
        "                )\n",
        "\n",
        "                processed_result[\"content_filename\"] = content_filename\n",
        "\n",
        "                print(f\"‚úÖ {len(scraped_data)}/{len(urls)} URLs erfolgreich gescrapt\")\n",
        "                return processed_result\n",
        "            else:\n",
        "                print(\"‚ùå Keine URLs erfolgreich gescrapt\")\n",
        "                return None\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Firecrawl Scrape Fehler: {e}\")\n",
        "            return None\n",
        "\n",
        "    def _format_scrape_results_as_markdown(self, result):\n",
        "        \"\"\"Formatiert Scrape-Ergebnisse als Markdown\"\"\"\n",
        "\n",
        "        markdown = f\"# {result['category'].title()} - {result['location'].title()} (Scraped)\\n\\n\"\n",
        "        markdown += f\"**Generiert:** {result['timestamp']}\\n\"\n",
        "        markdown += f\"**URLs gescrapt:** {result['successful_scrapes']}/{result['urls_count']}\\n\"\n",
        "        markdown += f\"**Query ID:** {result['query_id']}\\n\\n\"\n",
        "\n",
        "        for i, item in enumerate(result['scraped_data'], 1):\n",
        "            title = item.get('title', f\"Seite {i}\")\n",
        "            url = item['url']\n",
        "            content = item['content']\n",
        "\n",
        "            markdown += f\"## {i}. {title}\\n\\n\"\n",
        "            markdown += f\"**URL:** {url}\\n\\n\"\n",
        "\n",
        "            if item.get('description'):\n",
        "                markdown += f\"**Beschreibung:** {item['description']}\\n\\n\"\n",
        "\n",
        "            # Content Preview (erste 500 Zeichen)\n",
        "            content_preview = content[:500] + \"...\" if len(content) > 500 else content\n",
        "            markdown += f\"**Content:**\\n```markdown\\n{content_preview}\\n```\\n\\n\"\n",
        "\n",
        "            # Links falls verf√ºgbar\n",
        "            if item.get('links') and len(item['links']) > 0:\n",
        "                markdown += f\"**Links gefunden:** {len(item['links'])}\\n\"\n",
        "                for link in item['links'][:5]:  # Erste 5 Links\n",
        "                    markdown += f\"- {link}\\n\"\n",
        "                markdown += \"\\n\"\n",
        "\n",
        "            markdown += \"---\\n\\n\"\n",
        "\n",
        "        return markdown\n",
        "\n",
        "    # =========================================================================\n",
        "    # NEWSLETTER INTEGRATION\n",
        "    # =========================================================================\n",
        "\n",
        "    def process_category_for_newsletter(self, category, location):\n",
        "        \"\"\"\n",
        "        Verarbeitet eine Kategorie komplett f√ºr Newsletter-Generation\n",
        "        W√§hlt automatisch beste Methode (Search/Scrape) basierend auf Config\n",
        "\n",
        "        Args:\n",
        "            category: Newsletter-Kategorie\n",
        "            location: Ortsname\n",
        "\n",
        "        Returns:\n",
        "            dict: Vollst√§ndig verarbeitete Kategorie-Daten\n",
        "        \"\"\"\n",
        "        if not self.has_foundation:\n",
        "            print(\"‚ùå Foundation-System erforderlich\")\n",
        "            return None\n",
        "\n",
        "        # Beste Methode aus Config bestimmen\n",
        "        method = self.config_manager.get_category_method(category)\n",
        "\n",
        "        print(f\"üéØ Verarbeite {category} f√ºr {location} via {method}\")\n",
        "\n",
        "        if method == \"search\":\n",
        "            return self.search_with_foundation(category, location)\n",
        "        elif method == \"scrape\":\n",
        "            return self.scrape_with_foundation(category, location)\n",
        "        else:\n",
        "            print(f\"‚ùå Unbekannte Methode: {method}\")\n",
        "            return None\n",
        "\n",
        "    def get_newsletter_summary_for_location(self, location):\n",
        "        \"\"\"Gibt Zusammenfassung aller Daten f√ºr einen Ort zur√ºck\"\"\"\n",
        "\n",
        "        summary = {\n",
        "            \"location\": location,\n",
        "            \"timestamp\": datetime.now().isoformat(),\n",
        "            \"search_results\": [],\n",
        "            \"scrape_results\": [],\n",
        "            \"total_content_items\": 0\n",
        "        }\n",
        "\n",
        "        # Search Results f√ºr Location\n",
        "        for result in self.results[\"search\"]:\n",
        "            if result[\"location\"].lower() == location.lower():\n",
        "                summary[\"search_results\"].append({\n",
        "                    \"category\": result[\"category\"],\n",
        "                    \"results_count\": result[\"results_count\"],\n",
        "                    \"timeframe\": result[\"timeframe\"],\n",
        "                    \"content_filename\": result.get(\"content_filename\")\n",
        "                })\n",
        "\n",
        "        # Scrape Results f√ºr Location\n",
        "        for result in self.results[\"scrape\"]:\n",
        "            if result[\"location\"].lower() == location.lower():\n",
        "                summary[\"scrape_results\"].append({\n",
        "                    \"category\": result[\"category\"],\n",
        "                    \"successful_scrapes\": result[\"successful_scrapes\"],\n",
        "                    \"content_filename\": result.get(\"content_filename\")\n",
        "                })\n",
        "\n",
        "        summary[\"total_content_items\"] = len(summary[\"search_results\"]) + len(summary[\"scrape_results\"])\n",
        "\n",
        "        return summary\n",
        "\n",
        "# =============================================================================\n",
        "# INITIALISIERUNG MIT FOUNDATION-SYSTEM\n",
        "# =============================================================================\n",
        "\n",
        "# Firecrawl Worker V2 mit Foundation-System initialisieren\n",
        "if api_config.firecrawl_key:\n",
        "    # Foundation-System Integration\n",
        "    foundation_available = all([\n",
        "        'config_manager' in globals() and config_manager,\n",
        "        'time_manager' in globals() and time_manager,\n",
        "        'persistence_manager' in globals() and persistence_manager\n",
        "    ])\n",
        "\n",
        "    if foundation_available:\n",
        "        firecrawl_worker_v2 = FirecrawlWorkerV2(\n",
        "            api_key=api_config.firecrawl_key,\n",
        "            config_manager=config_manager,\n",
        "            time_manager=time_manager,\n",
        "            persistence_manager=persistence_manager\n",
        "        )\n",
        "        print(\"üöÄ Firecrawl Worker V2 mit Foundation-System bereit\")\n",
        "    else:\n",
        "        # Fallback ohne Foundation\n",
        "        firecrawl_worker_v2 = FirecrawlWorkerV2(api_key=api_config.firecrawl_key)\n",
        "        print(\"‚ö†Ô∏è Firecrawl Worker V2 im Legacy-Modus (Foundation-System fehlt)\")\n",
        "\n",
        "else:\n",
        "    print(\"‚ùå Firecrawl Worker V2 nicht verf√ºgbar - API Key fehlt\")\n",
        "    firecrawl_worker_v2 = None\n",
        "\n",
        "# =============================================================================\n",
        "# DIREKTER TEST - Foundation-Integration\n",
        "# =============================================================================\n",
        "\n",
        "if firecrawl_worker_v2 and foundation_available:\n",
        "    print(\"\\nüß™ TESTE FIRECRAWL WORKER V2 MIT FOUNDATION-SYSTEM\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    try:\n",
        "        test_location = \"m√ºnchen\"\n",
        "\n",
        "        # Test 1: Search mit Foundation\n",
        "        print(\"üìç Test 1: Search mit Foundation-System\")\n",
        "        search_result = firecrawl_worker_v2.search_with_foundation(\n",
        "            category=\"wetter\",\n",
        "            location=test_location,\n",
        "            timeframe=\"heute\",\n",
        "            limit=3\n",
        "        )\n",
        "\n",
        "        if search_result:\n",
        "            print(f\"  ‚úÖ Search: {search_result['results_count']} Ergebnisse\")\n",
        "            print(f\"  üìÅ Content File: {search_result.get('content_filename', 'N/A')}\")\n",
        "            print(f\"  üÜî Query ID: {search_result['query_id']}\")\n",
        "\n",
        "        # Test 2: Scrape mit Foundation\n",
        "        print(f\"\\nüìç Test 2: Scrape mit Foundation-System\")\n",
        "        scrape_result = firecrawl_worker_v2.scrape_with_foundation(\n",
        "            category=\"rathaus\",\n",
        "            location=test_location\n",
        "        )\n",
        "\n",
        "        if scrape_result:\n",
        "            print(f\"  ‚úÖ Scrape: {scrape_result['successful_scrapes']} URLs\")\n",
        "            print(f\"  üìÅ Content File: {scrape_result.get('content_filename', 'N/A')}\")\n",
        "            print(f\"  üÜî Query ID: {scrape_result['query_id']}\")\n",
        "\n",
        "        # Test 3: Kategorie-Processing\n",
        "        print(f\"\\nüìç Test 3: Auto Kategorie-Processing\")\n",
        "        category_result = firecrawl_worker_v2.process_category_for_newsletter(\"events\", test_location)\n",
        "\n",
        "        if category_result:\n",
        "            print(f\"  ‚úÖ Events: {category_result['method']} erfolgreich\")\n",
        "\n",
        "        # Test 4: Newsletter Summary\n",
        "        print(f\"\\nüìç Test 4: Newsletter Summary\")\n",
        "        newsletter_summary = firecrawl_worker_v2.get_newsletter_summary_for_location(test_location)\n",
        "\n",
        "        print(f\"  üìä Location: {newsletter_summary['location']}\")\n",
        "        print(f\"  üîç Search Results: {len(newsletter_summary['search_results'])}\")\n",
        "        print(f\"  üï∑Ô∏è Scrape Results: {len(newsletter_summary['scrape_results'])}\")\n",
        "        print(f\"  üìÑ Total Content Items: {newsletter_summary['total_content_items']}\")\n",
        "\n",
        "        print(f\"\\n‚úÖ Alle Firecrawl Worker V2 Tests erfolgreich!\")\n",
        "\n",
        "    except Exception as test_error:\n",
        "        print(f\"‚ùå Test Fehler: {test_error}\")\n",
        "        import traceback\n",
        "        print(f\"üîç Traceback: {traceback.format_exc()}\")\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"‚úÖ Firecrawl Worker V2 Setup komplett\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "id": "l5ut3OsNZnVV",
        "outputId": "9d3f152b-8f14-47eb-ad39-e1a764389e54"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Firecrawl Worker V2 initialisiert\n",
            "üèóÔ∏è Foundation Integration: ‚úÖ\n",
            "‚öôÔ∏è API Config geladen: 4 Parameter\n",
            "üöÄ Firecrawl Worker V2 mit Foundation-System bereit\n",
            "\n",
            "üß™ TESTE FIRECRAWL WORKER V2 MIT FOUNDATION-SYSTEM\n",
            "============================================================\n",
            "üìç Test 1: Search mit Foundation-System\n",
            "üîç Query-Log gespeichert: d6edc04d\n",
            "üîç Firecrawl Search: wetter in m√ºnchen\n",
            "üìù Enhanced Query: Wetter m√ºnchen heute Vorhersage Deutschland\n",
            "‚è∞ Timeframe: heute\n",
            "üìä Limit: 3\n",
            "üíæ Raw Response gespeichert: 002_firecrawl_search_wetter_13-35-47.json\n",
            "‚úÖ 3 Suchergebnisse erhalten\n",
            "üìÑ Processed Content gespeichert: wetter_13-35-47.md\n",
            "  1. Wetter M√ºnchen heute - aktuelle Wettervorhersage f√ºr M√ºnchen...\n",
            "     üîó https://www.wetter.com/deutschland/muenchen/DE0006515.html\n",
            "  2. Wetter M√ºnchen heute Vorhersage 14 - 21 Tage | wetter.de...\n",
            "     üîó https://www.wetter.de/wetter/r/62428\n",
            "  ‚úÖ Search: 3 Ergebnisse\n",
            "  üìÅ Content File: /content/drive/MyDrive/Newsletter_System/data/sessions/2025-07-20_13-35_m√ºnchen/processed_content/wetter_13-35-47.md\n",
            "  üÜî Query ID: d6edc04d\n",
            "\n",
            "üìç Test 2: Scrape mit Foundation-System\n",
            "üîç Query-Log gespeichert: 77e26c48\n",
            "üï∑Ô∏è Firecrawl Scrape: rathaus in m√ºnchen\n",
            "üìÑ URLs: 3\n",
            "  üìÑ Scraping 1/3: https://www.muenchen.de/rathaus\n",
            "üíæ Raw Response gespeichert: 003_firecrawl_scrape_rathaus_13-35-52.json\n",
            "    ‚úÖ 9588 Zeichen Content\n",
            "  üìÑ Scraping 2/3: https://www.muenchen.de/aktuelles\n",
            "üíæ Raw Response gespeichert: 004_firecrawl_scrape_rathaus_13-35-57.json\n",
            "    ‚úÖ 895 Zeichen Content\n",
            "  üìÑ Scraping 3/3: https://www.stadt-muenchen.de\n",
            "    ‚ùå Fehler bei https://www.stadt-muenchen.de: Internal Server Error: Failed to scrape URL. (Internal server error) - An SSL error occurred while scraping the URL. If you're not inputting any sensitive data, try scraping with `skipTlsVerification: true`. - No additional error details provided.\n",
            "üìÑ Processed Content gespeichert: rathaus_13-36-00.md\n",
            "‚úÖ 2/3 URLs erfolgreich gescrapt\n",
            "  ‚úÖ Scrape: 2 URLs\n",
            "  üìÅ Content File: /content/drive/MyDrive/Newsletter_System/data/sessions/2025-07-20_13-35_m√ºnchen/processed_content/rathaus_13-36-00.md\n",
            "  üÜî Query ID: 77e26c48\n",
            "\n",
            "üìç Test 3: Auto Kategorie-Processing\n",
            "üéØ Verarbeite events f√ºr m√ºnchen via scrape\n",
            "üîç Query-Log gespeichert: 417bbae4\n",
            "üï∑Ô∏è Firecrawl Scrape: events in m√ºnchen\n",
            "üìÑ URLs: 2\n",
            "  üìÑ Scraping 1/2: https://www.muenchen.de/veranstaltungen\n",
            "üíæ Raw Response gespeichert: 005_firecrawl_scrape_events_13-36-04.json\n",
            "    ‚úÖ 11371 Zeichen Content\n",
            "  üìÑ Scraping 2/2: https://www.eventbrite.de/d/germany--muenchen/events/\n",
            "üíæ Raw Response gespeichert: 006_firecrawl_scrape_events_13-36-11.json\n",
            "    ‚úÖ 44469 Zeichen Content\n",
            "üìÑ Processed Content gespeichert: events_13-36-11.md\n",
            "‚úÖ 2/2 URLs erfolgreich gescrapt\n",
            "  ‚úÖ Events: scrape erfolgreich\n",
            "\n",
            "üìç Test 4: Newsletter Summary\n",
            "  üìä Location: m√ºnchen\n",
            "  üîç Search Results: 1\n",
            "  üï∑Ô∏è Scrape Results: 2\n",
            "  üìÑ Total Content Items: 3\n",
            "\n",
            "‚úÖ Alle Firecrawl Worker V2 Tests erfolgreich!\n",
            "============================================================\n",
            "‚úÖ Firecrawl Worker V2 Setup komplett\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# ZELLE 3: Claude Worker V2 - Foundation-System Integration\n",
        "# =============================================================================\n",
        "# @title Claude Worker V2 - Mit ConfigManager + TimeContext + DataPersistence + Web Search\n",
        "import anthropic\n",
        "\n",
        "class ClaudeWorkerV2:\n",
        "    \"\"\"\n",
        "    Claude Worker V2 - Vollst√§ndig integriert mit Foundation-System\n",
        "    - ConfigManager f√ºr intelligente Web Search Queries\n",
        "    - TimeContextManager f√ºr zeitliche Kontextualisierung\n",
        "    - DataPersistenceManager f√ºr Citation-Tracking und Audit-Trail\n",
        "    - Anthropic Web Search API f√ºr aktuelle Informationen\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, api_key, config_manager=None, time_manager=None, persistence_manager=None):\n",
        "        \"\"\"\n",
        "        Initialisiert Claude Worker V2\n",
        "\n",
        "        Args:\n",
        "            api_key: Anthropic API Key\n",
        "            config_manager: ConfigManager Instance\n",
        "            time_manager: TimeContextManager Instance\n",
        "            persistence_manager: DataPersistenceManager Instance\n",
        "        \"\"\"\n",
        "        self.client = anthropic.Anthropic(api_key=api_key)\n",
        "\n",
        "        # Foundation-System Integration\n",
        "        self.config_manager = config_manager\n",
        "        self.time_manager = time_manager\n",
        "        self.persistence_manager = persistence_manager\n",
        "\n",
        "        # Legacy Support falls Foundation nicht verf√ºgbar\n",
        "        self.has_foundation = all([config_manager, time_manager, persistence_manager])\n",
        "\n",
        "        # Worker State\n",
        "        self.search_results = []\n",
        "        self.citation_registry = {}  # Tracking aller Citations f√ºr Fact-Checking\n",
        "\n",
        "        print(f\"‚úÖ Claude Worker V2 initialisiert\")\n",
        "        print(f\"üèóÔ∏è Foundation Integration: {'‚úÖ' if self.has_foundation else '‚ùå'}\")\n",
        "\n",
        "        if self.has_foundation:\n",
        "            # API-Config aus ConfigManager holen\n",
        "            self.api_config = self.config_manager.get_api_config(\"claude\")\n",
        "            self.model = self.api_config.get(\"model\", \"claude-3-5-haiku-latest\")\n",
        "            self.web_search_config = self.api_config.get(\"web_search\", {})\n",
        "            print(f\"‚öôÔ∏è API Config geladen: Model {self.model}\")\n",
        "            print(f\"üîç Web Search Config: {len(self.web_search_config)} Parameter\")\n",
        "        else:\n",
        "            self.model = \"claude-3-5-haiku-latest\"\n",
        "            self.web_search_config = {}\n",
        "            print(\"‚ö†Ô∏è L√§uft im Legacy-Modus ohne Foundation-System\")\n",
        "\n",
        "    # =========================================================================\n",
        "    # WEB SEARCH - Foundation-System Integration\n",
        "    # =========================================================================\n",
        "\n",
        "    def web_search_with_foundation(self, category, location, timeframe=\"heute\", max_searches=None):\n",
        "        \"\"\"\n",
        "        Intelligente Web Search mit Foundation-System Integration\n",
        "\n",
        "        Args:\n",
        "            category: Newsletter-Kategorie (z.B. \"wetter\", \"events\")\n",
        "            location: Ortsname\n",
        "            timeframe: Zeitrahmen (default: optimal f√ºr Kategorie)\n",
        "            max_searches: Max Web Searches (default: aus Config)\n",
        "\n",
        "        Returns:\n",
        "            dict: Strukturierte Search-Ergebnisse mit Citations\n",
        "        \"\"\"\n",
        "        if not self.has_foundation:\n",
        "            print(\"‚ùå Foundation-System erforderlich f√ºr diese Methode\")\n",
        "            return None\n",
        "\n",
        "        try:\n",
        "            # 1. Optimal Timeframe bestimmen\n",
        "            if timeframe == \"heute\":  # Auto-detect\n",
        "                timeframe = self.time_manager.get_optimal_timeframe_for_category(category)\n",
        "\n",
        "            # 2. Search Template aus Config holen\n",
        "            search_template = self.config_manager.get_search_template(category, \"claude_web\", location)\n",
        "\n",
        "            # 3. Template mit Zeit-Kontext anreichern\n",
        "            enhanced_query = self.time_manager.inject_time_context(search_template, timeframe, \"claude_web\")\n",
        "\n",
        "            # 4. Web Search Parameter aus Config\n",
        "            if max_searches is None:\n",
        "                max_searches = self.web_search_config.get(\"max_uses\", 5)\n",
        "\n",
        "            # 5. User Location f√ºr Web Search\n",
        "            user_location = self.web_search_config.get(\"user_location\", {})\n",
        "            if location.lower() == \"m√ºnchen\":\n",
        "                user_location.update({\n",
        "                    \"city\": \"Munich\",\n",
        "                    \"region\": \"Bavaria\",\n",
        "                    \"country\": \"DE\"\n",
        "                })\n",
        "\n",
        "            # 6. Query Log speichern\n",
        "            query_id = self.persistence_manager.save_query_log(\n",
        "                category=category,\n",
        "                api=\"claude_web_search\",\n",
        "                original_query=search_template,\n",
        "                enhanced_query=enhanced_query,\n",
        "                time_context=self.time_manager.get_time_context(timeframe, \"claude_web\")\n",
        "            )\n",
        "\n",
        "            print(f\"üîç Claude Web Search: {category} in {location}\")\n",
        "            print(f\"üìù Enhanced Query: {enhanced_query}\")\n",
        "            print(f\"‚è∞ Timeframe: {timeframe}\")\n",
        "            print(f\"üåê Max Searches: {max_searches}\")\n",
        "\n",
        "            # 7. Web Search Tools konfigurieren\n",
        "            web_search_tool = {\n",
        "                \"type\": \"web_search_20250305\",\n",
        "                \"name\": \"web_search\",\n",
        "                \"max_uses\": max_searches\n",
        "            }\n",
        "\n",
        "            if user_location:\n",
        "                web_search_tool[\"user_location\"] = user_location\n",
        "\n",
        "            # 8. Claude API Call mit Web Search\n",
        "            response = self.client.messages.create(\n",
        "                model=self.model,\n",
        "                max_tokens=self.api_config.get(\"max_tokens\", 2000),\n",
        "                messages=[\n",
        "                    {\n",
        "                        \"role\": \"user\",\n",
        "                        \"content\": enhanced_query\n",
        "                    }\n",
        "                ],\n",
        "                tools=[web_search_tool]\n",
        "            )\n",
        "\n",
        "            # 9. Raw Response speichern\n",
        "            raw_filename = self.persistence_manager.save_raw_response(\n",
        "                source=\"claude_web_search\",\n",
        "                response=response,\n",
        "                query=enhanced_query,\n",
        "                category=category,\n",
        "                metadata={\n",
        "                    \"query_id\": query_id,\n",
        "                    \"timeframe\": timeframe,\n",
        "                    \"location\": location,\n",
        "                    \"model\": self.model,\n",
        "                    \"max_searches\": max_searches\n",
        "                }\n",
        "            )\n",
        "\n",
        "            # 10. Response verarbeiten\n",
        "            if response and response.content:\n",
        "                processed_result = self._process_claude_web_search_response(\n",
        "                    response, category, location, timeframe, query_id, raw_filename\n",
        "                )\n",
        "\n",
        "                if processed_result:\n",
        "                    self.search_results.append(processed_result)\n",
        "\n",
        "                    # 11. Processed Content als Markdown speichern\n",
        "                    markdown_content = self._format_claude_search_as_markdown(processed_result)\n",
        "                    content_filename = self.persistence_manager.save_processed_content(\n",
        "                        category=category,\n",
        "                        content=markdown_content,\n",
        "                        content_type=\"markdown\",\n",
        "                        metadata={\n",
        "                            \"query_id\": query_id,\n",
        "                            \"source\": \"claude_web_search\",\n",
        "                            \"citations_count\": len(processed_result.get(\"citations\", [])),\n",
        "                            \"web_searches_used\": processed_result.get(\"web_searches_used\", 0)\n",
        "                        }\n",
        "                    )\n",
        "\n",
        "                    processed_result[\"content_filename\"] = content_filename\n",
        "\n",
        "                    print(f\"‚úÖ Claude Web Search erfolgreich!\")\n",
        "                    print(f\"üìä Web Searches verwendet: {processed_result.get('web_searches_used', 0)}\")\n",
        "                    print(f\"üìö Citations: {len(processed_result.get('citations', []))}\")\n",
        "                    print(f\"üìù Content: {len(processed_result.get('text_content', ''))} Zeichen\")\n",
        "\n",
        "                    return processed_result\n",
        "\n",
        "            print(\"‚ùå Keine Response von Claude erhalten\")\n",
        "            return None\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Claude Web Search Fehler: {e}\")\n",
        "\n",
        "            # Fehler in Persistence speichern\n",
        "            if self.persistence_manager:\n",
        "                error_log = {\n",
        "                    \"error\": str(e),\n",
        "                    \"category\": category,\n",
        "                    \"location\": location,\n",
        "                    \"query\": enhanced_query if 'enhanced_query' in locals() else \"N/A\"\n",
        "                }\n",
        "                self.persistence_manager.save_raw_response(\n",
        "                    source=\"claude_web_search_error\",\n",
        "                    response=error_log,\n",
        "                    category=category\n",
        "                )\n",
        "\n",
        "            return None\n",
        "\n",
        "    def _process_claude_web_search_response(self, response, category, location, timeframe, query_id, raw_filename):\n",
        "        \"\"\"Verarbeitet Claude Web Search Response und extrahiert Citations\"\"\"\n",
        "\n",
        "        processed_result = {\n",
        "            \"method\": \"web_search\",\n",
        "            \"category\": category,\n",
        "            \"location\": location,\n",
        "            \"timeframe\": timeframe,\n",
        "            \"query_id\": query_id,\n",
        "            \"raw_filename\": raw_filename,\n",
        "            \"timestamp\": datetime.now().isoformat(),\n",
        "            \"text_content\": \"\",\n",
        "            \"citations\": [],\n",
        "            \"web_searches_used\": 0,\n",
        "            \"content_blocks\": []\n",
        "        }\n",
        "\n",
        "        # Content Blocks verarbeiten\n",
        "        for content_block in response.content:\n",
        "            block_info = {\n",
        "                \"type\": content_block.type,\n",
        "                \"content\": \"\"\n",
        "            }\n",
        "\n",
        "            if content_block.type == 'text':\n",
        "                # Text Content\n",
        "                block_info[\"content\"] = content_block.text\n",
        "                processed_result[\"text_content\"] += content_block.text + \"\\n\"\n",
        "\n",
        "                # Citations aus Text-Block extrahieren\n",
        "                if hasattr(content_block, 'citations') and content_block.citations:\n",
        "                    for citation in content_block.citations:\n",
        "                        citation_info = {\n",
        "                            \"type\": citation.type,\n",
        "                            \"url\": getattr(citation, 'url', ''),\n",
        "                            \"title\": getattr(citation, 'title', ''),\n",
        "                            \"cited_text\": getattr(citation, 'cited_text', '')\n",
        "                        }\n",
        "                        processed_result[\"citations\"].append(citation_info)\n",
        "\n",
        "                        # Citation Registry f√ºr Fact-Checking\n",
        "                        citation_id = f\"{query_id}_{len(processed_result['citations'])}\"\n",
        "                        self.citation_registry[citation_id] = {\n",
        "                            \"category\": category,\n",
        "                            \"location\": location,\n",
        "                            \"citation\": citation_info,\n",
        "                            \"query_id\": query_id,\n",
        "                            \"timestamp\": datetime.now().isoformat()\n",
        "                        }\n",
        "\n",
        "            elif content_block.type == 'server_tool_use':\n",
        "                # Web Search Tool Use\n",
        "                block_info[\"tool_name\"] = getattr(content_block, 'name', '')\n",
        "                block_info[\"tool_input\"] = getattr(content_block, 'input', {})\n",
        "\n",
        "            elif content_block.type == 'web_search_tool_result':\n",
        "                # Web Search Results\n",
        "                block_info[\"tool_use_id\"] = getattr(content_block, 'tool_use_id', '')\n",
        "                if hasattr(content_block, 'content'):\n",
        "                    block_info[\"search_results\"] = content_block.content\n",
        "\n",
        "            processed_result[\"content_blocks\"].append(block_info)\n",
        "\n",
        "        # Web Search Usage aus Response extrahieren\n",
        "        if hasattr(response, 'usage') and hasattr(response.usage, 'server_tool_use'):\n",
        "            server_tool_use = response.usage.server_tool_use\n",
        "            if hasattr(server_tool_use, 'web_search_requests'):\n",
        "                processed_result[\"web_searches_used\"] = server_tool_use.web_search_requests\n",
        "            elif isinstance(server_tool_use, dict):\n",
        "                processed_result[\"web_searches_used\"] = server_tool_use.get('web_search_requests', 0)\n",
        "\n",
        "        return processed_result\n",
        "\n",
        "    def _format_claude_search_as_markdown(self, result):\n",
        "        \"\"\"Formatiert Claude Web Search Ergebnisse als Markdown\"\"\"\n",
        "\n",
        "        markdown = f\"# {result['category'].title()} - {result['location'].title()} (Claude Web Search)\\n\\n\"\n",
        "        markdown += f\"**Generiert:** {result['timestamp']}\\n\"\n",
        "        markdown += f\"**Timeframe:** {result['timeframe']}\\n\"\n",
        "        markdown += f\"**Query ID:** {result['query_id']}\\n\"\n",
        "        markdown += f\"**Web Searches verwendet:** {result['web_searches_used']}\\n\"\n",
        "        markdown += f\"**Citations:** {len(result['citations'])}\\n\\n\"\n",
        "\n",
        "        # Haupt-Content\n",
        "        markdown += \"## Claude's Antwort\\n\\n\"\n",
        "        if result['text_content']:\n",
        "            markdown += result['text_content'] + \"\\n\\n\"\n",
        "\n",
        "        # Citations\n",
        "        if result['citations']:\n",
        "            markdown += \"## Quellen\\n\\n\"\n",
        "            for i, citation in enumerate(result['citations'], 1):\n",
        "                markdown += f\"**[{i}] {citation.get('title', 'Keine Titel')}**\\n\"\n",
        "                markdown += f\"URL: {citation.get('url', 'Keine URL')}\\n\"\n",
        "                if citation.get('cited_text'):\n",
        "                    markdown += f\"Zitiert: \\\"{citation['cited_text']}\\\"\\n\"\n",
        "                markdown += \"\\n\"\n",
        "\n",
        "        # Content Blocks (f√ºr Debugging)\n",
        "        if result.get('content_blocks'):\n",
        "            markdown += \"## Content Blocks (Debug)\\n\\n\"\n",
        "            for i, block in enumerate(result['content_blocks']):\n",
        "                markdown += f\"### Block {i+1}: {block['type']}\\n\"\n",
        "                if block['type'] == 'server_tool_use':\n",
        "                    markdown += f\"Tool: {block.get('tool_name', 'N/A')}\\n\"\n",
        "                    if block.get('tool_input'):\n",
        "                        markdown += f\"Input: {block['tool_input']}\\n\"\n",
        "                elif block['content']:\n",
        "                    content_preview = block['content'][:200] + \"...\" if len(block['content']) > 200 else block['content']\n",
        "                    markdown += f\"```\\n{content_preview}\\n```\\n\"\n",
        "                markdown += \"\\n\"\n",
        "\n",
        "        return markdown\n",
        "\n",
        "    # =========================================================================\n",
        "    # CATEGORY-SPECIFIC SEARCH\n",
        "    # =========================================================================\n",
        "\n",
        "    def search_specific_category(self, category, location, timeframe=None, focused_query=None):\n",
        "        \"\"\"\n",
        "        Kategorie-spezifische Suche mit optionalem focused Query\n",
        "\n",
        "        Args:\n",
        "            category: Newsletter-Kategorie\n",
        "            location: Ortsname\n",
        "            timeframe: Zeitrahmen (optional, sonst optimal f√ºr Kategorie)\n",
        "            focused_query: Spezielle Query statt Config-Template (optional)\n",
        "\n",
        "        Returns:\n",
        "            dict: Kategorie-spezifische Suchergebnisse\n",
        "        \"\"\"\n",
        "        if not self.has_foundation:\n",
        "            return self.web_search_with_foundation(category, location, timeframe or \"heute\")\n",
        "\n",
        "        # Timeframe automatisch bestimmen falls nicht angegeben\n",
        "        if timeframe is None:\n",
        "            timeframe = self.time_manager.get_optimal_timeframe_for_category(category)\n",
        "\n",
        "        # Focused Query oder Config Template verwenden\n",
        "        if focused_query:\n",
        "            enhanced_query = self.time_manager.inject_time_context(focused_query, timeframe, \"claude_web\")\n",
        "            print(f\"üéØ Focused Query: {focused_query}\")\n",
        "        else:\n",
        "            result = self.web_search_with_foundation(category, location, timeframe)\n",
        "            return result\n",
        "\n",
        "        # Custom Search durchf√ºhren\n",
        "        try:\n",
        "            query_id = self.persistence_manager.save_query_log(\n",
        "                category=category,\n",
        "                api=\"claude_web_focused\",\n",
        "                original_query=focused_query,\n",
        "                enhanced_query=enhanced_query,\n",
        "                time_context=self.time_manager.get_time_context(timeframe, \"claude_web\")\n",
        "            )\n",
        "\n",
        "            print(f\"üéØ Focused Claude Search: {category}\")\n",
        "            print(f\"üìù Enhanced Query: {enhanced_query}\")\n",
        "\n",
        "            # Reduzierte Web Search f√ºr focused Queries\n",
        "            web_search_tool = {\n",
        "                \"type\": \"web_search_20250305\",\n",
        "                \"name\": \"web_search\",\n",
        "                \"max_uses\": 3  # Weniger Searches f√ºr focused Queries\n",
        "            }\n",
        "\n",
        "            response = self.client.messages.create(\n",
        "                model=self.model,\n",
        "                max_tokens=1500,  # K√ºrzere Antworten f√ºr focused Queries\n",
        "                messages=[\n",
        "                    {\n",
        "                        \"role\": \"user\",\n",
        "                        \"content\": enhanced_query\n",
        "                    }\n",
        "                ],\n",
        "                tools=[web_search_tool]\n",
        "            )\n",
        "\n",
        "            # Response Processing wie bei web_search_with_foundation\n",
        "            if response and response.content:\n",
        "                processed_result = self._process_claude_web_search_response(\n",
        "                    response, category, location, timeframe, query_id, None\n",
        "                )\n",
        "\n",
        "                if processed_result:\n",
        "                    processed_result[\"search_type\"] = \"focused\"\n",
        "                    print(f\"‚úÖ Focused Search erfolgreich: {len(processed_result.get('text_content', ''))} Zeichen\")\n",
        "                    return processed_result\n",
        "\n",
        "            return None\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Focused Search Fehler: {e}\")\n",
        "            return None\n",
        "\n",
        "    # =========================================================================\n",
        "    # NEWSLETTER INTEGRATION\n",
        "    # =========================================================================\n",
        "\n",
        "    def process_category_for_newsletter(self, category, location):\n",
        "        \"\"\"\n",
        "        Verarbeitet eine Kategorie komplett f√ºr Newsletter-Generation\n",
        "        Nutzt immer Web Search (Claude's St√§rke)\n",
        "\n",
        "        Args:\n",
        "            category: Newsletter-Kategorie\n",
        "            location: Ortsname\n",
        "\n",
        "        Returns:\n",
        "            dict: Vollst√§ndig verarbeitete Kategorie-Daten\n",
        "        \"\"\"\n",
        "        print(f\"üéØ Verarbeite {category} f√ºr {location} via Claude Web Search\")\n",
        "\n",
        "        return self.web_search_with_foundation(category, location)\n",
        "\n",
        "    def get_citation_summary(self, location=None):\n",
        "        \"\"\"\n",
        "        Gibt Zusammenfassung aller Citations zur√ºck (f√ºr Fact-Checking)\n",
        "\n",
        "        Args:\n",
        "            location: Filter nach Location (optional)\n",
        "\n",
        "        Returns:\n",
        "            dict: Citation Summary\n",
        "        \"\"\"\n",
        "        filtered_citations = {}\n",
        "\n",
        "        if location:\n",
        "            for citation_id, citation_data in self.citation_registry.items():\n",
        "                if citation_data[\"location\"].lower() == location.lower():\n",
        "                    filtered_citations[citation_id] = citation_data\n",
        "        else:\n",
        "            filtered_citations = self.citation_registry\n",
        "\n",
        "        # Summary Statistics\n",
        "        summary = {\n",
        "            \"total_citations\": len(filtered_citations),\n",
        "            \"categories\": set(),\n",
        "            \"sources\": set(),\n",
        "            \"citations\": filtered_citations\n",
        "        }\n",
        "\n",
        "        for citation_data in filtered_citations.values():\n",
        "            summary[\"categories\"].add(citation_data[\"category\"])\n",
        "            if citation_data[\"citation\"].get(\"url\"):\n",
        "                summary[\"sources\"].add(citation_data[\"citation\"][\"url\"])\n",
        "\n",
        "        summary[\"categories\"] = list(summary[\"categories\"])\n",
        "        summary[\"sources\"] = list(summary[\"sources\"])\n",
        "\n",
        "        return summary\n",
        "\n",
        "    def get_newsletter_summary_for_location(self, location):\n",
        "        \"\"\"Gibt Zusammenfassung aller Claude-Daten f√ºr einen Ort zur√ºck\"\"\"\n",
        "\n",
        "        summary = {\n",
        "            \"location\": location,\n",
        "            \"timestamp\": datetime.now().isoformat(),\n",
        "            \"web_search_results\": [],\n",
        "            \"total_citations\": 0,\n",
        "            \"total_web_searches_used\": 0,\n",
        "            \"categories_processed\": set()\n",
        "        }\n",
        "\n",
        "        # Web Search Results f√ºr Location\n",
        "        for result in self.search_results:\n",
        "            if result[\"location\"].lower() == location.lower():\n",
        "                summary[\"web_search_results\"].append({\n",
        "                    \"category\": result[\"category\"],\n",
        "                    \"timeframe\": result[\"timeframe\"],\n",
        "                    \"citations_count\": len(result.get(\"citations\", [])),\n",
        "                    \"web_searches_used\": result.get(\"web_searches_used\", 0),\n",
        "                    \"content_filename\": result.get(\"content_filename\"),\n",
        "                    \"query_id\": result[\"query_id\"]\n",
        "                })\n",
        "\n",
        "                summary[\"total_citations\"] += len(result.get(\"citations\", []))\n",
        "                summary[\"total_web_searches_used\"] += result.get(\"web_searches_used\", 0)\n",
        "                summary[\"categories_processed\"].add(result[\"category\"])\n",
        "\n",
        "        summary[\"categories_processed\"] = list(summary[\"categories_processed\"])\n",
        "        summary[\"total_search_results\"] = len(summary[\"web_search_results\"])\n",
        "\n",
        "        return summary\n",
        "\n",
        "# =============================================================================\n",
        "# INITIALISIERUNG MIT FOUNDATION-SYSTEM\n",
        "# =============================================================================\n",
        "\n",
        "# Claude Worker V2 mit Foundation-System initialisieren\n",
        "if api_config.claude_key:\n",
        "    # Foundation-System Integration\n",
        "    foundation_available = all([\n",
        "        'config_manager' in globals() and config_manager,\n",
        "        'time_manager' in globals() and time_manager,\n",
        "        'persistence_manager' in globals() and persistence_manager\n",
        "    ])\n",
        "\n",
        "    if foundation_available:\n",
        "        claude_worker_v2 = ClaudeWorkerV2(\n",
        "            api_key=api_config.claude_key,\n",
        "            config_manager=config_manager,\n",
        "            time_manager=time_manager,\n",
        "            persistence_manager=persistence_manager\n",
        "        )\n",
        "        print(\"üöÄ Claude Worker V2 mit Foundation-System bereit\")\n",
        "    else:\n",
        "        # Fallback ohne Foundation\n",
        "        claude_worker_v2 = ClaudeWorkerV2(api_key=api_config.claude_key)\n",
        "        print(\"‚ö†Ô∏è Claude Worker V2 im Legacy-Modus (Foundation-System fehlt)\")\n",
        "\n",
        "else:\n",
        "    print(\"‚ùå Claude Worker V2 nicht verf√ºgbar - API Key fehlt\")\n",
        "    claude_worker_v2 = None\n",
        "\n",
        "# =============================================================================\n",
        "# DIREKTER TEST - Foundation-Integration\n",
        "# =============================================================================\n",
        "\n",
        "if claude_worker_v2 and foundation_available:\n",
        "    print(\"\\nüß™ TESTE CLAUDE WORKER V2 MIT FOUNDATION-SYSTEM\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    try:\n",
        "        test_location = \"m√ºnchen\"\n",
        "\n",
        "        # Test 1: Web Search mit Foundation\n",
        "        print(\"üìç Test 1: Web Search mit Foundation-System\")\n",
        "        search_result = claude_worker_v2.web_search_with_foundation(\n",
        "            category=\"nachrichten\",\n",
        "            location=test_location,\n",
        "            timeframe=\"heute\",\n",
        "            max_searches=3\n",
        "        )\n",
        "\n",
        "        if search_result:\n",
        "            print(f\"  ‚úÖ Web Search: {len(search_result.get('text_content', ''))} Zeichen Content\")\n",
        "            print(f\"  üìÅ Content File: {search_result.get('content_filename', 'N/A')}\")\n",
        "            print(f\"  üÜî Query ID: {search_result['query_id']}\")\n",
        "            print(f\"  üìö Citations: {len(search_result.get('citations', []))}\")\n",
        "\n",
        "        # Test 2: Kategorie-spezifische Suche\n",
        "        print(f\"\\nüìç Test 2: Kategorie-Processing\")\n",
        "        category_result = claude_worker_v2.process_category_for_newsletter(\"verkehr\", test_location)\n",
        "\n",
        "        if category_result:\n",
        "            print(f\"  ‚úÖ Verkehr: Web Search erfolgreich\")\n",
        "            print(f\"  üåê Web Searches: {category_result.get('web_searches_used', 0)}\")\n",
        "            print(f\"  üìö Citations: {len(category_result.get('citations', []))}\")\n",
        "\n",
        "        # Test 3: Citation Summary\n",
        "        print(f\"\\nüìç Test 3: Citation Summary\")\n",
        "        citation_summary = claude_worker_v2.get_citation_summary(test_location)\n",
        "\n",
        "        print(f\"  üìä Total Citations: {citation_summary['total_citations']}\")\n",
        "        print(f\"  üìã Kategorien: {citation_summary['categories']}\")\n",
        "        print(f\"  üåê Unique Sources: {len(citation_summary['sources'])}\")\n",
        "\n",
        "        # Test 4: Newsletter Summary\n",
        "        print(f\"\\nüìç Test 4: Newsletter Summary\")\n",
        "        newsletter_summary = claude_worker_v2.get_newsletter_summary_for_location(test_location)\n",
        "\n",
        "        print(f\"  üìä Location: {newsletter_summary['location']}\")\n",
        "        print(f\"  üîç Search Results: {newsletter_summary['total_search_results']}\")\n",
        "        print(f\"  üìö Total Citations: {newsletter_summary['total_citations']}\")\n",
        "        print(f\"  üåê Total Web Searches: {newsletter_summary['total_web_searches_used']}\")\n",
        "        print(f\"  üìã Kategorien: {newsletter_summary['categories_processed']}\")\n",
        "\n",
        "        print(f\"\\n‚úÖ Alle Claude Worker V2 Tests erfolgreich!\")\n",
        "\n",
        "    except Exception as test_error:\n",
        "        print(f\"‚ùå Test Fehler: {test_error}\")\n",
        "        import traceback\n",
        "        print(f\"üîç Traceback: {traceback.format_exc()}\")\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"‚úÖ Claude Worker V2 Setup komplett\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "id": "H1NWuHFmZrMA",
        "outputId": "470d7584-75a0-459d-f822-2438fc92cb33"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Claude Worker V2 initialisiert\n",
            "üèóÔ∏è Foundation Integration: ‚úÖ\n",
            "‚öôÔ∏è API Config geladen: Model claude-3-5-haiku-latest\n",
            "üîç Web Search Config: 2 Parameter\n",
            "üöÄ Claude Worker V2 mit Foundation-System bereit\n",
            "\n",
            "üß™ TESTE CLAUDE WORKER V2 MIT FOUNDATION-SYSTEM\n",
            "============================================================\n",
            "üìç Test 1: Web Search mit Foundation-System\n",
            "üîç Query-Log gespeichert: e28abba4\n",
            "üîç Claude Web Search: nachrichten in m√ºnchen\n",
            "üìù Enhanced Query: lokale Nachrichten m√ºnchen heute heute aktuell\n",
            "‚è∞ Timeframe: heute\n",
            "üåê Max Searches: 3\n",
            "üíæ Raw Response gespeichert: 007_claude_web_search_nachrichten_13-36-28.json\n",
            "üìÑ Processed Content gespeichert: nachrichten_13-36-28.md\n",
            "‚úÖ Claude Web Search erfolgreich!\n",
            "üìä Web Searches verwendet: 1\n",
            "üìö Citations: 8\n",
            "üìù Content: 1660 Zeichen\n",
            "  ‚úÖ Web Search: 1660 Zeichen Content\n",
            "  üìÅ Content File: /content/drive/MyDrive/Newsletter_System/data/sessions/2025-07-20_13-35_m√ºnchen/processed_content/nachrichten_13-36-28.md\n",
            "  üÜî Query ID: e28abba4\n",
            "  üìö Citations: 8\n",
            "\n",
            "üìç Test 2: Kategorie-Processing\n",
            "üéØ Verarbeite verkehr f√ºr m√ºnchen via Claude Web Search\n",
            "üîç Query-Log gespeichert: d5f44af2\n",
            "üîç Claude Web Search: verkehr in m√ºnchen\n",
            "üìù Enhanced Query: Verkehrslage m√ºnchen aktuell St√∂rungen Staus heute\n",
            "‚è∞ Timeframe: aktuell\n",
            "üåê Max Searches: 5\n",
            "üíæ Raw Response gespeichert: 008_claude_web_search_verkehr_13-36-44.json\n",
            "üìÑ Processed Content gespeichert: verkehr_13-36-44.md\n",
            "‚úÖ Claude Web Search erfolgreich!\n",
            "üìä Web Searches verwendet: 1\n",
            "üìö Citations: 11\n",
            "üìù Content: 1564 Zeichen\n",
            "  ‚úÖ Verkehr: Web Search erfolgreich\n",
            "  üåê Web Searches: 1\n",
            "  üìö Citations: 11\n",
            "\n",
            "üìç Test 3: Citation Summary\n",
            "  üìä Total Citations: 19\n",
            "  üìã Kategorien: ['nachrichten', 'verkehr']\n",
            "  üåê Unique Sources: 8\n",
            "\n",
            "üìç Test 4: Newsletter Summary\n",
            "  üìä Location: m√ºnchen\n",
            "  üîç Search Results: 2\n",
            "  üìö Total Citations: 19\n",
            "  üåê Total Web Searches: 2\n",
            "  üìã Kategorien: ['nachrichten', 'verkehr']\n",
            "\n",
            "‚úÖ Alle Claude Worker V2 Tests erfolgreich!\n",
            "============================================================\n",
            "‚úÖ Claude Worker V2 Setup komplett\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# ZELLE 4: Perplexity Worker V2 - Foundation-System Integration\n",
        "# =============================================================================\n",
        "# @title Perplexity Worker V2 - Mit ConfigManager + TimeContext + DataPersistence\n",
        "from openai import OpenAI\n",
        "\n",
        "class PerplexityWorkerV2:\n",
        "    \"\"\"\n",
        "    Perplexity Worker V2 - Vollst√§ndig integriert mit Foundation-System\n",
        "    - ConfigManager f√ºr intelligente Search Queries\n",
        "    - TimeContextManager f√ºr Echtzeit-Kontextualisierung\n",
        "    - DataPersistenceManager f√ºr Search-Result Tracking\n",
        "    - Perplexity API f√ºr zus√§tzliche Search-Perspektiven\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, api_key, config_manager=None, time_manager=None, persistence_manager=None):\n",
        "        \"\"\"\n",
        "        Initialisiert Perplexity Worker V2\n",
        "\n",
        "        Args:\n",
        "            api_key: Perplexity API Key\n",
        "            config_manager: ConfigManager Instance\n",
        "            time_manager: TimeContextManager Instance\n",
        "            persistence_manager: DataPersistenceManager Instance\n",
        "        \"\"\"\n",
        "        self.client = OpenAI(\n",
        "            api_key=api_key,\n",
        "            base_url=\"https://api.perplexity.ai\"\n",
        "        )\n",
        "\n",
        "        # Foundation-System Integration\n",
        "        self.config_manager = config_manager\n",
        "        self.time_manager = time_manager\n",
        "        self.persistence_manager = persistence_manager\n",
        "\n",
        "        # Legacy Support falls Foundation nicht verf√ºgbar\n",
        "        self.has_foundation = all([config_manager, time_manager, persistence_manager])\n",
        "\n",
        "        # Worker State\n",
        "        self.search_results = []\n",
        "        self.source_registry = {}  # Tracking aller Quellen f√ºr Cross-Validation\n",
        "\n",
        "        print(f\"‚úÖ Perplexity Worker V2 initialisiert\")\n",
        "        print(f\"üèóÔ∏è Foundation Integration: {'‚úÖ' if self.has_foundation else '‚ùå'}\")\n",
        "\n",
        "        if self.has_foundation:\n",
        "            # API-Config aus ConfigManager holen\n",
        "            self.api_config = self.config_manager.get_api_config(\"perplexity\")\n",
        "            self.model = self.api_config.get(\"model\", \"sonar-pro\")\n",
        "            self.default_params = self.api_config.get(\"extra_body\", {})\n",
        "            print(f\"‚öôÔ∏è API Config geladen: Model {self.model}\")\n",
        "            print(f\"üîß Default Params: {len(self.default_params)} Parameter\")\n",
        "        else:\n",
        "            self.model = \"sonar-pro\"\n",
        "            self.default_params = {\n",
        "                \"search_mode\": \"web\",\n",
        "                \"return_images\": False,\n",
        "                \"return_related_questions\": False\n",
        "            }\n",
        "            print(\"‚ö†Ô∏è L√§uft im Legacy-Modus ohne Foundation-System\")\n",
        "\n",
        "    # =========================================================================\n",
        "    # SEARCH - Foundation-System Integration\n",
        "    # =========================================================================\n",
        "\n",
        "    def search_with_foundation(self, category, location, timeframe=\"heute\", context_size=\"medium\"):\n",
        "        \"\"\"\n",
        "        Intelligente Search mit Foundation-System Integration\n",
        "\n",
        "        Args:\n",
        "            category: Newsletter-Kategorie (z.B. \"wetter\", \"events\")\n",
        "            location: Ortsname\n",
        "            timeframe: Zeitrahmen (default: optimal f√ºr Kategorie)\n",
        "            context_size: Search context size (\"low\", \"medium\", \"high\")\n",
        "\n",
        "        Returns:\n",
        "            dict: Strukturierte Search-Ergebnisse mit Source-Tracking\n",
        "        \"\"\"\n",
        "        if not self.has_foundation:\n",
        "            print(\"‚ùå Foundation-System erforderlich f√ºr diese Methode\")\n",
        "            return None\n",
        "\n",
        "        try:\n",
        "            # 1. Optimal Timeframe bestimmen\n",
        "            if timeframe == \"heute\":  # Auto-detect\n",
        "                timeframe = self.time_manager.get_optimal_timeframe_for_category(category)\n",
        "\n",
        "            # 2. Search Template aus Config holen\n",
        "            search_template = self.config_manager.get_search_template(category, \"perplexity\", location)\n",
        "\n",
        "            # 3. Template mit Zeit-Kontext anreichern\n",
        "            enhanced_query = self.time_manager.inject_time_context(search_template, timeframe, \"perplexity\")\n",
        "\n",
        "            # 4. Query Log speichern\n",
        "            query_id = self.persistence_manager.save_query_log(\n",
        "                category=category,\n",
        "                api=\"perplexity_search\",\n",
        "                original_query=search_template,\n",
        "                enhanced_query=enhanced_query,\n",
        "                time_context=self.time_manager.get_time_context(timeframe, \"perplexity\")\n",
        "            )\n",
        "\n",
        "            print(f\"üîç Perplexity Search: {category} in {location}\")\n",
        "            print(f\"üìù Enhanced Query: {enhanced_query}\")\n",
        "            print(f\"‚è∞ Timeframe: {timeframe}\")\n",
        "            print(f\"üß† Context Size: {context_size}\")\n",
        "\n",
        "            # 5. Perplexity API-Parameter zusammensetzen\n",
        "            extra_body = self.default_params.copy()\n",
        "            extra_body[\"web_search_options\"] = {\n",
        "                \"search_context_size\": context_size,\n",
        "                \"user_location\": {\"country\": \"DE\"}\n",
        "            }\n",
        "\n",
        "            # Zeit-spezifische Parameter hinzuf√ºgen\n",
        "            time_context = self.time_manager.get_time_context(timeframe, \"perplexity\")\n",
        "            if time_context.get(\"api_parameters\", {}).get(\"date_hint\"):\n",
        "                enhanced_query += f\" {time_context['api_parameters']['date_hint']}\"\n",
        "\n",
        "            # 6. Perplexity API Call\n",
        "            response = self.client.chat.completions.create(\n",
        "                model=self.model,\n",
        "                messages=[\n",
        "                    {\n",
        "                        \"role\": \"user\",\n",
        "                        \"content\": enhanced_query\n",
        "                    }\n",
        "                ],\n",
        "                temperature=self.api_config.get(\"temperature\", 0.2),\n",
        "                top_p=self.api_config.get(\"top_p\", 0.9),\n",
        "                stream=False,\n",
        "                extra_body=extra_body\n",
        "            )\n",
        "\n",
        "            # 7. Raw Response speichern\n",
        "            raw_filename = self.persistence_manager.save_raw_response(\n",
        "                source=\"perplexity_search\",\n",
        "                response=response,\n",
        "                query=enhanced_query,\n",
        "                category=category,\n",
        "                metadata={\n",
        "                    \"query_id\": query_id,\n",
        "                    \"timeframe\": timeframe,\n",
        "                    \"location\": location,\n",
        "                    \"model\": self.model,\n",
        "                    \"context_size\": context_size\n",
        "                }\n",
        "            )\n",
        "\n",
        "            # 8. Response verarbeiten\n",
        "            if response and response.choices:\n",
        "                processed_result = self._process_perplexity_response(\n",
        "                    response, category, location, timeframe, query_id, raw_filename\n",
        "                )\n",
        "\n",
        "                if processed_result:\n",
        "                    self.search_results.append(processed_result)\n",
        "\n",
        "                    # 9. Processed Content als Markdown speichern\n",
        "                    markdown_content = self._format_perplexity_search_as_markdown(processed_result)\n",
        "                    content_filename = self.persistence_manager.save_processed_content(\n",
        "                        category=category,\n",
        "                        content=markdown_content,\n",
        "                        content_type=\"markdown\",\n",
        "                        metadata={\n",
        "                            \"query_id\": query_id,\n",
        "                            \"source\": \"perplexity_search\",\n",
        "                            \"sources_count\": len(processed_result.get(\"sources\", [])),\n",
        "                            \"context_size\": context_size\n",
        "                        }\n",
        "                    )\n",
        "\n",
        "                    processed_result[\"content_filename\"] = content_filename\n",
        "\n",
        "                    print(f\"‚úÖ Perplexity Search erfolgreich!\")\n",
        "                    print(f\"üìù Content: {len(processed_result.get('content', ''))} Zeichen\")\n",
        "                    print(f\"üìö Sources: {len(processed_result.get('sources', []))}\")\n",
        "\n",
        "                    return processed_result\n",
        "\n",
        "            print(\"‚ùå Keine Response von Perplexity erhalten\")\n",
        "            return None\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Perplexity Search Fehler: {e}\")\n",
        "\n",
        "            # Fehler in Persistence speichern\n",
        "            if self.persistence_manager:\n",
        "                error_log = {\n",
        "                    \"error\": str(e),\n",
        "                    \"category\": category,\n",
        "                    \"location\": location,\n",
        "                    \"query\": enhanced_query if 'enhanced_query' in locals() else \"N/A\"\n",
        "                }\n",
        "                self.persistence_manager.save_raw_response(\n",
        "                    source=\"perplexity_search_error\",\n",
        "                    response=error_log,\n",
        "                    category=category\n",
        "                )\n",
        "\n",
        "            return None\n",
        "\n",
        "    def _process_perplexity_response(self, response, category, location, timeframe, query_id, raw_filename):\n",
        "        \"\"\"Verarbeitet Perplexity Response und extrahiert Sources\"\"\"\n",
        "\n",
        "        # Hauptinhalt aus Response\n",
        "        main_content = response.choices[0].message.content\n",
        "\n",
        "        processed_result = {\n",
        "            \"method\": \"search\",\n",
        "            \"category\": category,\n",
        "            \"location\": location,\n",
        "            \"timeframe\": timeframe,\n",
        "            \"query_id\": query_id,\n",
        "            \"raw_filename\": raw_filename,\n",
        "            \"timestamp\": datetime.now().isoformat(),\n",
        "            \"content\": main_content,\n",
        "            \"sources\": [],\n",
        "            \"model\": self.model\n",
        "        }\n",
        "\n",
        "        # Citations aus Response extrahieren (falls verf√ºgbar)\n",
        "        # Perplexity hat manchmal citations in verschiedenen Formaten\n",
        "        citations = []\n",
        "        if hasattr(response, 'citations') and response.citations:\n",
        "            citations = list(response.citations)\n",
        "\n",
        "        # Sources aus Response extrahieren (falls verf√ºgbar)\n",
        "        sources = []\n",
        "        if hasattr(response, 'sources') and response.sources:\n",
        "            sources = list(response.sources)\n",
        "        elif hasattr(response, 'search_results') and response.search_results:\n",
        "            sources = response.search_results\n",
        "\n",
        "        # Sources verarbeiten und registrieren\n",
        "        for i, source in enumerate(sources):\n",
        "            if isinstance(source, dict):\n",
        "                source_info = {\n",
        "                    \"index\": i + 1,\n",
        "                    \"url\": source.get(\"url\", \"\"),\n",
        "                    \"title\": source.get(\"title\", f\"Quelle {i+1}\"),\n",
        "                    \"snippet\": source.get(\"snippet\", source.get(\"description\", \"\")),\n",
        "                    \"date\": source.get(\"date\", \"\")\n",
        "                }\n",
        "            else:\n",
        "                # Fallback f√ºr String-Sources\n",
        "                source_info = {\n",
        "                    \"index\": i + 1,\n",
        "                    \"url\": str(source),\n",
        "                    \"title\": f\"Quelle {i+1}\",\n",
        "                    \"snippet\": \"\",\n",
        "                    \"date\": \"\"\n",
        "                }\n",
        "\n",
        "            processed_result[\"sources\"].append(source_info)\n",
        "\n",
        "            # Source Registry f√ºr Cross-Validation\n",
        "            source_id = f\"{query_id}_source_{i+1}\"\n",
        "            self.source_registry[source_id] = {\n",
        "                \"category\": category,\n",
        "                \"location\": location,\n",
        "                \"source\": source_info,\n",
        "                \"query_id\": query_id,\n",
        "                \"timestamp\": datetime.now().isoformat()\n",
        "            }\n",
        "\n",
        "        # Citations zu Sources hinzuf√ºgen falls verf√ºgbar\n",
        "        if citations:\n",
        "            processed_result[\"citations\"] = citations\n",
        "            for citation in citations:\n",
        "                print(f\"üì∞ Citation: {citation}\")\n",
        "\n",
        "        return processed_result\n",
        "\n",
        "    def _format_perplexity_search_as_markdown(self, result):\n",
        "        \"\"\"Formatiert Perplexity Search Ergebnisse als Markdown\"\"\"\n",
        "\n",
        "        markdown = f\"# {result['category'].title()} - {result['location'].title()} (Perplexity Search)\\n\\n\"\n",
        "        markdown += f\"**Generiert:** {result['timestamp']}\\n\"\n",
        "        markdown += f\"**Timeframe:** {result['timeframe']}\\n\"\n",
        "        markdown += f\"**Query ID:** {result['query_id']}\\n\"\n",
        "        markdown += f\"**Model:** {result['model']}\\n\"\n",
        "        markdown += f\"**Sources:** {len(result['sources'])}\\n\\n\"\n",
        "\n",
        "        # Haupt-Content\n",
        "        markdown += \"## Perplexity's Antwort\\n\\n\"\n",
        "        if result['content']:\n",
        "            markdown += result['content'] + \"\\n\\n\"\n",
        "\n",
        "        # Sources\n",
        "        if result['sources']:\n",
        "            markdown += \"## Quellen\\n\\n\"\n",
        "            for source in result['sources']:\n",
        "                markdown += f\"**[{source['index']}] {source['title']}**\\n\"\n",
        "                markdown += f\"URL: {source['url']}\\n\"\n",
        "                if source.get('snippet'):\n",
        "                    markdown += f\"Beschreibung: {source['snippet']}\\n\"\n",
        "                if source.get('date'):\n",
        "                    markdown += f\"Datum: {source['date']}\\n\"\n",
        "                markdown += \"\\n\"\n",
        "\n",
        "        # Citations falls verf√ºgbar\n",
        "        if result.get('citations'):\n",
        "            markdown += \"## Citations\\n\\n\"\n",
        "            for i, citation in enumerate(result['citations'], 1):\n",
        "                markdown += f\"**Citation {i}:** {citation}\\n\"\n",
        "            markdown += \"\\n\"\n",
        "\n",
        "        return markdown\n",
        "\n",
        "    # =========================================================================\n",
        "    # COMPARATIVE SEARCH\n",
        "    # =========================================================================\n",
        "\n",
        "    def comparative_search(self, category, location, comparison_topic=None):\n",
        "        \"\"\"\n",
        "        Vergleichende Suche f√ºr Cross-Validation mit anderen Workern\n",
        "\n",
        "        Args:\n",
        "            category: Newsletter-Kategorie\n",
        "            location: Ortsname\n",
        "            comparison_topic: Spezifisches Thema f√ºr Vergleich (optional)\n",
        "\n",
        "        Returns:\n",
        "            dict: Vergleichende Search-Ergebnisse\n",
        "        \"\"\"\n",
        "        if not self.has_foundation:\n",
        "            return self.search_with_foundation(category, location)\n",
        "\n",
        "        # Spezielle Query f√ºr Vergleichssuche\n",
        "        if comparison_topic:\n",
        "            focused_query = f\"{comparison_topic} in {location} aktuell Deutschland\"\n",
        "        else:\n",
        "            # Standard Template verwenden\n",
        "            return self.search_with_foundation(category, location, context_size=\"high\")\n",
        "\n",
        "        try:\n",
        "            query_id = self.persistence_manager.save_query_log(\n",
        "                category=category,\n",
        "                api=\"perplexity_comparative\",\n",
        "                original_query=comparison_topic or category,\n",
        "                enhanced_query=focused_query,\n",
        "                time_context={\"comparison_mode\": True}\n",
        "            )\n",
        "\n",
        "            print(f\"üîÑ Comparative Search: {category}\")\n",
        "            print(f\"üìù Focused Query: {focused_query}\")\n",
        "\n",
        "            # Perplexity mit gro√üem Kontext f√ºr umfassende Suche\n",
        "            extra_body = self.default_params.copy()\n",
        "            extra_body[\"web_search_options\"] = {\n",
        "                \"search_context_size\": \"high\",  # Fixed: \"high\" statt \"large\"\n",
        "                \"user_location\": {\"country\": \"DE\"}\n",
        "            }\n",
        "\n",
        "            response = self.client.chat.completions.create(\n",
        "                model=self.model,\n",
        "                messages=[\n",
        "                    {\n",
        "                        \"role\": \"user\",\n",
        "                        \"content\": focused_query\n",
        "                    }\n",
        "                ],\n",
        "                temperature=0.1,  # Niedriger f√ºr faktische Vergleiche\n",
        "                top_p=0.9,\n",
        "                stream=False,\n",
        "                extra_body=extra_body\n",
        "            )\n",
        "\n",
        "            if response and response.choices:\n",
        "                processed_result = self._process_perplexity_response(\n",
        "                    response, category, location, \"comparative\", query_id, None\n",
        "                )\n",
        "\n",
        "                if processed_result:\n",
        "                    processed_result[\"search_type\"] = \"comparative\"\n",
        "                    processed_result[\"comparison_topic\"] = comparison_topic\n",
        "                    print(f\"‚úÖ Comparative Search erfolgreich: {len(processed_result.get('sources', []))} Sources\")\n",
        "                    return processed_result\n",
        "\n",
        "            return None\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Comparative Search Fehler: {e}\")\n",
        "            return None\n",
        "\n",
        "    # =========================================================================\n",
        "    # MULTI-ANGLE SEARCH\n",
        "    # =========================================================================\n",
        "\n",
        "    def multi_angle_search(self, category, location, angles=None):\n",
        "        \"\"\"\n",
        "        Multi-Angle Search f√ºr umfassende Kategorie-Abdeckung\n",
        "\n",
        "        Args:\n",
        "            category: Newsletter-Kategorie\n",
        "            location: Ortsname\n",
        "            angles: Liste von Suchperspektiven (optional)\n",
        "\n",
        "        Returns:\n",
        "            list: Multiple Search-Ergebnisse aus verschiedenen Winkeln\n",
        "        \"\"\"\n",
        "        if not angles:\n",
        "            # Standard-Angles basierend auf Kategorie\n",
        "            angle_mapping = {\n",
        "                \"wetter\": [\"Wettervorhersage\", \"Wetterwarnungen\", \"Klima aktuell\"],\n",
        "                \"verkehr\": [\"Verkehrslage\", \"√ñPNV St√∂rungen\", \"Baustellen\"],\n",
        "                \"events\": [\"Kulturveranstaltungen\", \"Sport Events\", \"Festivals\"],\n",
        "                \"nachrichten\": [\"Lokalnachrichten\", \"Politik lokal\", \"Wirtschaft lokal\"],\n",
        "                \"sport\": [\"Sportergebnisse\", \"Spielberichte\", \"Vereinsnachrichten\"]\n",
        "            }\n",
        "\n",
        "            angles = angle_mapping.get(category.lower(), [category])\n",
        "\n",
        "        results = []\n",
        "\n",
        "        print(f\"üéØ Multi-Angle Search f√ºr {category}: {len(angles)} Perspektiven\")\n",
        "\n",
        "        for i, angle in enumerate(angles):\n",
        "            print(f\"  üìê Angle {i+1}/{len(angles)}: {angle}\")\n",
        "\n",
        "            result = self.comparative_search(category, location, angle)\n",
        "\n",
        "            if result:\n",
        "                result[\"angle\"] = angle\n",
        "                result[\"angle_index\"] = i + 1\n",
        "                results.append(result)\n",
        "                print(f\"    ‚úÖ {len(result.get('sources', []))} Sources gefunden\")\n",
        "            else:\n",
        "                print(f\"    ‚ùå Keine Ergebnisse f√ºr {angle}\")\n",
        "\n",
        "        print(f\"üìä Multi-Angle Search: {len(results)}/{len(angles)} Angles erfolgreich\")\n",
        "\n",
        "        # Kombinierte Ergebnisse speichern\n",
        "        if results and self.persistence_manager:\n",
        "            combined_content = self._format_multi_angle_results(results, category, location)\n",
        "            self.persistence_manager.save_processed_content(\n",
        "                category=f\"{category}_multi_angle\",\n",
        "                content=combined_content,\n",
        "                content_type=\"markdown\",\n",
        "                metadata={\n",
        "                    \"angles_count\": len(results),\n",
        "                    \"total_sources\": sum(len(r.get('sources', [])) for r in results)\n",
        "                }\n",
        "            )\n",
        "\n",
        "        return results\n",
        "\n",
        "    def _format_multi_angle_results(self, results, category, location):\n",
        "        \"\"\"Formatiert Multi-Angle Search Ergebnisse als kombiniertes Markdown\"\"\"\n",
        "\n",
        "        markdown = f\"# {category.title()} Multi-Angle Search - {location.title()}\\n\\n\"\n",
        "        markdown += f\"**Generiert:** {datetime.now().isoformat()}\\n\"\n",
        "        markdown += f\"**Angles:** {len(results)}\\n\"\n",
        "        markdown += f\"**Total Sources:** {sum(len(r.get('sources', [])) for r in results)}\\n\\n\"\n",
        "\n",
        "        for result in results:\n",
        "            markdown += f\"## Angle: {result.get('angle', 'Unbekannt')}\\n\\n\"\n",
        "\n",
        "            # Content\n",
        "            if result.get('content'):\n",
        "                content_preview = result['content'][:500] + \"...\" if len(result['content']) > 500 else result['content']\n",
        "                markdown += f\"**Antwort:**\\n{content_preview}\\n\\n\"\n",
        "\n",
        "            # Top 3 Sources\n",
        "            if result.get('sources'):\n",
        "                markdown += f\"**Top Sources ({len(result['sources'])}):**\\n\"\n",
        "                for source in result['sources'][:3]:\n",
        "                    markdown += f\"- [{source['index']}] {source['title']} ({source['url']})\\n\"\n",
        "                markdown += \"\\n\"\n",
        "\n",
        "            markdown += \"---\\n\\n\"\n",
        "\n",
        "        return markdown\n",
        "\n",
        "    # =========================================================================\n",
        "    # NEWSLETTER INTEGRATION\n",
        "    # =========================================================================\n",
        "\n",
        "    def process_category_for_newsletter(self, category, location, search_strategy=\"standard\"):\n",
        "        \"\"\"\n",
        "        Verarbeitet eine Kategorie f√ºr Newsletter mit verschiedenen Strategien\n",
        "\n",
        "        Args:\n",
        "            category: Newsletter-Kategorie\n",
        "            location: Ortsname\n",
        "            search_strategy: \"standard\", \"comparative\", \"multi_angle\"\n",
        "\n",
        "        Returns:\n",
        "            dict/list: Verarbeitete Kategorie-Daten\n",
        "        \"\"\"\n",
        "        print(f\"üéØ Verarbeite {category} f√ºr {location} via Perplexity ({search_strategy})\")\n",
        "\n",
        "        if search_strategy == \"multi_angle\":\n",
        "            return self.multi_angle_search(category, location)\n",
        "        elif search_strategy == \"comparative\":\n",
        "            return self.comparative_search(category, location)\n",
        "        else:\n",
        "            return self.search_with_foundation(category, location)\n",
        "\n",
        "    def get_source_summary(self, location=None):\n",
        "        \"\"\"\n",
        "        Gibt Zusammenfassung aller Sources zur√ºck (f√ºr Cross-Validation)\n",
        "\n",
        "        Args:\n",
        "            location: Filter nach Location (optional)\n",
        "\n",
        "        Returns:\n",
        "            dict: Source Summary\n",
        "        \"\"\"\n",
        "        filtered_sources = {}\n",
        "\n",
        "        if location:\n",
        "            for source_id, source_data in self.source_registry.items():\n",
        "                if source_data[\"location\"].lower() == location.lower():\n",
        "                    filtered_sources[source_id] = source_data\n",
        "        else:\n",
        "            filtered_sources = self.source_registry\n",
        "\n",
        "        # Summary Statistics\n",
        "        summary = {\n",
        "            \"total_sources\": len(filtered_sources),\n",
        "            \"categories\": set(),\n",
        "            \"domains\": set(),\n",
        "            \"sources\": filtered_sources\n",
        "        }\n",
        "\n",
        "        for source_data in filtered_sources.values():\n",
        "            summary[\"categories\"].add(source_data[\"category\"])\n",
        "            source_url = source_data[\"source\"].get(\"url\", \"\")\n",
        "            if source_url:\n",
        "                try:\n",
        "                    domain = source_url.split(\"//\")[1].split(\"/\")[0]\n",
        "                    summary[\"domains\"].add(domain)\n",
        "                except:\n",
        "                    pass\n",
        "\n",
        "        summary[\"categories\"] = list(summary[\"categories\"])\n",
        "        summary[\"domains\"] = list(summary[\"domains\"])\n",
        "\n",
        "        return summary\n",
        "\n",
        "    def get_newsletter_summary_for_location(self, location):\n",
        "        \"\"\"Gibt Zusammenfassung aller Perplexity-Daten f√ºr einen Ort zur√ºck\"\"\"\n",
        "\n",
        "        summary = {\n",
        "            \"location\": location,\n",
        "            \"timestamp\": datetime.now().isoformat(),\n",
        "            \"search_results\": [],\n",
        "            \"total_sources\": 0,\n",
        "            \"categories_processed\": set(),\n",
        "            \"search_strategies\": set()\n",
        "        }\n",
        "\n",
        "        # Search Results f√ºr Location\n",
        "        for result in self.search_results:\n",
        "            if result[\"location\"].lower() == location.lower():\n",
        "                search_info = {\n",
        "                    \"category\": result[\"category\"],\n",
        "                    \"timeframe\": result[\"timeframe\"],\n",
        "                    \"sources_count\": len(result.get(\"sources\", [])),\n",
        "                    \"content_filename\": result.get(\"content_filename\"),\n",
        "                    \"query_id\": result[\"query_id\"],\n",
        "                    \"search_type\": result.get(\"search_type\", \"standard\")\n",
        "                }\n",
        "\n",
        "                summary[\"search_results\"].append(search_info)\n",
        "                summary[\"total_sources\"] += len(result.get(\"sources\", []))\n",
        "                summary[\"categories_processed\"].add(result[\"category\"])\n",
        "                summary[\"search_strategies\"].add(result.get(\"search_type\", \"standard\"))\n",
        "\n",
        "        summary[\"categories_processed\"] = list(summary[\"categories_processed\"])\n",
        "        summary[\"search_strategies\"] = list(summary[\"search_strategies\"])\n",
        "        summary[\"total_search_results\"] = len(summary[\"search_results\"])\n",
        "\n",
        "        return summary\n",
        "\n",
        "# =============================================================================\n",
        "# INITIALISIERUNG MIT FOUNDATION-SYSTEM\n",
        "# =============================================================================\n",
        "\n",
        "# Perplexity Worker V2 mit Foundation-System initialisieren\n",
        "if api_config.perplexity_key:\n",
        "    # Foundation-System Integration\n",
        "    foundation_available = all([\n",
        "        'config_manager' in globals() and config_manager,\n",
        "        'time_manager' in globals() and time_manager,\n",
        "        'persistence_manager' in globals() and persistence_manager\n",
        "    ])\n",
        "\n",
        "    if foundation_available:\n",
        "        perplexity_worker_v2 = PerplexityWorkerV2(\n",
        "            api_key=api_config.perplexity_key,\n",
        "            config_manager=config_manager,\n",
        "            time_manager=time_manager,\n",
        "            persistence_manager=persistence_manager\n",
        "        )\n",
        "        print(\"üöÄ Perplexity Worker V2 mit Foundation-System bereit\")\n",
        "    else:\n",
        "        # Fallback ohne Foundation\n",
        "        perplexity_worker_v2 = PerplexityWorkerV2(api_key=api_config.perplexity_key)\n",
        "        print(\"‚ö†Ô∏è Perplexity Worker V2 im Legacy-Modus (Foundation-System fehlt)\")\n",
        "\n",
        "else:\n",
        "    print(\"‚ùå Perplexity Worker V2 nicht verf√ºgbar - API Key fehlt\")\n",
        "    perplexity_worker_v2 = None\n",
        "\n",
        "# =============================================================================\n",
        "# DIREKTER TEST - Foundation-Integration\n",
        "# =============================================================================\n",
        "\n",
        "if perplexity_worker_v2 and foundation_available:\n",
        "    print(\"\\nüß™ TESTE PERPLEXITY WORKER V2 MIT FOUNDATION-SYSTEM\")\n",
        "    print(\"=\" * 65)\n",
        "\n",
        "    try:\n",
        "        test_location = \"m√ºnchen\"\n",
        "\n",
        "        # Test 1: Standard Search mit Foundation\n",
        "        print(\"üìç Test 1: Standard Search mit Foundation-System\")\n",
        "        search_result = perplexity_worker_v2.search_with_foundation(\n",
        "            category=\"sport\",\n",
        "            location=test_location,\n",
        "            timeframe=\"heute\",\n",
        "            context_size=\"medium\"\n",
        "        )\n",
        "\n",
        "        if search_result:\n",
        "            print(f\"  ‚úÖ Search: {len(search_result.get('content', ''))} Zeichen Content\")\n",
        "            print(f\"  üìÅ Content File: {search_result.get('content_filename', 'N/A')}\")\n",
        "            print(f\"  üÜî Query ID: {search_result['query_id']}\")\n",
        "            print(f\"  üìö Sources: {len(search_result.get('sources', []))}\")\n",
        "\n",
        "        # Test 2: Comparative Search\n",
        "        print(f\"\\nüìç Test 2: Comparative Search\")\n",
        "        comparative_result = perplexity_worker_v2.comparative_search(\n",
        "            category=\"wetter\",\n",
        "            location=test_location,\n",
        "            comparison_topic=\"Wettervorhersage Wochenende\"\n",
        "        )\n",
        "\n",
        "        if comparative_result:\n",
        "            print(f\"  ‚úÖ Comparative: {len(comparative_result.get('sources', []))} Sources\")\n",
        "            print(f\"  üîç Topic: {comparative_result.get('comparison_topic', 'N/A')}\")\n",
        "\n",
        "        # Test 3: Source Summary\n",
        "        print(f\"\\nüìç Test 3: Source Summary\")\n",
        "        source_summary = perplexity_worker_v2.get_source_summary(test_location)\n",
        "\n",
        "        print(f\"  üìä Total Sources: {source_summary['total_sources']}\")\n",
        "        print(f\"  üìã Kategorien: {source_summary['categories']}\")\n",
        "        print(f\"  üåê Unique Domains: {len(source_summary['domains'])}\")\n",
        "\n",
        "        # Test 4: Newsletter Summary\n",
        "        print(f\"\\nüìç Test 4: Newsletter Summary\")\n",
        "        newsletter_summary = perplexity_worker_v2.get_newsletter_summary_for_location(test_location)\n",
        "\n",
        "        print(f\"  üìä Location: {newsletter_summary['location']}\")\n",
        "        print(f\"  üîç Search Results: {newsletter_summary['total_search_results']}\")\n",
        "        print(f\"  üìö Total Sources: {newsletter_summary['total_sources']}\")\n",
        "        print(f\"  üìã Kategorien: {newsletter_summary['categories_processed']}\")\n",
        "        print(f\"  üéØ Strategien: {newsletter_summary['search_strategies']}\")\n",
        "\n",
        "        print(f\"\\n‚úÖ Alle Perplexity Worker V2 Tests erfolgreich!\")\n",
        "\n",
        "    except Exception as test_error:\n",
        "        print(f\"‚ùå Test Fehler: {test_error}\")\n",
        "        import traceback\n",
        "        print(f\"üîç Traceback: {traceback.format_exc()}\")\n",
        "\n",
        "print(\"=\" * 65)\n",
        "print(\"‚úÖ Perplexity Worker V2 Setup komplett\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "id": "YUj5lzeMZ2QN",
        "outputId": "ed160518-25c3-4a0e-d79e-ed7e595213f7"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Perplexity Worker V2 initialisiert\n",
            "üèóÔ∏è Foundation Integration: ‚úÖ\n",
            "‚öôÔ∏è API Config geladen: Model sonar-pro\n",
            "üîß Default Params: 4 Parameter\n",
            "üöÄ Perplexity Worker V2 mit Foundation-System bereit\n",
            "\n",
            "üß™ TESTE PERPLEXITY WORKER V2 MIT FOUNDATION-SYSTEM\n",
            "=================================================================\n",
            "üìç Test 1: Standard Search mit Foundation-System\n",
            "üîç Query-Log gespeichert: 92d69e0c\n",
            "üîç Perplexity Search: sport in m√ºnchen\n",
            "üìù Enhanced Query: Sport m√ºnchen Ergebnisse Vereine heute\n",
            "‚è∞ Timeframe: heute\n",
            "üß† Context Size: medium\n",
            "üíæ Raw Response gespeichert: 009_perplexity_search_sport_13-36-54.json\n",
            "üì∞ Citation: https://www.leichtathletik.de/wettkaempfe/ergebnisse\n",
            "üì∞ Citation: https://sport.sky.de/fc-bayern-muenchen-ergebnisse\n",
            "üì∞ Citation: https://www.weltfussball.de/tore_tabellen/\n",
            "üì∞ Citation: https://www.sueddeutsche.de/sport-liveticker/tennis/atp-kroatien-konzum-croatia-open/ma11423393/matej-dodig_francesco-passaro/\n",
            "üì∞ Citation: https://www.sport.de/spielort/ve81/allianz-arena/ergebnisse/\n",
            "üì∞ Citation: https://sport.bild.de/fussball/\n",
            "üì∞ Citation: https://www.sueddeutsche.de/sport-liveticker/tennis/atp-schweden-skistar-swedish-open/ma11423996/luciano-darderi_jesper-de-jong/\n",
            "üì∞ Citation: https://www.laola1.at/de/daten/ergebnisse/fussball/fc-bayern-muenchen/\n",
            "üìÑ Processed Content gespeichert: sport_13-36-54.md\n",
            "‚úÖ Perplexity Search erfolgreich!\n",
            "üìù Content: 2130 Zeichen\n",
            "üìö Sources: 8\n",
            "  ‚úÖ Search: 2130 Zeichen Content\n",
            "  üìÅ Content File: /content/drive/MyDrive/Newsletter_System/data/sessions/2025-07-20_13-35_m√ºnchen/processed_content/sport_13-36-54.md\n",
            "  üÜî Query ID: 92d69e0c\n",
            "  üìö Sources: 8\n",
            "\n",
            "üìç Test 2: Comparative Search\n",
            "üîç Query-Log gespeichert: 323dd7d2\n",
            "üîÑ Comparative Search: wetter\n",
            "üìù Focused Query: Wettervorhersage Wochenende in m√ºnchen aktuell Deutschland\n",
            "üì∞ Citation: https://www.wetterprognose-wettervorhersage.de/wetter-muenchen.html\n",
            "üì∞ Citation: https://www.daswetter.com/wochenende/wetter_Munchen-Europa-Deutschland-Bayern--1-27076.html\n",
            "üì∞ Citation: https://www.meteoprog.com/de/weather/Munich/month/july/\n",
            "üì∞ Citation: https://www.muenchen.de/freizeit/wetter-aktuell-muenchen\n",
            "üì∞ Citation: https://www.donnerwetter.de/wetter/muenchen/DE21179.html\n",
            "üì∞ Citation: https://www.proplanta.de/wetter/muenchen-wochenendwetter.html\n",
            "üì∞ Citation: https://14-tage-wettervorhersage.de/wetter/muenchen/vorhersage/178086/\n",
            "üì∞ Citation: https://www.wetteronline.de/wetter/muenchen\n",
            "üì∞ Citation: https://www.wetter.com/wetter_aktuell/wettervorhersage/16_tagesvorhersage/deutschland/muenchen/DE0006515.html\n",
            "üì∞ Citation: https://www.wetter.com/wetter_aktuell/wettervorhersage/wochenend_vorhersage/deutschland/muenchen/DE0006515.html\n",
            "‚úÖ Comparative Search erfolgreich: 10 Sources\n",
            "  ‚úÖ Comparative: 10 Sources\n",
            "  üîç Topic: Wettervorhersage Wochenende\n",
            "\n",
            "üìç Test 3: Source Summary\n",
            "  üìä Total Sources: 18\n",
            "  üìã Kategorien: ['wetter', 'sport']\n",
            "  üåê Unique Domains: 16\n",
            "\n",
            "üìç Test 4: Newsletter Summary\n",
            "  üìä Location: m√ºnchen\n",
            "  üîç Search Results: 1\n",
            "  üìö Total Sources: 8\n",
            "  üìã Kategorien: ['sport']\n",
            "  üéØ Strategien: ['standard']\n",
            "\n",
            "‚úÖ Alle Perplexity Worker V2 Tests erfolgreich!\n",
            "=================================================================\n",
            "‚úÖ Perplexity Worker V2 Setup komplett\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# ZELLE 5a: Enhanced Content Processor - Source Integration f√ºr detaillierte Newsletter\n",
        "# =============================================================================\n",
        "# @title Enhanced Content Processor - Macht gesammelte Quellen f√ºr Newsletter nutzbar\n",
        "\n",
        "import re\n",
        "from pathlib import Path\n",
        "from datetime import datetime\n",
        "from typing import Dict, List, Optional, Any\n",
        "\n",
        "class EnhancedContentProcessor:\n",
        "    \"\"\"\n",
        "    Enhanced Content Processor - L√§dt und verarbeitet alle gesammelten Quellen\n",
        "    Macht Markdown-Files nutzbar f√ºr detaillierte Newsletter-Generation\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, persistence_manager, config_manager=None):\n",
        "        \"\"\"\n",
        "        Initialisiert Enhanced Content Processor\n",
        "\n",
        "        Args:\n",
        "            persistence_manager: DataPersistenceManager Instance\n",
        "            config_manager: ConfigManager Instance (optional)\n",
        "        \"\"\"\n",
        "        self.persistence_manager = persistence_manager\n",
        "        self.config_manager = config_manager\n",
        "\n",
        "        # Content Registry\n",
        "        self.processed_categories = {}\n",
        "        self.extracted_facts = {}\n",
        "        self.source_citations = {}\n",
        "\n",
        "        print(f\"‚úÖ Enhanced Content Processor initialisiert\")\n",
        "        print(f\"üèóÔ∏è Integration: DataPersistenceManager + ContentExtraction\")\n",
        "\n",
        "    # =========================================================================\n",
        "    # CONTENT LOADING & PARSING\n",
        "    # =========================================================================\n",
        "\n",
        "    def load_all_category_content(self, location):\n",
        "        \"\"\"\n",
        "        L√§dt alle gespeicherten Markdown-Files f√ºr einen Ort\n",
        "\n",
        "        Args:\n",
        "            location: Ortsname\n",
        "\n",
        "        Returns:\n",
        "            dict: Alle Category-Contents strukturiert\n",
        "        \"\"\"\n",
        "        print(f\"üìÇ Lade alle Category-Contents f√ºr {location}\")\n",
        "\n",
        "        all_content = {}\n",
        "\n",
        "        # Alle Content-Items aus Registry holen\n",
        "        for content_item in self.persistence_manager.content_registry:\n",
        "            category = content_item[\"category\"]\n",
        "\n",
        "            if category not in all_content:\n",
        "                all_content[category] = []\n",
        "\n",
        "            # Content-File lesen\n",
        "            try:\n",
        "                filepath = Path(content_item[\"filepath\"])\n",
        "                if filepath.exists():\n",
        "                    with open(filepath, 'r', encoding='utf-8') as f:\n",
        "                        content = f.read()\n",
        "\n",
        "                    content_data = {\n",
        "                        \"source\": content_item.get(\"source\", \"unknown\"),\n",
        "                        \"content\": content,\n",
        "                        \"timestamp\": content_item[\"timestamp\"],\n",
        "                        \"filename\": content_item[\"filename\"],\n",
        "                        \"content_type\": content_item[\"content_type\"],\n",
        "                        \"metadata\": content_item\n",
        "                    }\n",
        "\n",
        "                    all_content[category].append(content_data)\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"  ‚ùå Fehler beim Laden von {content_item['filename']}: {e}\")\n",
        "                continue\n",
        "\n",
        "        print(f\"  üìä Kategorien geladen: {len(all_content)}\")\n",
        "        for category, items in all_content.items():\n",
        "            print(f\"    {category}: {len(items)} Content-Items\")\n",
        "\n",
        "        self.processed_categories = all_content\n",
        "        return all_content\n",
        "\n",
        "    def extract_facts_from_content(self, category, content_data):\n",
        "        \"\"\"\n",
        "        Extrahiert konkrete Facts und Daten aus Content\n",
        "\n",
        "        Args:\n",
        "            category: Newsletter-Kategorie\n",
        "            content_data: Content-Daten von einem Worker\n",
        "\n",
        "        Returns:\n",
        "            dict: Extrahierte Facts strukturiert\n",
        "        \"\"\"\n",
        "        content = content_data[\"content\"]\n",
        "        source = content_data[\"source\"]\n",
        "\n",
        "        facts = {\n",
        "            \"category\": category,\n",
        "            \"source\": source,\n",
        "            \"timestamp\": content_data[\"timestamp\"],\n",
        "            \"raw_facts\": [],\n",
        "            \"structured_data\": {},\n",
        "            \"citations\": []\n",
        "        }\n",
        "\n",
        "        # Kategorie-spezifische Fact-Extraction\n",
        "        if category == \"wetter\":\n",
        "            facts[\"structured_data\"] = self._extract_weather_facts(content)\n",
        "\n",
        "        elif category == \"nachrichten\":\n",
        "            facts[\"structured_data\"] = self._extract_news_facts(content)\n",
        "\n",
        "        elif category == \"events\":\n",
        "            facts[\"structured_data\"] = self._extract_events_facts(content)\n",
        "\n",
        "        elif category == \"sport\":\n",
        "            facts[\"structured_data\"] = self._extract_sport_facts(content)\n",
        "\n",
        "        elif category == \"verkehr\":\n",
        "            facts[\"structured_data\"] = self._extract_traffic_facts(content)\n",
        "\n",
        "        else:\n",
        "            # Generic fact extraction\n",
        "            facts[\"structured_data\"] = self._extract_generic_facts(content)\n",
        "\n",
        "        # URLs und Citations extrahieren\n",
        "        facts[\"citations\"] = self._extract_citations(content)\n",
        "\n",
        "        return facts\n",
        "\n",
        "    # =========================================================================\n",
        "    # KATEGORIE-SPEZIFISCHE FACT EXTRACTION\n",
        "    # =========================================================================\n",
        "\n",
        "    def _extract_weather_facts(self, content):\n",
        "        \"\"\"Extrahiert Wetter-spezifische Facts\"\"\"\n",
        "        weather_facts = {\n",
        "            \"temperatures\": [],\n",
        "            \"conditions\": [],\n",
        "            \"forecasts\": [],\n",
        "            \"warnings\": [],\n",
        "            \"times\": []\n",
        "        }\n",
        "\n",
        "        # Temperaturen finden (z.B. \"25¬∞C\", \"18 Grad\", \"25-30¬∞\")\n",
        "        temp_patterns = [\n",
        "            r'(\\d{1,2}¬∞C?)',\n",
        "            r'(\\d{1,2}-\\d{1,2}¬∞C?)',\n",
        "            r'(\\d{1,2}\\s?Grad)',\n",
        "            r'Temperatur[en]?[:\\s]+(\\d{1,2}¬∞?C?)',\n",
        "            r'(\\d{1,2})\\s?bis\\s?(\\d{1,2})\\s?Grad'\n",
        "        ]\n",
        "\n",
        "        for pattern in temp_patterns:\n",
        "            matches = re.findall(pattern, content, re.IGNORECASE)\n",
        "            for match in matches:\n",
        "                if isinstance(match, tuple):\n",
        "                    weather_facts[\"temperatures\"].extend([m for m in match if m])\n",
        "                else:\n",
        "                    weather_facts[\"temperatures\"].append(match)\n",
        "\n",
        "        # Wetterbedingungen\n",
        "        weather_conditions = [\n",
        "            r'(sonnig|bew√∂lkt|regnerisch|st√ºrmisch|neblig)',\n",
        "            r'(Regen|Sonne|Wolken|Sturm|Nebel|Schnee)',\n",
        "            r'(heiter|wolkig|tr√ºb|klar|mild|warm|kalt)',\n",
        "            r'(Schauer|Gewitter|Nieselregen|Spr√ºhregen)'\n",
        "        ]\n",
        "\n",
        "        for pattern in weather_conditions:\n",
        "            matches = re.findall(pattern, content, re.IGNORECASE)\n",
        "            weather_facts[\"conditions\"].extend([m.lower() for m in matches])\n",
        "\n",
        "        # Zeiten (heute, morgen, nachmittag, etc.)\n",
        "        time_patterns = [\n",
        "            r'(heute|morgen|√ºbermorgen)',\n",
        "            r'(vormittag|nachmittag|abend|nacht)',\n",
        "            r'(\\d{1,2}:\\d{2})',\n",
        "            r'(am\\s+\\w+tag)',\n",
        "            r'(bis\\s+\\d{1,2}\\s+Uhr)'\n",
        "        ]\n",
        "\n",
        "        for pattern in time_patterns:\n",
        "            matches = re.findall(pattern, content, re.IGNORECASE)\n",
        "            weather_facts[\"times\"].extend([m.lower() for m in matches])\n",
        "\n",
        "        # Warnungen\n",
        "        warning_keywords = ['warnung', 'unwetter', 'sturm', 'starkregen', 'hitze', 'frost']\n",
        "        for keyword in warning_keywords:\n",
        "            if keyword in content.lower():\n",
        "                # Kontext um Warnung extrahieren\n",
        "                context_match = re.search(f'.{{0,50}}{keyword}.{{0,50}}', content, re.IGNORECASE)\n",
        "                if context_match:\n",
        "                    weather_facts[\"warnings\"].append(context_match.group().strip())\n",
        "\n",
        "        return weather_facts\n",
        "\n",
        "    def _extract_news_facts(self, content):\n",
        "        \"\"\"Extrahiert News-spezifische Facts\"\"\"\n",
        "        news_facts = {\n",
        "            \"headlines\": [],\n",
        "            \"dates\": [],\n",
        "            \"locations\": [],\n",
        "            \"persons\": [],\n",
        "            \"organizations\": [],\n",
        "            \"key_statements\": []\n",
        "        }\n",
        "\n",
        "        # Headlines/Titel (typische Markdown Headlines)\n",
        "        headlines = re.findall(r'^#{1,3}\\s+(.+)$', content, re.MULTILINE)\n",
        "        news_facts[\"headlines\"] = [h.strip() for h in headlines]\n",
        "\n",
        "        # Datumsangaben\n",
        "        date_patterns = [\n",
        "            r'(\\d{1,2}\\.\\d{1,2}\\.\\d{4})',\n",
        "            r'(\\d{1,2}\\.\\s?\\w+\\s?\\d{4})',\n",
        "            r'(Januar|Februar|M√§rz|April|Mai|Juni|Juli|August|September|Oktober|November|Dezember)\\s+\\d{4}',\n",
        "            r'(Montag|Dienstag|Mittwoch|Donnerstag|Freitag|Samstag|Sonntag)[,\\s]+\\d{1,2}\\.'\n",
        "        ]\n",
        "\n",
        "        for pattern in date_patterns:\n",
        "            matches = re.findall(pattern, content, re.IGNORECASE)\n",
        "            news_facts[\"dates\"].extend(matches)\n",
        "\n",
        "        # Stadtteile und Orte in M√ºnchen\n",
        "        munich_locations = [\n",
        "            'Innenstadt', 'Maxvorstadt', 'Schwabing', 'Haidhausen', 'Giesing',\n",
        "            'Sendling', 'Neuhausen', 'Pasing', 'Bogenhausen', 'Lehel',\n",
        "            'Olympiapark', 'Marienplatz', 'Hauptbahnhof', 'Flughafen'\n",
        "        ]\n",
        "\n",
        "        for location in munich_locations:\n",
        "            if location.lower() in content.lower():\n",
        "                news_facts[\"locations\"].append(location)\n",
        "\n",
        "        # Organisationen\n",
        "        org_patterns = [\n",
        "            r'(Stadtrat|Stadtverwaltung|Rathaus)',\n",
        "            r'(MVG|Stadtwerke)',\n",
        "            r'(Polizei|Feuerwehr)',\n",
        "            r'(Universit√§t|LMU|TU M√ºnchen)',\n",
        "            r'(Flughafen M√ºnchen)'\n",
        "        ]\n",
        "\n",
        "        for pattern in org_patterns:\n",
        "            matches = re.findall(pattern, content, re.IGNORECASE)\n",
        "            news_facts[\"organizations\"].extend(matches)\n",
        "\n",
        "        # Key Statements (S√§tze mit wichtigen Info-Markern)\n",
        "        statement_patterns = [\n",
        "            r'[^.]*(?:plant|beschlie√üt|verk√ºndet|startet|er√∂ffnet)[^.]*\\.',\n",
        "            r'[^.]*(?:Millionen?|Euro|Prozent)[^.]*\\.',\n",
        "            r'[^.]*(?:ab sofort|ab\\s+\\d{1,2}\\.|bis\\s+\\d{1,2}\\.)[^.]*\\.'\n",
        "        ]\n",
        "\n",
        "        for pattern in statement_patterns:\n",
        "            matches = re.findall(pattern, content, re.IGNORECASE)\n",
        "            news_facts[\"key_statements\"].extend([s.strip() for s in matches[:3]])  # Nur erste 3\n",
        "\n",
        "        return news_facts\n",
        "\n",
        "    def _extract_events_facts(self, content):\n",
        "        \"\"\"Extrahiert Event-spezifische Facts\"\"\"\n",
        "        events_facts = {\n",
        "            \"event_names\": [],\n",
        "            \"dates_times\": [],\n",
        "            \"locations\": [],\n",
        "            \"prices\": [],\n",
        "            \"categories\": [],\n",
        "            \"descriptions\": []\n",
        "        }\n",
        "\n",
        "        # Event-Namen (oft in Headlines oder als Event Name)\n",
        "        event_patterns = [\n",
        "            r'^#{2,4}\\s+(.+)$',\n",
        "            r'\\*\\*([^*]+)\\*\\*',\n",
        "            r'Event[:\\s]+([^\\n]+)',\n",
        "            r'Veranstaltung[:\\s]+([^\\n]+)',\n",
        "            r'Konzert[:\\s]+([^\\n]+)',\n",
        "            r'Festival[:\\s]+([^\\n]+)'\n",
        "        ]\n",
        "\n",
        "        for pattern in event_patterns:\n",
        "            try:\n",
        "                matches = re.findall(pattern, content, re.MULTILINE | re.IGNORECASE)\n",
        "                events_facts[\"event_names\"].extend([m.strip() for m in matches])\n",
        "            except re.error as e:\n",
        "                print(f\"    ‚ùå Regex Error in event_patterns: {pattern} - {e}\")\n",
        "                continue\n",
        "\n",
        "        # Datum und Zeit Informationen\n",
        "        datetime_patterns = [\n",
        "            r'(\\d{1,2}\\.\\d{1,2}\\.\\d{4})',\n",
        "            r'(\\d{1,2}\\.\\d{1,2}\\.)',\n",
        "            r'(\\d{1,2}:\\d{2})',\n",
        "            r'(ab\\s+\\d{1,2}:\\d{2})',\n",
        "            r'(\\w+tag,\\s+\\d{1,2}\\.\\d{1,2}\\.)',\n",
        "            r'(vom\\s+\\d{1,2}\\.\\d{1,2}\\.?\\s+bis\\s+\\d{1,2}\\.\\d{1,2}\\.?)'\n",
        "        ]\n",
        "\n",
        "        for pattern in datetime_patterns:\n",
        "            try:\n",
        "                matches = re.findall(pattern, content, re.IGNORECASE)\n",
        "                events_facts[\"dates_times\"].extend(matches)\n",
        "            except re.error as e:\n",
        "                print(f\"    ‚ùå Regex Error in datetime_patterns: {pattern} - {e}\")\n",
        "                continue\n",
        "\n",
        "        # Locations/Veranstaltungsorte\n",
        "        venue_patterns = [\n",
        "            r'(Olympiahalle|Olympiastadion|Olympiapark)',\n",
        "            r'(Marienplatz|Viktualienmarkt)',\n",
        "            r'(Englischer Garten|Isar)',\n",
        "            r'(Gasteig|Philharmonie)',\n",
        "            r'(L√∂wenbr√§ukeller|Augustiner)',\n",
        "            r'(Museum\\s+\\w+)',\n",
        "            r'Ort[:\\s]+([^\\n]+)',\n",
        "            r'Adresse[:\\s]+([^\\n]+)'\n",
        "        ]\n",
        "\n",
        "        for pattern in venue_patterns:\n",
        "            try:\n",
        "                matches = re.findall(pattern, content, re.IGNORECASE)\n",
        "                # Flache Liste f√ºr alle Matches\n",
        "                for match in matches:\n",
        "                    if isinstance(match, tuple):\n",
        "                        # Nur non-empty Gruppen nehmen\n",
        "                        for group in match:\n",
        "                            if group.strip():\n",
        "                                events_facts[\"locations\"].append(group.strip())\n",
        "                    else:\n",
        "                        events_facts[\"locations\"].append(match)\n",
        "            except re.error as e:\n",
        "                print(f\"    ‚ùå Regex Error in venue_patterns: {pattern} - {e}\")\n",
        "                continue\n",
        "\n",
        "        # Preise\n",
        "        price_patterns = [\n",
        "            r'(\\d+[,.]?\\d*\\s?‚Ç¨)',\n",
        "            r'(kostenlos|frei|gratis)',\n",
        "            r'Eintritt[:\\s]+(\\d+\\s?‚Ç¨|kostenlos|frei)',\n",
        "            r'Tickets?[:\\s]+(\\d+\\s?‚Ç¨)',\n",
        "            r'(ab\\s+\\d+\\s?‚Ç¨)'\n",
        "        ]\n",
        "\n",
        "        for pattern in price_patterns:\n",
        "            try:\n",
        "                matches = re.findall(pattern, content, re.IGNORECASE)\n",
        "                for match in matches:\n",
        "                    if isinstance(match, tuple):\n",
        "                        # Nehme erste non-empty Gruppe\n",
        "                        for group in match:\n",
        "                            if group.strip():\n",
        "                                events_facts[\"prices\"].append(group.strip())\n",
        "                                break\n",
        "                    else:\n",
        "                        events_facts[\"prices\"].append(match)\n",
        "            except re.error as e:\n",
        "                print(f\"    ‚ùå Regex Error in price_patterns: {pattern} - {e}\")\n",
        "                continue\n",
        "\n",
        "        # Event-Kategorien\n",
        "        category_keywords = [\n",
        "            'Konzert', 'Festival', 'Theater', 'Ausstellung', 'Museum',\n",
        "            'Sport', 'Markt', 'F√ºhrung', 'Workshop', 'Lesung',\n",
        "            'Kabarett', 'Oper', 'Ballet', 'Film', 'Kino'\n",
        "        ]\n",
        "\n",
        "        for keyword in category_keywords:\n",
        "            if keyword.lower() in content.lower():\n",
        "                events_facts[\"categories\"].append(keyword)\n",
        "\n",
        "        return events_facts\n",
        "\n",
        "    def _extract_sport_facts(self, content):\n",
        "        \"\"\"Extrahiert Sport-spezifische Facts\"\"\"\n",
        "        sport_facts = {\n",
        "            \"teams\": [],\n",
        "            \"scores\": [],\n",
        "            \"dates_times\": [],\n",
        "            \"leagues\": [],\n",
        "            \"players\": [],\n",
        "            \"results\": []\n",
        "        }\n",
        "\n",
        "        # Teams (besonders M√ºnchen-bezogene)\n",
        "        team_patterns = [\n",
        "            r'(FC Bayern|Bayern M√ºnchen|FCB)',\n",
        "            r'(TSV 1860|1860 M√ºnchen)',\n",
        "            r'(Red Bull M√ºnchen)',\n",
        "            r'(M√ºnchen Baskets)',\n",
        "            r'(EHC M√ºnchen)',\n",
        "            r'(\\w+\\s+M√ºnchen)',\n",
        "            r'(FC\\s+\\w+|TSV\\s+\\w+|SC\\s+\\w+)'\n",
        "        ]\n",
        "\n",
        "        for pattern in team_patterns:\n",
        "            matches = re.findall(pattern, content, re.IGNORECASE)\n",
        "            sport_facts[\"teams\"].extend(matches)\n",
        "\n",
        "        # Spielst√§nde/Ergebnisse\n",
        "        score_patterns = [\n",
        "            r'(\\d+:\\d+)',\n",
        "            r'(\\d+\\s*-\\s*\\d+)',\n",
        "            r'(\\d+\\s*zu\\s*\\d+)',\n",
        "            r'(gewonnen|verloren|unentschieden)',\n",
        "            r'(Sieg|Niederlage|Remis)'\n",
        "        ]\n",
        "\n",
        "        for pattern in score_patterns:\n",
        "            matches = re.findall(pattern, content, re.IGNORECASE)\n",
        "            sport_facts[\"scores\"].extend(matches)\n",
        "\n",
        "        # Spieltermine\n",
        "        datetime_patterns = [\n",
        "            r'(\\w+tag,\\s+\\d{1,2}\\.\\d{1,2}\\.)',\n",
        "            r'(\\d{1,2}\\.\\d{1,2}\\.\\d{4})',\n",
        "            r'(\\d{1,2}:\\d{2})',\n",
        "            r'(um\\s+\\d{1,2}:\\d{2})',\n",
        "            r'(ab\\s+\\d{1,2}:\\d{2})'\n",
        "        ]\n",
        "\n",
        "        for pattern in datetime_patterns:\n",
        "            matches = re.findall(pattern, content, re.IGNORECASE)\n",
        "            sport_facts[\"dates_times\"].extend(matches)\n",
        "\n",
        "        # Ligen/Wettbewerbe\n",
        "        league_patterns = [\n",
        "            r'(Bundesliga|Champions League|Europa League)',\n",
        "            r'(DFB-Pokal|Pokal)',\n",
        "            r'(Basketball Bundesliga|BBL)',\n",
        "            r'(DEL|Deutsche Eishockey Liga)',\n",
        "            r'(Regionalliga|Bayernliga)'\n",
        "        ]\n",
        "\n",
        "        for pattern in league_patterns:\n",
        "            matches = re.findall(pattern, content, re.IGNORECASE)\n",
        "            sport_facts[\"leagues\"].extend(matches)\n",
        "\n",
        "        return sport_facts\n",
        "\n",
        "    def _extract_traffic_facts(self, content):\n",
        "        \"\"\"Extrahiert Verkehr-spezifische Facts\"\"\"\n",
        "        traffic_facts = {\n",
        "            \"disruptions\": [],\n",
        "            \"delays\": [],\n",
        "            \"routes\": [],\n",
        "            \"stations\": [],\n",
        "            \"times\": []\n",
        "        }\n",
        "\n",
        "        # Verkehrsst√∂rungen\n",
        "        disruption_patterns = [\n",
        "            r'(St√∂rung|Ausfall|Versp√§tung|Sperrung)',\n",
        "            r'(gesperrt|blockiert|eingeschr√§nkt)',\n",
        "            r'(Bauarbeiten|Baustelle)'\n",
        "        ]\n",
        "\n",
        "        for pattern in disruption_patterns:\n",
        "            matches = re.findall(pattern, content, re.IGNORECASE)\n",
        "            traffic_facts[\"disruptions\"].extend(matches)\n",
        "\n",
        "        # MVG Linien und Stationen\n",
        "        mvg_patterns = [\n",
        "            r'(U\\d+|S\\d+|Tram\\s+\\d+|Bus\\s+\\d+)',\n",
        "            r'(Hauptbahnhof|Marienplatz|Sendlinger Tor|Odeonsplatz)'\n",
        "        ]\n",
        "\n",
        "        for pattern in mvg_patterns:\n",
        "            matches = re.findall(pattern, content, re.IGNORECASE)\n",
        "            traffic_facts[\"routes\"].extend(matches)\n",
        "\n",
        "        return traffic_facts\n",
        "\n",
        "    def _extract_generic_facts(self, content):\n",
        "        \"\"\"Extrahiert generische Facts aus Content\"\"\"\n",
        "        generic_facts = {\n",
        "            \"key_numbers\": [],\n",
        "            \"dates\": [],\n",
        "            \"locations\": [],\n",
        "            \"key_phrases\": [],\n",
        "            \"urls\": []\n",
        "        }\n",
        "\n",
        "        # Zahlen mit Kontext\n",
        "        number_patterns = [\n",
        "            r'(\\d+\\s?%)',\n",
        "            r'(\\d+[.,]\\d+)',\n",
        "            r'(\\d+\\s?Euro?)',\n",
        "            r'(\\d+\\s?Million)',\n",
        "            r'(\\d+\\s?Prozent)'\n",
        "        ]\n",
        "\n",
        "        for pattern in number_patterns:\n",
        "            matches = re.findall(pattern, content, re.IGNORECASE)\n",
        "            generic_facts[\"key_numbers\"].extend(matches)\n",
        "\n",
        "        # Generische Datumspatterns\n",
        "        date_patterns = [\n",
        "            r'(\\d{1,2}\\.\\d{1,2}\\.\\d{4})',\n",
        "            r'(\\w+\\s+\\d{4})'\n",
        "        ]\n",
        "\n",
        "        for pattern in date_patterns:\n",
        "            matches = re.findall(pattern, content)\n",
        "            generic_facts[\"dates\"].extend(matches)\n",
        "\n",
        "        return generic_facts\n",
        "\n",
        "    def _extract_citations(self, content):\n",
        "        \"\"\"Extrahiert URLs und Zitierbare Quellen\"\"\"\n",
        "        citations = []\n",
        "\n",
        "        # URLs extrahieren\n",
        "        url_pattern = r'https?://[^\\s)\\]]+|www\\.[^\\s)\\]]+'\n",
        "        urls = re.findall(url_pattern, content)\n",
        "\n",
        "        for url in urls:\n",
        "            citations.append({\n",
        "                \"type\": \"url\",\n",
        "                \"source\": url,\n",
        "                \"context\": \"\"\n",
        "            })\n",
        "\n",
        "        # Markierte Zitate (in Anf√ºhrungszeichen)\n",
        "        quote_pattern = r'\"([^\"]{10,})\"'\n",
        "        quotes = re.findall(quote_pattern, content)\n",
        "\n",
        "        for quote in quotes:\n",
        "            citations.append({\n",
        "                \"type\": \"quote\",\n",
        "                \"source\": quote,\n",
        "                \"context\": \"\"\n",
        "            })\n",
        "\n",
        "        return citations\n",
        "\n",
        "    # =========================================================================\n",
        "    # CONTENT SYNTHESIS & STRUCTURING\n",
        "    # =========================================================================\n",
        "\n",
        "    def process_all_categories(self, location):\n",
        "        \"\"\"\n",
        "        Verarbeitet alle Kategorien und extrahiert strukturierte Facts\n",
        "\n",
        "        Args:\n",
        "            location: Ortsname\n",
        "\n",
        "        Returns:\n",
        "            dict: Vollst√§ndig verarbeitete Category-Facts\n",
        "        \"\"\"\n",
        "        print(f\"üß† Verarbeite alle Category-Facts f√ºr {location}\")\n",
        "\n",
        "        # 1. Content laden\n",
        "        all_content = self.load_all_category_content(location)\n",
        "\n",
        "        # 2. Facts pro Kategorie extrahieren\n",
        "        processed_facts = {}\n",
        "\n",
        "        for category, content_items in all_content.items():\n",
        "            print(f\"  üéØ Verarbeite {category}: {len(content_items)} Sources\")\n",
        "\n",
        "            category_facts = {\n",
        "                \"category\": category,\n",
        "                \"sources_processed\": len(content_items),\n",
        "                \"worker_facts\": [],\n",
        "                \"combined_facts\": {},\n",
        "                \"citations\": [],\n",
        "                \"confidence_score\": 0.0\n",
        "            }\n",
        "\n",
        "            # Facts von allen Workern f√ºr diese Kategorie sammeln\n",
        "            for content_data in content_items:\n",
        "                worker_facts = self.extract_facts_from_content(category, content_data)\n",
        "                category_facts[\"worker_facts\"].append(worker_facts)\n",
        "\n",
        "                # Citations sammeln\n",
        "                category_facts[\"citations\"].extend(worker_facts[\"citations\"])\n",
        "\n",
        "            # 3. Facts kombinieren und deduplizieren\n",
        "            category_facts[\"combined_facts\"] = self._combine_worker_facts(\n",
        "                category, category_facts[\"worker_facts\"]\n",
        "            )\n",
        "\n",
        "            # 4. Confidence Score berechnen\n",
        "            category_facts[\"confidence_score\"] = self._calculate_confidence_score(\n",
        "                category_facts[\"worker_facts\"]\n",
        "            )\n",
        "\n",
        "            processed_facts[category] = category_facts\n",
        "\n",
        "            print(f\"    ‚úÖ {category}: {category_facts['confidence_score']:.2f} Confidence, {len(category_facts['citations'])} Citations\")\n",
        "\n",
        "        self.extracted_facts = processed_facts\n",
        "\n",
        "        print(f\"üèÅ Fact-Processing komplett: {len(processed_facts)} Kategorien\")\n",
        "        return processed_facts\n",
        "\n",
        "    def _combine_worker_facts(self, category, worker_facts_list):\n",
        "        \"\"\"Kombiniert Facts von verschiedenen Workern\"\"\"\n",
        "\n",
        "        if category == \"wetter\":\n",
        "            return self._combine_weather_facts(worker_facts_list)\n",
        "        elif category == \"nachrichten\":\n",
        "            return self._combine_news_facts(worker_facts_list)\n",
        "        elif category == \"events\":\n",
        "            return self._combine_events_facts(worker_facts_list)\n",
        "        elif category == \"sport\":\n",
        "            return self._combine_sport_facts(worker_facts_list)\n",
        "        else:\n",
        "            return self._combine_generic_facts(worker_facts_list)\n",
        "\n",
        "    def _combine_weather_facts(self, worker_facts_list):\n",
        "        \"\"\"Kombiniert Wetter-Facts von verschiedenen Workern\"\"\"\n",
        "        combined = {\n",
        "            \"temperatures\": [],\n",
        "            \"conditions\": [],\n",
        "            \"forecasts\": [],\n",
        "            \"warnings\": [],\n",
        "            \"times\": []\n",
        "        }\n",
        "\n",
        "        for worker_facts in worker_facts_list:\n",
        "            weather_data = worker_facts[\"structured_data\"]\n",
        "            for key in combined.keys():\n",
        "                if key in weather_data:\n",
        "                    combined[key].extend(weather_data[key])\n",
        "\n",
        "        # Deduplizieren\n",
        "        for key in combined.keys():\n",
        "            combined[key] = list(set(combined[key]))\n",
        "\n",
        "        return combined\n",
        "\n",
        "    def _combine_news_facts(self, worker_facts_list):\n",
        "        \"\"\"Kombiniert News-Facts von verschiedenen Workern\"\"\"\n",
        "        combined = {\n",
        "            \"headlines\": [],\n",
        "            \"dates\": [],\n",
        "            \"locations\": [],\n",
        "            \"organizations\": [],\n",
        "            \"key_statements\": []\n",
        "        }\n",
        "\n",
        "        for worker_facts in worker_facts_list:\n",
        "            news_data = worker_facts[\"structured_data\"]\n",
        "            for key in combined.keys():\n",
        "                if key in news_data:\n",
        "                    combined[key].extend(news_data[key])\n",
        "\n",
        "        # Deduplizieren und begrenzen\n",
        "        for key in combined.keys():\n",
        "            combined[key] = list(set(combined[key]))[:5]  # Maximal 5 pro Typ\n",
        "\n",
        "        return combined\n",
        "\n",
        "    def _combine_events_facts(self, worker_facts_list):\n",
        "        \"\"\"Kombiniert Events-Facts von verschiedenen Workern\"\"\"\n",
        "        combined = {\n",
        "            \"event_names\": [],\n",
        "            \"dates_times\": [],\n",
        "            \"locations\": [],\n",
        "            \"prices\": [],\n",
        "            \"categories\": []\n",
        "        }\n",
        "\n",
        "        for worker_facts in worker_facts_list:\n",
        "            events_data = worker_facts[\"structured_data\"]\n",
        "            for key in combined.keys():\n",
        "                if key in events_data:\n",
        "                    combined[key].extend(events_data[key])\n",
        "\n",
        "        # Deduplizieren\n",
        "        for key in combined.keys():\n",
        "            combined[key] = list(set(combined[key]))\n",
        "\n",
        "        return combined\n",
        "\n",
        "    def _combine_sport_facts(self, worker_facts_list):\n",
        "        \"\"\"Kombiniert Sport-Facts von verschiedenen Workern\"\"\"\n",
        "        combined = {\n",
        "            \"teams\": [],\n",
        "            \"scores\": [],\n",
        "            \"dates_times\": [],\n",
        "            \"leagues\": [],\n",
        "            \"results\": []\n",
        "        }\n",
        "\n",
        "        for worker_facts in worker_facts_list:\n",
        "            sport_data = worker_facts[\"structured_data\"]\n",
        "            for key in combined.keys():\n",
        "                if key in sport_data:\n",
        "                    combined[key].extend(sport_data[key])\n",
        "\n",
        "        # Deduplizieren\n",
        "        for key in combined.keys():\n",
        "            combined[key] = list(set(combined[key]))\n",
        "\n",
        "        return combined\n",
        "\n",
        "    def _combine_generic_facts(self, worker_facts_list):\n",
        "        \"\"\"Kombiniert generische Facts\"\"\"\n",
        "        combined = {\n",
        "            \"key_numbers\": [],\n",
        "            \"dates\": [],\n",
        "            \"locations\": [],\n",
        "            \"key_phrases\": []\n",
        "        }\n",
        "\n",
        "        for worker_facts in worker_facts_list:\n",
        "            generic_data = worker_facts[\"structured_data\"]\n",
        "            for key in combined.keys():\n",
        "                if key in generic_data:\n",
        "                    combined[key].extend(generic_data[key])\n",
        "\n",
        "        return combined\n",
        "\n",
        "    def _calculate_confidence_score(self, worker_facts_list):\n",
        "        \"\"\"Berechnet Confidence Score basierend auf Worker-√úbereinstimmung\"\"\"\n",
        "\n",
        "        # Basis-Score: Anzahl Worker\n",
        "        base_score = min(len(worker_facts_list) * 0.3, 1.0)\n",
        "\n",
        "        # Bonus f√ºr Citations\n",
        "        total_citations = sum(len(wf[\"citations\"]) for wf in worker_facts_list)\n",
        "        citation_bonus = min(total_citations * 0.1, 0.3)\n",
        "\n",
        "        # Bonus f√ºr strukturierte Daten\n",
        "        structured_bonus = 0.0\n",
        "        for worker_facts in worker_facts_list:\n",
        "            if worker_facts[\"structured_data\"]:\n",
        "                structured_bonus += 0.2\n",
        "\n",
        "        structured_bonus = min(structured_bonus, 0.4)\n",
        "\n",
        "        total_score = min(base_score + citation_bonus + structured_bonus, 1.0)\n",
        "        return round(total_score, 2)\n",
        "\n",
        "    # =========================================================================\n",
        "    # NEWSLETTER CONTENT PREPARATION\n",
        "    # =========================================================================\n",
        "\n",
        "    def prepare_content_for_newsletter(self, location, newsletter_style=\"standard\"):\n",
        "        \"\"\"\n",
        "        Bereitet verarbeitete Facts f√ºr Newsletter-Generation vor\n",
        "\n",
        "        Args:\n",
        "            location: Ortsname\n",
        "            newsletter_style: \"compact\", \"standard\", \"detailed\"\n",
        "\n",
        "        Returns:\n",
        "            dict: Newsletter-ready Content Structure\n",
        "        \"\"\"\n",
        "        print(f\"üì∞ Bereite Content f√ºr {newsletter_style} Newsletter vor\")\n",
        "\n",
        "        if not self.extracted_facts:\n",
        "            print(\"  ‚ö†Ô∏è Keine Facts verf√ºgbar - f√ºhre erst process_all_categories() aus\")\n",
        "            return None\n",
        "\n",
        "        newsletter_content = {\n",
        "            \"location\": location,\n",
        "            \"newsletter_style\": newsletter_style,\n",
        "            \"timestamp\": datetime.now().isoformat(),\n",
        "            \"categories\": {},\n",
        "            \"total_facts\": 0,\n",
        "            \"total_citations\": 0\n",
        "        }\n",
        "\n",
        "        for category, facts_data in self.extracted_facts.items():\n",
        "\n",
        "            # Content-Level basierend auf Style bestimmen\n",
        "            if newsletter_style == \"compact\":\n",
        "                content_level = \"minimal\"\n",
        "                max_facts_per_category = 2\n",
        "                include_citations = False\n",
        "\n",
        "            elif newsletter_style == \"standard\":\n",
        "                content_level = \"balanced\"\n",
        "                max_facts_per_category = 5\n",
        "                include_citations = False\n",
        "\n",
        "            elif newsletter_style == \"detailed\":\n",
        "                content_level = \"comprehensive\"\n",
        "                max_facts_per_category = 10\n",
        "                include_citations = True\n",
        "\n",
        "            # Category Content strukturieren\n",
        "            category_content = {\n",
        "                \"category\": category,\n",
        "                \"confidence_score\": facts_data[\"confidence_score\"],\n",
        "                \"sources_count\": facts_data[\"sources_processed\"],\n",
        "                \"content_level\": content_level,\n",
        "                \"facts\": self._select_best_facts(\n",
        "                    facts_data[\"combined_facts\"],\n",
        "                    max_facts_per_category\n",
        "                ),\n",
        "                \"citations\": facts_data[\"citations\"][:3] if include_citations else [],\n",
        "                \"newsletter_text_snippets\": self._generate_text_snippets(\n",
        "                    category,\n",
        "                    facts_data[\"combined_facts\"],\n",
        "                    content_level\n",
        "                )\n",
        "            }\n",
        "\n",
        "            newsletter_content[\"categories\"][category] = category_content\n",
        "            newsletter_content[\"total_facts\"] += len(category_content[\"facts\"])\n",
        "            newsletter_content[\"total_citations\"] += len(category_content[\"citations\"])\n",
        "\n",
        "        print(f\"  üìä Newsletter Content bereit:\")\n",
        "        print(f\"    Style: {newsletter_style}\")\n",
        "        print(f\"    Kategorien: {len(newsletter_content['categories'])}\")\n",
        "        print(f\"    Total Facts: {newsletter_content['total_facts']}\")\n",
        "        print(f\"    Total Citations: {newsletter_content['total_citations']}\")\n",
        "\n",
        "        return newsletter_content\n",
        "\n",
        "    def _select_best_facts(self, combined_facts, max_facts):\n",
        "        \"\"\"W√§hlt die besten/relevantesten Facts aus\"\"\"\n",
        "\n",
        "        best_facts = []\n",
        "\n",
        "        # Priorisierung nach Fact-Typ und Relevanz\n",
        "        for fact_type, facts_list in combined_facts.items():\n",
        "            if not facts_list:\n",
        "                continue\n",
        "\n",
        "            # Priorisierung nach Kategorie\n",
        "            priority_map = {\n",
        "                \"temperatures\": 1,\n",
        "                \"event_names\": 1,\n",
        "                \"teams\": 1,\n",
        "                \"headlines\": 1,\n",
        "                \"conditions\": 2,\n",
        "                \"scores\": 2,\n",
        "                \"dates\": 2,\n",
        "                \"key_statements\": 2,\n",
        "                \"locations\": 3,\n",
        "                \"prices\": 3\n",
        "            }\n",
        "\n",
        "            priority = priority_map.get(fact_type, 4)\n",
        "\n",
        "            # Beste Facts aus dieser Kategorie nehmen\n",
        "            for fact in facts_list[:2]:  # Max 2 pro Fact-Type\n",
        "                if len(best_facts) < max_facts:\n",
        "                    best_facts.append({\n",
        "                        \"type\": fact_type,\n",
        "                        \"value\": fact,\n",
        "                        \"priority\": priority\n",
        "                    })\n",
        "\n",
        "        # Nach Priorit√§t sortieren\n",
        "        best_facts.sort(key=lambda x: x[\"priority\"])\n",
        "\n",
        "        return best_facts[:max_facts]\n",
        "\n",
        "    def _generate_text_snippets(self, category, combined_facts, content_level):\n",
        "        \"\"\"Generiert Text-Snippets f√ºr Newsletter-Integration\"\"\"\n",
        "\n",
        "        snippets = []\n",
        "\n",
        "        if category == \"wetter\" and combined_facts.get(\"temperatures\"):\n",
        "            temp_info = combined_facts[\"temperatures\"][0] if combined_facts[\"temperatures\"] else \"\"\n",
        "            conditions = combined_facts.get(\"conditions\", [\"\"])\n",
        "            condition_info = conditions[0] if conditions else \"\"\n",
        "\n",
        "            if content_level == \"minimal\":\n",
        "                snippets.append(f\"Heute {temp_info}\")\n",
        "            elif content_level == \"balanced\":\n",
        "                snippets.append(f\"Heute {temp_info} mit {condition_info} Wetter\")\n",
        "            else:\n",
        "                times = combined_facts.get(\"times\", [])\n",
        "                time_info = f\" {times[0]}\" if times else \"\"\n",
        "                snippets.append(f\"Heute{time_info} {temp_info} mit {condition_info} Bedingungen\")\n",
        "\n",
        "        elif category == \"events\" and combined_facts.get(\"event_names\"):\n",
        "            events = combined_facts[\"event_names\"][:2]\n",
        "            locations = combined_facts.get(\"locations\", [])\n",
        "\n",
        "            if content_level == \"minimal\":\n",
        "                snippets.append(f\"Events: {', '.join(events[:1])}\")\n",
        "            elif content_level == \"balanced\":\n",
        "                location_info = f\" im {locations[0]}\" if locations else \"\"\n",
        "                snippets.append(f\"Events: {', '.join(events)}{location_info}\")\n",
        "            else:\n",
        "                prices = combined_facts.get(\"prices\", [])\n",
        "                dates = combined_facts.get(\"dates_times\", [])\n",
        "                price_info = f\" (ab {prices[0]})\" if prices else \"\"\n",
        "                date_info = f\" am {dates[0]}\" if dates else \"\"\n",
        "                snippets.append(f\"Events: {events[0]}{date_info}{price_info}\")\n",
        "\n",
        "        elif category == \"sport\" and combined_facts.get(\"teams\"):\n",
        "            teams = combined_facts[\"teams\"][:2]\n",
        "            scores = combined_facts.get(\"scores\", [])\n",
        "\n",
        "            if content_level == \"minimal\":\n",
        "                snippets.append(f\"Sport: {teams[0]}\")\n",
        "            elif content_level == \"balanced\":\n",
        "                score_info = f\" ({scores[0]})\" if scores else \"\"\n",
        "                snippets.append(f\"Sport: {', '.join(teams)}{score_info}\")\n",
        "            else:\n",
        "                leagues = combined_facts.get(\"leagues\", [])\n",
        "                dates = combined_facts.get(\"dates_times\", [])\n",
        "                league_info = f\" in der {leagues[0]}\" if leagues else \"\"\n",
        "                date_info = f\" am {dates[0]}\" if dates else \"\"\n",
        "                snippets.append(f\"{teams[0]}{league_info}{date_info}\")\n",
        "\n",
        "        elif category == \"nachrichten\" and combined_facts.get(\"key_statements\"):\n",
        "            statements = combined_facts[\"key_statements\"][:2]\n",
        "\n",
        "            if content_level == \"minimal\":\n",
        "                snippets.append(statements[0][:50] + \"...\" if statements else \"\")\n",
        "            else:\n",
        "                snippets.extend(statements[:2 if content_level == \"balanced\" else 3])\n",
        "\n",
        "        return [s for s in snippets if s]  # Leere Snippets entfernen\n",
        "\n",
        "    # =========================================================================\n",
        "    # UTILITY METHODS\n",
        "    # =========================================================================\n",
        "\n",
        "    def get_processing_summary(self):\n",
        "        \"\"\"Gibt Zusammenfassung der Content-Processing zur√ºck\"\"\"\n",
        "\n",
        "        if not self.extracted_facts:\n",
        "            return {\"status\": \"no_processing_done\"}\n",
        "\n",
        "        summary = {\n",
        "            \"status\": \"processed\",\n",
        "            \"categories_processed\": len(self.extracted_facts),\n",
        "            \"total_sources\": sum(f[\"sources_processed\"] for f in self.extracted_facts.values()),\n",
        "            \"average_confidence\": sum(f[\"confidence_score\"] for f in self.extracted_facts.values()) / len(self.extracted_facts),\n",
        "            \"total_citations\": sum(len(f[\"citations\"]) for f in self.extracted_facts.values()),\n",
        "            \"categories\": {}\n",
        "        }\n",
        "\n",
        "        for category, facts_data in self.extracted_facts.items():\n",
        "            summary[\"categories\"][category] = {\n",
        "                \"sources\": facts_data[\"sources_processed\"],\n",
        "                \"confidence\": facts_data[\"confidence_score\"],\n",
        "                \"citations\": len(facts_data[\"citations\"]),\n",
        "                \"fact_types\": len(facts_data[\"combined_facts\"])\n",
        "            }\n",
        "\n",
        "        return summary\n",
        "\n",
        "# =============================================================================\n",
        "# INITIALISIERUNG UND INTEGRATION\n",
        "# =============================================================================\n",
        "\n",
        "# Enhanced Content Processor mit Foundation-System initialisieren\n",
        "foundation_available = all([\n",
        "    'persistence_manager' in globals() and persistence_manager,\n",
        "    'config_manager' in globals() and config_manager\n",
        "])\n",
        "\n",
        "if foundation_available:\n",
        "    enhanced_content_processor = EnhancedContentProcessor(\n",
        "        persistence_manager=persistence_manager,\n",
        "        config_manager=config_manager\n",
        "    )\n",
        "    print(\"üöÄ Enhanced Content Processor mit Foundation-System bereit\")\n",
        "    print(\"üìä Integration: Kann alle gesammelten Markdown-Files verarbeiten\")\n",
        "    print(\"üß† Capabilities: Fact-Extraction + Content-Synthesis + Newsletter-Preparation\")\n",
        "\n",
        "else:\n",
        "    print(\"‚ùå Enhanced Content Processor nicht verf√ºgbar - Foundation-System fehlt\")\n",
        "    enhanced_content_processor = None\n",
        "\n",
        "print(\"=\" * 70)\n",
        "print(\"‚úÖ Zelle 5a: Enhanced Content Processor Setup komplett\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "id": "GeWEGTfayN4R",
        "outputId": "b5e06b3e-638a-4824-d678-2619f7f0a13e"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Enhanced Content Processor initialisiert\n",
            "üèóÔ∏è Integration: DataPersistenceManager + ContentExtraction\n",
            "üöÄ Enhanced Content Processor mit Foundation-System bereit\n",
            "üìä Integration: Kann alle gesammelten Markdown-Files verarbeiten\n",
            "üß† Capabilities: Fact-Extraction + Content-Synthesis + Newsletter-Preparation\n",
            "======================================================================\n",
            "‚úÖ Zelle 5a: Enhanced Content Processor Setup komplett\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# ZELLE 5a: Simple Content Processor - Einfache Alternative f√ºr Newsletter-Enhancement\n",
        "# =============================================================================\n",
        "# @title Simple Content Processor - Direkte Markdown-Integration statt komplexer Regex\n",
        "\n",
        "import re\n",
        "from pathlib import Path\n",
        "from datetime import datetime\n",
        "\n",
        "class SimpleContentProcessor:\n",
        "    \"\"\"\n",
        "    Simple Content Processor - Einfache Alternative zum Enhanced Content Processor\n",
        "    - L√§dt Markdown-Files direkt\n",
        "    - Extrahiert nur wichtige Facts (Zahlen, Daten, URLs)\n",
        "    - √úbergibt rohen Content an Gemini f√ºr intelligente Verarbeitung\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, persistence_manager):\n",
        "        \"\"\"\n",
        "        Initialisiert Simple Content Processor\n",
        "\n",
        "        Args:\n",
        "            persistence_manager: DataPersistenceManager Instance\n",
        "        \"\"\"\n",
        "        self.persistence_manager = persistence_manager\n",
        "        self.processed_content = {}\n",
        "\n",
        "        print(f\"‚úÖ Simple Content Processor initialisiert\")\n",
        "        print(f\"üìä Konzept: Direkte Markdown-Integration + LLM-basierte Fact-Extraction\")\n",
        "\n",
        "    # =========================================================================\n",
        "    # SIMPLE CONTENT LOADING\n",
        "    # =========================================================================\n",
        "\n",
        "    def load_all_content_for_newsletter(self, location, newsletter_style=\"standard\"):\n",
        "        \"\"\"\n",
        "        L√§dt allen Content und bereitet ihn f√ºr Newsletter-Stil vor\n",
        "\n",
        "        Args:\n",
        "            location: Ortsname\n",
        "            newsletter_style: \"compact\", \"standard\", \"detailed\"\n",
        "\n",
        "        Returns:\n",
        "            dict: Newsletter-ready Content\n",
        "        \"\"\"\n",
        "        print(f\"üìÇ Lade Content f√ºr {newsletter_style} Newsletter\")\n",
        "\n",
        "        # Alle Content-Items aus Registry laden\n",
        "        all_content = {}\n",
        "        total_chars = 0\n",
        "\n",
        "        for content_item in self.persistence_manager.content_registry:\n",
        "            category = content_item[\"category\"]\n",
        "\n",
        "            if category not in all_content:\n",
        "                all_content[category] = {\n",
        "                    \"sources\": [],\n",
        "                    \"total_content\": \"\",\n",
        "                    \"key_facts\": [],\n",
        "                    \"source_count\": 0\n",
        "                }\n",
        "\n",
        "            # Content-File lesen\n",
        "            try:\n",
        "                filepath = Path(content_item[\"filepath\"])\n",
        "                if filepath.exists():\n",
        "                    with open(filepath, 'r', encoding='utf-8') as f:\n",
        "                        content = f.read()\n",
        "\n",
        "                    # Source Info\n",
        "                    source_info = {\n",
        "                        \"source\": content_item.get(\"source\", \"unknown\"),\n",
        "                        \"filename\": content_item[\"filename\"],\n",
        "                        \"content\": content,\n",
        "                        \"char_count\": len(content)\n",
        "                    }\n",
        "\n",
        "                    all_content[category][\"sources\"].append(source_info)\n",
        "                    all_content[category][\"source_count\"] += 1\n",
        "                    total_chars += len(content)\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"  ‚ùå Fehler beim Laden: {content_item['filename']}\")\n",
        "                continue\n",
        "\n",
        "        # Content f√ºr Newsletter-Stil aufbereiten\n",
        "        newsletter_content = self._prepare_for_newsletter_style(all_content, newsletter_style)\n",
        "\n",
        "        print(f\"  üìä Kategorien: {len(all_content)}\")\n",
        "        print(f\"  üìù Total Content: {total_chars:,} Zeichen\")\n",
        "        print(f\"  üé® Style: {newsletter_style}\")\n",
        "\n",
        "        return newsletter_content\n",
        "\n",
        "    def _prepare_for_newsletter_style(self, all_content, newsletter_style):\n",
        "        \"\"\"Bereitet Content f√ºr spezifischen Newsletter-Stil auf\"\"\"\n",
        "\n",
        "        newsletter_content = {\n",
        "            \"style\": newsletter_style,\n",
        "            \"timestamp\": datetime.now().isoformat(),\n",
        "            \"categories\": {},\n",
        "            \"total_sources\": 0,\n",
        "            \"content_limits\": self._get_content_limits(newsletter_style)\n",
        "        }\n",
        "\n",
        "        for category, content_data in all_content.items():\n",
        "\n",
        "            # Style-spezifische Limits\n",
        "            limits = newsletter_content[\"content_limits\"]\n",
        "\n",
        "            # Key Facts extrahieren (einfach!)\n",
        "            key_facts = self._extract_simple_facts(content_data[\"sources\"])\n",
        "\n",
        "            # Content zusammenfassen basierend auf Stil\n",
        "            if newsletter_style == \"compact\":\n",
        "                # Nur wichtigste Facts\n",
        "                prepared_content = self._prepare_compact_content(content_data, key_facts)\n",
        "\n",
        "            elif newsletter_style == \"standard\":\n",
        "                # Facts + erste Abs√§tze von jedem Source\n",
        "                prepared_content = self._prepare_standard_content(content_data, key_facts)\n",
        "\n",
        "            elif newsletter_style == \"detailed\":\n",
        "                # Alles + URLs + vollst√§ndige Quellen\n",
        "                prepared_content = self._prepare_detailed_content(content_data, key_facts)\n",
        "\n",
        "            newsletter_content[\"categories\"][category] = prepared_content\n",
        "            newsletter_content[\"total_sources\"] += content_data[\"source_count\"]\n",
        "\n",
        "        return newsletter_content\n",
        "\n",
        "    def _get_content_limits(self, style):\n",
        "        \"\"\"Gibt Style-spezifische Limits zur√ºck\"\"\"\n",
        "        limits = {\n",
        "            \"compact\": {\n",
        "                \"max_facts_per_category\": 3,\n",
        "                \"max_content_chars\": 500,\n",
        "                \"include_sources\": False,\n",
        "                \"include_urls\": False\n",
        "            },\n",
        "            \"standard\": {\n",
        "                \"max_facts_per_category\": 6,\n",
        "                \"max_content_chars\": 1500,\n",
        "                \"include_sources\": False,\n",
        "                \"include_urls\": False\n",
        "            },\n",
        "            \"detailed\": {\n",
        "                \"max_facts_per_category\": 12,\n",
        "                \"max_content_chars\": 3000,\n",
        "                \"include_sources\": True,\n",
        "                \"include_urls\": True\n",
        "            }\n",
        "        }\n",
        "        return limits.get(style, limits[\"standard\"])\n",
        "\n",
        "    # =========================================================================\n",
        "    # SIMPLE FACT EXTRACTION (statt komplexer Regex)\n",
        "    # =========================================================================\n",
        "\n",
        "    def _extract_simple_facts(self, sources):\n",
        "        \"\"\"\n",
        "        Einfache Fact-Extraction - findet Zahlen, Daten, wichtige Keywords\n",
        "\n",
        "        Args:\n",
        "            sources: Liste von Source-Content\n",
        "\n",
        "        Returns:\n",
        "            list: Einfache Facts (Strings mit Kontext)\n",
        "        \"\"\"\n",
        "        all_facts = []\n",
        "\n",
        "        for source in sources:\n",
        "            content = source[\"content\"]\n",
        "\n",
        "            # Split in Zeilen f√ºr einfachere Verarbeitung\n",
        "            lines = content.split('\\n')\n",
        "\n",
        "            for line in lines:\n",
        "                line = line.strip()\n",
        "                if len(line) < 10:  # Zu kurze Zeilen ignorieren\n",
        "                    continue\n",
        "\n",
        "                # Einfache Fact-Patterns (viel simpler als vorher!)\n",
        "                is_fact = False\n",
        "\n",
        "                # Zahlen mit Einheiten (Temp, Geld, Prozent, Zeit)\n",
        "                if re.search(r'\\d+[¬∞‚Ç¨%]\\w*|\\d{1,2}:\\d{2}|\\d{1,2}\\.\\d{1,2}\\.', line):\n",
        "                    is_fact = True\n",
        "\n",
        "                # Datumsangaben\n",
        "                if re.search(r'heute|morgen|montag|dienstag|mittwoch|donnerstag|freitag|samstag|sonntag', line.lower()):\n",
        "                    is_fact = True\n",
        "\n",
        "                # Wichtige Keywords\n",
        "                important_keywords = [\n",
        "                    'er√∂ffnet', 'startet', 'beginnt', 'findet statt', 'kostenlos',\n",
        "                    'Eintritt', 'Tickets', 'Anmeldung', 'Termin', 'Uhr'\n",
        "                ]\n",
        "                if any(keyword.lower() in line.lower() for keyword in important_keywords):\n",
        "                    is_fact = True\n",
        "\n",
        "                # Kurze, pr√§gnante S√§tze (oft Facts)\n",
        "                if len(line.split()) <= 15 and ('.' in line or '!' in line):\n",
        "                    is_fact = True\n",
        "\n",
        "                if is_fact:\n",
        "                    all_facts.append({\n",
        "                        \"text\": line,\n",
        "                        \"source\": source[\"source\"],\n",
        "                        \"char_count\": len(line)\n",
        "                    })\n",
        "\n",
        "        # Sortiere nach Relevanz (kurze, pr√§gnante Facts zuerst)\n",
        "        all_facts.sort(key=lambda x: len(x[\"text\"]))\n",
        "\n",
        "        return all_facts\n",
        "\n",
        "    def _prepare_compact_content(self, content_data, key_facts):\n",
        "        \"\"\"Compact Content: Nur wichtigste Facts\"\"\"\n",
        "        return {\n",
        "            \"category_summary\": f\"{content_data['source_count']} Quellen verf√ºgbar\",\n",
        "            \"key_facts\": key_facts[:3],  # Top 3 Facts\n",
        "            \"content_snippets\": [],\n",
        "            \"source_info\": f\"{content_data['source_count']} Sources\",\n",
        "            \"urls\": []\n",
        "        }\n",
        "\n",
        "    def _prepare_standard_content(self, content_data, key_facts):\n",
        "        \"\"\"Standard Content: Facts + Content-Snippets\"\"\"\n",
        "\n",
        "        # Erste Abs√§tze von jedem Source\n",
        "        content_snippets = []\n",
        "        for source in content_data[\"sources\"]:\n",
        "            # Ersten sinnvollen Absatz finden\n",
        "            paragraphs = source[\"content\"].split('\\n\\n')\n",
        "            for paragraph in paragraphs:\n",
        "                if len(paragraph.strip()) > 50:  # Sinnvolle L√§nge\n",
        "                    snippet = paragraph.strip()[:300]  # Ersten 300 Zeichen\n",
        "                    if len(paragraph) > 300:\n",
        "                        snippet += \"...\"\n",
        "                    content_snippets.append({\n",
        "                        \"text\": snippet,\n",
        "                        \"source\": source[\"source\"]\n",
        "                    })\n",
        "                    break\n",
        "\n",
        "        return {\n",
        "            \"category_summary\": f\"{content_data['source_count']} Quellen analysiert\",\n",
        "            \"key_facts\": key_facts[:6],  # Top 6 Facts\n",
        "            \"content_snippets\": content_snippets,\n",
        "            \"source_info\": f\"{content_data['source_count']} verschiedene Datenquellen\",\n",
        "            \"urls\": []\n",
        "        }\n",
        "\n",
        "    def _prepare_detailed_content(self, content_data, key_facts):\n",
        "        \"\"\"Detailed Content: Alles + URLs + Quellen\"\"\"\n",
        "\n",
        "        # L√§ngere Content-Snippets\n",
        "        content_snippets = []\n",
        "        urls = []\n",
        "\n",
        "        for source in content_data[\"sources\"]:\n",
        "            # L√§ngere Snippets f√ºr detailed\n",
        "            paragraphs = source[\"content\"].split('\\n\\n')\n",
        "            combined_content = \"\"\n",
        "\n",
        "            for paragraph in paragraphs[:3]:  # Erste 3 Abs√§tze\n",
        "                if len(paragraph.strip()) > 20:\n",
        "                    combined_content += paragraph.strip() + \"\\n\\n\"\n",
        "\n",
        "            if combined_content:\n",
        "                snippet = combined_content[:800]  # Erste 800 Zeichen\n",
        "                if len(combined_content) > 800:\n",
        "                    snippet += \"...\"\n",
        "\n",
        "                content_snippets.append({\n",
        "                    \"text\": snippet,\n",
        "                    \"source\": source[\"source\"],\n",
        "                    \"filename\": source[\"filename\"]\n",
        "                })\n",
        "\n",
        "            # URLs extrahieren\n",
        "            url_matches = re.findall(r'https?://[^\\s\\)]+', source[\"content\"])\n",
        "            urls.extend(url_matches[:2])  # Max 2 URLs per source\n",
        "\n",
        "        return {\n",
        "            \"category_summary\": f\"{content_data['source_count']} Quellen detailliert analysiert\",\n",
        "            \"key_facts\": key_facts[:12],  # Alle relevanten Facts\n",
        "            \"content_snippets\": content_snippets,\n",
        "            \"source_info\": f\"{content_data['source_count']} Datenquellen: \" + \", \".join([s[\"source\"] for s in content_data[\"sources\"]]),\n",
        "            \"urls\": list(set(urls))  # Deduplizierte URLs\n",
        "        }\n",
        "\n",
        "    # =========================================================================\n",
        "    # GEMINI-READY CONTENT FORMATTING\n",
        "    # =========================================================================\n",
        "\n",
        "    def format_for_gemini_prompt(self, newsletter_content, location):\n",
        "        \"\"\"\n",
        "        Formatiert Content f√ºr Gemini Newsletter-Prompt\n",
        "\n",
        "        Args:\n",
        "            newsletter_content: Vorbereiteter Newsletter Content\n",
        "            location: Ortsname\n",
        "\n",
        "        Returns:\n",
        "            str: Gemini-ready Content-Section f√ºr Prompt\n",
        "        \"\"\"\n",
        "        style = newsletter_content[\"style\"]\n",
        "\n",
        "        formatted_content = f\"\"\"\n",
        "VERF√úGBARE CONTENT-DATEN F√úR {location.upper()} ({style.upper()} STYLE):\n",
        "Quellen insgesamt: {newsletter_content['total_sources']}\n",
        "Kategorien: {len(newsletter_content['categories'])}\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "        for category, content_data in newsletter_content[\"categories\"].items():\n",
        "            formatted_content += f\"\"\"\n",
        "=== {category.upper()} ===\n",
        "{content_data['category_summary']}\n",
        "\n",
        "Key Facts:\"\"\"\n",
        "\n",
        "            for i, fact in enumerate(content_data[\"key_facts\"], 1):\n",
        "                formatted_content += f\"\"\"\n",
        "{i}. {fact['text']} (Quelle: {fact['source']})\"\"\"\n",
        "\n",
        "            if content_data[\"content_snippets\"]:\n",
        "                formatted_content += f\"\"\"\n",
        "\n",
        "Content-Zusammenfassung:\"\"\"\n",
        "                for snippet in content_data[\"content_snippets\"]:\n",
        "                    formatted_content += f\"\"\"\n",
        "‚Ä¢ {snippet['text'][:200]}... (von {snippet['source']})\"\"\"\n",
        "\n",
        "            if style == \"detailed\" and content_data.get(\"urls\"):\n",
        "                formatted_content += f\"\"\"\n",
        "\n",
        "Referenz-URLs:\"\"\"\n",
        "                for url in content_data[\"urls\"][:3]:\n",
        "                    formatted_content += f\"\"\"\n",
        "- {url}\"\"\"\n",
        "\n",
        "            formatted_content += \"\\n\"\n",
        "\n",
        "        formatted_content += f\"\"\"\n",
        "ANWEISUNG: Nutze diese konkreten Facts und Content-Snippets f√ºr einen {style} Newsletter!\"\"\"\n",
        "\n",
        "        return formatted_content\n",
        "\n",
        "    # =========================================================================\n",
        "    # UTILITY METHODS\n",
        "    # =========================================================================\n",
        "\n",
        "    def get_content_summary(self, location):\n",
        "        \"\"\"Gibt Simple Content Summary zur√ºck\"\"\"\n",
        "\n",
        "        if location not in self.processed_content:\n",
        "            return {\"status\": \"no_content_processed\"}\n",
        "\n",
        "        content = self.processed_content[location]\n",
        "\n",
        "        summary = {\n",
        "            \"location\": location,\n",
        "            \"style\": content.get(\"style\", \"unknown\"),\n",
        "            \"categories\": len(content.get(\"categories\", {})),\n",
        "            \"total_sources\": content.get(\"total_sources\", 0),\n",
        "            \"total_facts\": sum(len(cat.get(\"key_facts\", [])) for cat in content.get(\"categories\", {}).values()),\n",
        "            \"processing_method\": \"simple_direct_content\"\n",
        "        }\n",
        "\n",
        "        return summary\n",
        "\n",
        "# =============================================================================\n",
        "# INITIALISIERUNG\n",
        "# =============================================================================\n",
        "\n",
        "# Simple Content Processor initialisieren\n",
        "if 'persistence_manager' in globals() and persistence_manager:\n",
        "    simple_content_processor = SimpleContentProcessor(\n",
        "        persistence_manager=persistence_manager\n",
        "    )\n",
        "    print(\"üöÄ Simple Content Processor bereit\")\n",
        "    print(\"üìä Methode: Direkte Markdown-Integration statt komplexer Regex\")\n",
        "    print(\"üéØ Vorteile: Einfach, wartbar, LLM-basierte Intelligenz\")\n",
        "\n",
        "else:\n",
        "    print(\"‚ùå Simple Content Processor nicht verf√ºgbar - DataPersistenceManager fehlt\")\n",
        "    simple_content_processor = None\n",
        "\n",
        "# =============================================================================\n",
        "# DIREKTER TEST\n",
        "# =============================================================================\n",
        "\n",
        "if simple_content_processor:\n",
        "    print(\"\\nüß™ TESTE SIMPLE CONTENT PROCESSOR\")\n",
        "    print(\"=\" * 50)\n",
        "\n",
        "    try:\n",
        "        test_location = \"m√ºnchen\"\n",
        "\n",
        "        # Test 1: Content Loading f√ºr verschiedene Styles\n",
        "        print(\"üìç Test 1: Content Loading\")\n",
        "\n",
        "        for style in [\"compact\", \"standard\", \"detailed\"]:\n",
        "            print(f\"\\n  üé® Style: {style}\")\n",
        "            content = simple_content_processor.load_all_content_for_newsletter(test_location, style)\n",
        "\n",
        "            if content:\n",
        "                print(f\"    ‚úÖ Kategorien: {len(content['categories'])}\")\n",
        "                print(f\"    üìä Sources: {content['total_sources']}\")\n",
        "\n",
        "                # Beispiel einer Kategorie zeigen\n",
        "                if content['categories']:\n",
        "                    example_cat = list(content['categories'].keys())[0]\n",
        "                    cat_data = content['categories'][example_cat]\n",
        "                    print(f\"    üìù {example_cat}: {len(cat_data['key_facts'])} Facts, {len(cat_data['content_snippets'])} Snippets\")\n",
        "\n",
        "        # Test 2: Gemini-Prompt Formatting\n",
        "        print(f\"\\nüìç Test 2: Gemini-Prompt Formatting\")\n",
        "        standard_content = simple_content_processor.load_all_content_for_newsletter(test_location, \"standard\")\n",
        "\n",
        "        if standard_content:\n",
        "            prompt_section = simple_content_processor.format_for_gemini_prompt(standard_content, test_location)\n",
        "            print(f\"    ‚úÖ Prompt-Section generiert: {len(prompt_section)} Zeichen\")\n",
        "            print(f\"    üëÄ Preview:\")\n",
        "            preview = prompt_section[:300] + \"...\" if len(prompt_section) > 300 else prompt_section\n",
        "            print(f\"    {preview}\")\n",
        "\n",
        "        print(f\"\\n‚úÖ Simple Content Processor Tests erfolgreich!\")\n",
        "        print(f\"üí° Viel einfacher als Enhanced Content Processor!\")\n",
        "\n",
        "    except Exception as test_error:\n",
        "        print(f\"‚ùå Test Fehler: {test_error}\")\n",
        "        import traceback\n",
        "        print(f\"üîç Traceback: {traceback.format_exc()}\")\n",
        "\n",
        "print(\"=\" * 50)\n",
        "print(\"‚úÖ Simple Content Processor Setup komplett\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "id": "U8Z74h6n0GR_",
        "outputId": "f540b8a5-e72c-45a2-ff91-c1a823a3edbc"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Simple Content Processor initialisiert\n",
            "üìä Konzept: Direkte Markdown-Integration + LLM-basierte Fact-Extraction\n",
            "üöÄ Simple Content Processor bereit\n",
            "üìä Methode: Direkte Markdown-Integration statt komplexer Regex\n",
            "üéØ Vorteile: Einfach, wartbar, LLM-basierte Intelligenz\n",
            "\n",
            "üß™ TESTE SIMPLE CONTENT PROCESSOR\n",
            "==================================================\n",
            "üìç Test 1: Content Loading\n",
            "\n",
            "  üé® Style: compact\n",
            "üìÇ Lade Content f√ºr compact Newsletter\n",
            "  üìä Kategorien: 6\n",
            "  üìù Total Content: 22,821 Zeichen\n",
            "  üé® Style: compact\n",
            "    ‚úÖ Kategorien: 6\n",
            "    üìä Sources: 7\n",
            "    üìù wetter: 3 Facts, 0 Snippets\n",
            "\n",
            "  üé® Style: standard\n",
            "üìÇ Lade Content f√ºr standard Newsletter\n",
            "  üìä Kategorien: 6\n",
            "  üìù Total Content: 22,821 Zeichen\n",
            "  üé® Style: standard\n",
            "    ‚úÖ Kategorien: 6\n",
            "    üìä Sources: 7\n",
            "    üìù wetter: 6 Facts, 2 Snippets\n",
            "\n",
            "  üé® Style: detailed\n",
            "üìÇ Lade Content f√ºr detailed Newsletter\n",
            "  üìä Kategorien: 6\n",
            "  üìù Total Content: 22,821 Zeichen\n",
            "  üé® Style: detailed\n",
            "    ‚úÖ Kategorien: 6\n",
            "    üìä Sources: 7\n",
            "    üìù wetter: 12 Facts, 2 Snippets\n",
            "\n",
            "üìç Test 2: Gemini-Prompt Formatting\n",
            "üìÇ Lade Content f√ºr standard Newsletter\n",
            "  üìä Kategorien: 6\n",
            "  üìù Total Content: 22,821 Zeichen\n",
            "  üé® Style: standard\n",
            "    ‚úÖ Prompt-Section generiert: 3430 Zeichen\n",
            "    üëÄ Preview:\n",
            "    \n",
            "VERF√úGBARE CONTENT-DATEN F√úR M√úNCHEN (STANDARD STYLE):\n",
            "Quellen insgesamt: 7\n",
            "Kategorien: 6\n",
            "\n",
            "\n",
            "=== WETTER ===\n",
            "2 Quellen analysiert\n",
            "\n",
            "Key Facts:\n",
            "1. - Temperatur: 25¬∞C (Quelle: unknown)\n",
            "2. **Timeframe:** heute (Quelle: unknown)\n",
            "3. - Morgen: Teilweise bew√∂lkt (Quelle: unknown)\n",
            "4. - √úbermorgen: Regen m√∂gli...\n",
            "\n",
            "‚úÖ Simple Content Processor Tests erfolgreich!\n",
            "üí° Viel einfacher als Enhanced Content Processor!\n",
            "==================================================\n",
            "‚úÖ Simple Content Processor Setup komplett\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# ZELLE 5: Gemini Worker V2 - Enhanced mit Content Processor Integration\n",
        "# =============================================================================\n",
        "# @title Gemini Worker V2 Enhanced - Nutzt Enhanced Content Processor f√ºr detaillierte Newsletter\n",
        "\n",
        "import google.generativeai as genai\n",
        "\n",
        "class GeminiWorkerV2Enhanced:\n",
        "    \"\"\"\n",
        "    Gemini Worker V2 Enhanced - Vollst√§ndig integriert mit Enhanced Content Processor\n",
        "    - ConfigManager f√ºr Template-basierte Newsletter-Generation\n",
        "    - TimeContextManager f√ºr zeitlichen Kontext in Newslettern\n",
        "    - DataPersistenceManager f√ºr Newsletter-Archivierung\n",
        "    - Enhanced Content Processor f√ºr strukturierte Fact-Integration\n",
        "    - Google Gemini 2.0 Flash f√ºr intelligente Multi-Level Content-Synthese\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, api_key, config_manager=None, time_manager=None, persistence_manager=None, content_processor=None):\n",
        "        \"\"\"\n",
        "        Initialisiert Gemini Worker V2 Enhanced\n",
        "\n",
        "        Args:\n",
        "            api_key: Google Gemini API Key\n",
        "            config_manager: ConfigManager Instance\n",
        "            time_manager: TimeContextManager Instance\n",
        "            persistence_manager: DataPersistenceManager Instance\n",
        "            content_processor: Enhanced Content Processor Instance\n",
        "        \"\"\"\n",
        "        genai.configure(api_key=api_key)\n",
        "\n",
        "        # Foundation-System Integration\n",
        "        self.config_manager = config_manager\n",
        "        self.time_manager = time_manager\n",
        "        self.persistence_manager = persistence_manager\n",
        "        self.content_processor = content_processor  # NEW: Enhanced Content Processor\n",
        "\n",
        "        # Legacy Support falls Foundation nicht verf√ºgbar\n",
        "        self.has_foundation = all([config_manager, time_manager, persistence_manager])\n",
        "        self.has_enhanced_content = content_processor is not None\n",
        "\n",
        "        # Worker State\n",
        "        self.generated_newsletters = []\n",
        "        self.content_synthesis_history = []\n",
        "\n",
        "        print(f\"‚úÖ Gemini Worker V2 Enhanced initialisiert\")\n",
        "        print(f\"üèóÔ∏è Foundation Integration: {'‚úÖ' if self.has_foundation else '‚ùå'}\")\n",
        "        print(f\"üß† Enhanced Content Processor: {'‚úÖ' if self.has_enhanced_content else '‚ùå'}\")\n",
        "\n",
        "        if self.has_foundation:\n",
        "            # API-Config aus ConfigManager holen\n",
        "            self.api_config = self.config_manager.get_api_config(\"gemini\")\n",
        "            self.model_name = self.api_config.get(\"model\", \"gemini-2.0-flash-exp\")\n",
        "            self.model = genai.GenerativeModel(self.model_name)\n",
        "\n",
        "            print(f\"‚öôÔ∏è API Config geladen: Model {self.model_name}\")\n",
        "            print(f\"üéõÔ∏è Generation Config: temperature={self.api_config.get('temperature', 0.3)}\")\n",
        "        else:\n",
        "            self.model_name = \"gemini-2.0-flash-exp\"\n",
        "            self.model = genai.GenerativeModel(self.model_name)\n",
        "            print(\"‚ö†Ô∏è L√§uft im Legacy-Modus ohne Foundation-System\")\n",
        "\n",
        "    # =========================================================================\n",
        "    # ENHANCED CONTENT COLLECTION & SYNTHESIS\n",
        "    # =========================================================================\n",
        "\n",
        "    def collect_enhanced_content_for_location(self, location):\n",
        "        \"\"\"\n",
        "        Sammelt und verarbeitet Content mit Enhanced Content Processor\n",
        "\n",
        "        Args:\n",
        "            location: Ortsname\n",
        "\n",
        "        Returns:\n",
        "            dict: Enhanced Content-Daten mit strukturierten Facts\n",
        "        \"\"\"\n",
        "        print(f\"üß† Sammle Enhanced Content f√ºr {location}\")\n",
        "\n",
        "        enhanced_content = {\n",
        "            \"location\": location,\n",
        "            \"timestamp\": datetime.now().isoformat(),\n",
        "            \"processing_method\": \"enhanced\" if self.has_enhanced_content else \"legacy\",\n",
        "            \"content_summary\": {}\n",
        "        }\n",
        "\n",
        "        if self.has_enhanced_content:\n",
        "            # Enhanced Content Processing\n",
        "            print(\"  üìä Verwende Enhanced Content Processor\")\n",
        "\n",
        "            # 1. Alle Categories mit strukturierten Facts verarbeiten\n",
        "            processed_facts = self.content_processor.process_all_categories(location)\n",
        "            enhanced_content[\"processed_facts\"] = processed_facts\n",
        "\n",
        "            # 2. Processing Summary\n",
        "            processing_summary = self.content_processor.get_processing_summary()\n",
        "            enhanced_content[\"processing_summary\"] = processing_summary\n",
        "\n",
        "            print(f\"  ‚úÖ Enhanced Processing komplett:\")\n",
        "            print(f\"    Kategorien: {processing_summary['categories_processed']}\")\n",
        "            print(f\"    Sources: {processing_summary['total_sources']}\")\n",
        "            print(f\"    Avg Confidence: {processing_summary['average_confidence']:.2f}\")\n",
        "            print(f\"    Citations: {processing_summary['total_citations']}\")\n",
        "\n",
        "        else:\n",
        "            # Legacy Content Collection (Fallback)\n",
        "            print(\"  ‚ö†Ô∏è Fallback: Legacy Content Collection\")\n",
        "            legacy_content = self.collect_all_content_for_location_legacy(location)\n",
        "            enhanced_content.update(legacy_content)\n",
        "\n",
        "        return enhanced_content\n",
        "\n",
        "    def collect_all_content_for_location_legacy(self, location):\n",
        "        \"\"\"\n",
        "        Legacy Content Collection (Fallback wenn Enhanced Content Processor fehlt)\n",
        "        \"\"\"\n",
        "        print(f\"üìä Sammle Content f√ºr {location} von allen Workern (Legacy)\")\n",
        "\n",
        "        collected_content = {\n",
        "            \"location\": location,\n",
        "            \"timestamp\": datetime.now().isoformat(),\n",
        "            \"firecrawl_content\": [],\n",
        "            \"claude_content\": [],\n",
        "            \"perplexity_content\": [],\n",
        "            \"total_sources\": 0,\n",
        "            \"categories_covered\": set(),\n",
        "            \"content_summary\": {}\n",
        "        }\n",
        "\n",
        "        # Firecrawl Content sammeln\n",
        "        if 'firecrawl_worker_v2' in globals() and firecrawl_worker_v2:\n",
        "            firecrawl_summary = firecrawl_worker_v2.get_newsletter_summary_for_location(location)\n",
        "            collected_content[\"firecrawl_content\"] = firecrawl_summary\n",
        "            collected_content[\"categories_covered\"].update(\n",
        "                [item[\"category\"] for item in firecrawl_summary.get(\"search_results\", [])] +\n",
        "                [item[\"category\"] for item in firecrawl_summary.get(\"scrape_results\", [])]\n",
        "            )\n",
        "\n",
        "            total_firecrawl_items = (\n",
        "                len(firecrawl_summary.get(\"search_results\", [])) +\n",
        "                len(firecrawl_summary.get(\"scrape_results\", []))\n",
        "            )\n",
        "            collected_content[\"total_sources\"] += total_firecrawl_items\n",
        "\n",
        "        # Claude Content sammeln\n",
        "        if 'claude_worker_v2' in globals() and claude_worker_v2:\n",
        "            claude_summary = claude_worker_v2.get_newsletter_summary_for_location(location)\n",
        "            collected_content[\"claude_content\"] = claude_summary\n",
        "            collected_content[\"categories_covered\"].update(claude_summary.get(\"categories_processed\", []))\n",
        "            collected_content[\"total_sources\"] += claude_summary.get(\"total_search_results\", 0)\n",
        "\n",
        "        # Perplexity Content sammeln\n",
        "        if 'perplexity_worker_v2' in globals() and perplexity_worker_v2:\n",
        "            perplexity_summary = perplexity_worker_v2.get_newsletter_summary_for_location(location)\n",
        "            collected_content[\"perplexity_content\"] = perplexity_summary\n",
        "            collected_content[\"categories_covered\"].update(perplexity_summary.get(\"categories_processed\", []))\n",
        "            collected_content[\"total_sources\"] += perplexity_summary.get(\"total_search_results\", 0)\n",
        "\n",
        "        collected_content[\"categories_covered\"] = list(collected_content[\"categories_covered\"])\n",
        "        return collected_content\n",
        "\n",
        "    # =========================================================================\n",
        "    # ENHANCED NEWSLETTER GENERATION\n",
        "    # =========================================================================\n",
        "\n",
        "    def generate_newsletter_enhanced(self, location, categories=None, newsletter_style=\"standard\"):\n",
        "        \"\"\"\n",
        "        Enhanced Newsletter Generation mit strukturierten Facts\n",
        "\n",
        "        Args:\n",
        "            location: Ortsname\n",
        "            categories: Kategorien-Liste (optional, aus Config falls None)\n",
        "            newsletter_style: \"compact\", \"standard\", \"detailed\"\n",
        "\n",
        "        Returns:\n",
        "            dict: Enhanced Newsletter mit Metadaten\n",
        "        \"\"\"\n",
        "        if not self.has_foundation:\n",
        "            print(\"‚ùå Foundation-System erforderlich f√ºr Enhanced Newsletter\")\n",
        "            return None\n",
        "\n",
        "        try:\n",
        "            # 1. Kategorien bestimmen\n",
        "            if categories is None:\n",
        "                categories = self.config_manager.get_newsletter_categories(\"high\")\n",
        "                categories.extend(self.config_manager.get_newsletter_categories(\"medium\"))\n",
        "\n",
        "            # 2. Enhanced Content sammeln und verarbeiten\n",
        "            enhanced_content = self.collect_enhanced_content_for_location(location)\n",
        "\n",
        "            # 3. Newsletter-ready Content vorbereiten\n",
        "            if self.has_enhanced_content:\n",
        "                newsletter_content = self.content_processor.prepare_content_for_newsletter(\n",
        "                    location, newsletter_style\n",
        "                )\n",
        "            else:\n",
        "                newsletter_content = self._prepare_legacy_content(enhanced_content, newsletter_style)\n",
        "\n",
        "            # 4. Zeit-Kontext f√ºr Newsletter\n",
        "            current_time_info = self.time_manager.get_current_time_info()\n",
        "            newsletter_date = self.time_manager.format_for_newsletter(\"heute\")\n",
        "\n",
        "            # 5. Enhanced Newsletter-Prompt erstellen\n",
        "            newsletter_prompt = self._create_enhanced_newsletter_prompt(\n",
        "                location, categories, newsletter_content, newsletter_date, newsletter_style\n",
        "            )\n",
        "\n",
        "            # 6. Query Log speichern\n",
        "            query_id = self.persistence_manager.save_query_log(\n",
        "                category=\"enhanced_newsletter_generation\",\n",
        "                api=\"gemini_2_0_flash_enhanced\",\n",
        "                original_query=f\"Enhanced Newsletter f√ºr {location} ({newsletter_style})\",\n",
        "                enhanced_query=newsletter_prompt[:300] + \"...\",\n",
        "                time_context=current_time_info\n",
        "            )\n",
        "\n",
        "            print(f\"üì∞ Generiere Enhanced Newsletter f√ºr {location}\")\n",
        "            print(f\"üìã Kategorien: {len(categories)}\")\n",
        "            print(f\"üé® Style: {newsletter_style}\")\n",
        "            print(f\"üìÖ Datum: {newsletter_date}\")\n",
        "\n",
        "            if newsletter_content:\n",
        "                print(f\"üìä Facts: {newsletter_content.get('total_facts', 0)}\")\n",
        "                print(f\"üìö Citations: {newsletter_content.get('total_citations', 0)}\")\n",
        "\n",
        "            # 7. Gemini API Call mit erweiterten Parametern\n",
        "            generation_config = genai.GenerationConfig(\n",
        "                temperature=self._get_temperature_for_style(newsletter_style),\n",
        "                max_output_tokens=self._get_max_tokens_for_style(newsletter_style)\n",
        "            )\n",
        "\n",
        "            response = self.model.generate_content(\n",
        "                newsletter_prompt,\n",
        "                generation_config=generation_config\n",
        "            )\n",
        "\n",
        "            # 8. Raw Response speichern\n",
        "            raw_filename = self.persistence_manager.save_raw_response(\n",
        "                source=\"gemini_enhanced_newsletter\",\n",
        "                response=response,\n",
        "                query=newsletter_prompt[:500] + \"...\",\n",
        "                category=\"enhanced_newsletter\",\n",
        "                metadata={\n",
        "                    \"query_id\": query_id,\n",
        "                    \"location\": location,\n",
        "                    \"categories\": categories,\n",
        "                    \"newsletter_style\": newsletter_style,\n",
        "                    \"enhanced_processing\": self.has_enhanced_content,\n",
        "                    \"facts_count\": newsletter_content.get('total_facts', 0) if newsletter_content else 0,\n",
        "                    \"citations_count\": newsletter_content.get('total_citations', 0) if newsletter_content else 0,\n",
        "                    \"model\": self.model_name\n",
        "                }\n",
        "            )\n",
        "\n",
        "            # 9. Response verarbeiten\n",
        "            if response and response.text:\n",
        "                newsletter_result = {\n",
        "                    \"location\": location,\n",
        "                    \"categories\": categories,\n",
        "                    \"newsletter_content\": response.text,\n",
        "                    \"newsletter_style\": newsletter_style,\n",
        "                    \"newsletter_date\": newsletter_date,\n",
        "                    \"query_id\": query_id,\n",
        "                    \"raw_filename\": raw_filename,\n",
        "                    \"timestamp\": datetime.now().isoformat(),\n",
        "                    \"enhanced_processing\": self.has_enhanced_content,\n",
        "                    \"facts_integrated\": newsletter_content.get('total_facts', 0) if newsletter_content else 0,\n",
        "                    \"citations_integrated\": newsletter_content.get('total_citations', 0) if newsletter_content else 0,\n",
        "                    \"word_count\": len(response.text.split()),\n",
        "                    \"char_count\": len(response.text),\n",
        "                    \"processing_summary\": enhanced_content.get(\"processing_summary\", {})\n",
        "                }\n",
        "\n",
        "                self.generated_newsletters.append(newsletter_result)\n",
        "\n",
        "                # 10. Newsletter als Markdown speichern\n",
        "                newsletter_filename = self.persistence_manager.save_final_newsletter(\n",
        "                    newsletter_content=response.text,\n",
        "                    format=\"markdown\",\n",
        "                    metadata={\n",
        "                        \"query_id\": query_id,\n",
        "                        \"location\": location,\n",
        "                        \"categories\": categories,\n",
        "                        \"newsletter_style\": newsletter_style,\n",
        "                        \"enhanced_processing\": self.has_enhanced_content,\n",
        "                        \"facts_count\": newsletter_result[\"facts_integrated\"],\n",
        "                        \"citations_count\": newsletter_result[\"citations_integrated\"],\n",
        "                        \"word_count\": newsletter_result[\"word_count\"],\n",
        "                        \"generation_timestamp\": newsletter_result[\"timestamp\"]\n",
        "                    }\n",
        "                )\n",
        "\n",
        "                newsletter_result[\"newsletter_filename\"] = newsletter_filename\n",
        "\n",
        "                print(f\"‚úÖ Enhanced Newsletter erfolgreich generiert!\")\n",
        "                print(f\"üìù W√∂rter: {newsletter_result['word_count']}\")\n",
        "                print(f\"üìÑ Zeichen: {newsletter_result['char_count']}\")\n",
        "                print(f\"üß† Facts integriert: {newsletter_result['facts_integrated']}\")\n",
        "                print(f\"üìö Citations: {newsletter_result['citations_integrated']}\")\n",
        "                print(f\"üìÅ Gespeichert: {newsletter_filename}\")\n",
        "\n",
        "                return newsletter_result\n",
        "            else:\n",
        "                print(\"‚ùå Keine Enhanced Newsletter-Response von Gemini erhalten\")\n",
        "                return None\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Enhanced Newsletter-Generierung Fehler: {e}\")\n",
        "            import traceback\n",
        "            print(f\"üîç Traceback: {traceback.format_exc()}\")\n",
        "\n",
        "            # Fehler in Persistence speichern\n",
        "            if self.persistence_manager:\n",
        "                error_log = {\n",
        "                    \"error\": str(e),\n",
        "                    \"location\": location,\n",
        "                    \"categories\": categories,\n",
        "                    \"newsletter_style\": newsletter_style,\n",
        "                    \"enhanced_processing\": self.has_enhanced_content\n",
        "                }\n",
        "                self.persistence_manager.save_raw_response(\n",
        "                    source=\"gemini_enhanced_newsletter_error\",\n",
        "                    response=error_log,\n",
        "                    category=\"enhanced_newsletter\"\n",
        "                )\n",
        "\n",
        "            return None\n",
        "\n",
        "    def _create_enhanced_newsletter_prompt(self, location, categories, newsletter_content, newsletter_date, style):\n",
        "        \"\"\"Erstellt Enhanced Newsletter-Generation Prompt mit strukturierten Facts\"\"\"\n",
        "\n",
        "        base_prompt = f\"\"\"Du bist ein erfahrener Newsletter-Redakteur f√ºr lokale Nachrichten in Deutschland.\n",
        "\n",
        "Erstelle einen professionellen lokalen Newsletter f√ºr {location} vom {newsletter_date}.\n",
        "\n",
        "NEWSLETTER-STIL: {style}\n",
        "\n",
        "STIL-SPEZIFIKATIONEN:\n",
        "\"\"\"\n",
        "\n",
        "        if style == \"compact\":\n",
        "            base_prompt += \"\"\"- COMPACT: Kurze, pr√§gnante Informationen\n",
        "- Maximal 300 W√∂rter\n",
        "- 1-2 S√§tze pro Kategorie-Sektion\n",
        "- Keine Quellenangaben\n",
        "- Fokus auf wichtigste Informationen\"\"\"\n",
        "\n",
        "        elif style == \"standard\":\n",
        "            base_prompt += \"\"\"- STANDARD: Ausgewogene, informative Berichterstattung\n",
        "- 400-600 W√∂rter\n",
        "- 2-4 S√§tze pro Kategorie-Sektion\n",
        "- Konkrete Fakten und Details einbauen\n",
        "- Keine Quellenangaben\n",
        "- Lokaler Fokus mit spezifischen Informationen\"\"\"\n",
        "\n",
        "        elif style == \"detailed\":\n",
        "            base_prompt += \"\"\"- DETAILED: Umfassende, faktenbasierte Berichterstattung\n",
        "- 600-1000 W√∂rter\n",
        "- 3-6 S√§tze pro Kategorie-Sektion\n",
        "- Alle verf√ºgbaren konkreten Fakten integrieren\n",
        "- Quellenangaben in eckigen Klammern [Quelle: ...]\n",
        "- Spezifische Daten, Zeiten, Namen, Zahlen verwenden\"\"\"\n",
        "\n",
        "        # Enhanced Content Integration\n",
        "        if newsletter_content and self.has_enhanced_content:\n",
        "            base_prompt += f\"\"\"\n",
        "\n",
        "VERF√úGBARE STRUKTURIERTE FAKTEN ({newsletter_content.get('total_facts', 0)} Facts):\n",
        "\"\"\"\n",
        "            for category, content_data in newsletter_content.get('categories', {}).items():\n",
        "                if content_data['facts']:\n",
        "                    base_prompt += f\"\"\"\n",
        "{category.upper()}:\n",
        "- Confidence Score: {content_data['confidence_score']:.2f}\n",
        "- Quellen: {content_data['sources_count']} verschiedene APIs\"\"\"\n",
        "\n",
        "                    # Facts f√ºr diese Kategorie\n",
        "                    for fact in content_data['facts'][:5]:  # Top 5 Facts\n",
        "                        base_prompt += f\"\"\"\n",
        "  ‚Ä¢ {fact['type']}: {fact['value']}\"\"\"\n",
        "\n",
        "                    # Text-Snippets\n",
        "                    if content_data['newsletter_text_snippets']:\n",
        "                        base_prompt += f\"\"\"\n",
        "- Vorgenerierte Textbausteine: {' | '.join(content_data['newsletter_text_snippets'])}\"\"\"\n",
        "\n",
        "                    # Citations f√ºr detailed Style\n",
        "                    if style == \"detailed\" and content_data['citations']:\n",
        "                        base_prompt += f\"\"\"\n",
        "- Verf√ºgbare Quellen ({len(content_data['citations'])}):\"\"\"\n",
        "                        for citation in content_data['citations'][:3]:\n",
        "                            if citation.get('source'):\n",
        "                                base_prompt += f\"\"\"\n",
        "  [Quelle: {citation['source'][:50]}...]\"\"\"\n",
        "\n",
        "        else:\n",
        "            # Legacy Content (fallback)\n",
        "            base_prompt += f\"\"\"\n",
        "HINWEIS: Verwende allgemeine lokale Informationen f√ºr {location}.\"\"\"\n",
        "\n",
        "        base_prompt += f\"\"\"\n",
        "\n",
        "STRUKTUR-ANFORDERUNGEN:\n",
        "1. **Titel**: \"{location} Newsletter - {newsletter_date}\"\n",
        "2. **Kurze Begr√º√üung** (1-2 S√§tze)\n",
        "3. **Kategorien-Sections** (nur die verf√ºgbaren):\n",
        "   - Nachrichten\n",
        "   - Wetter\n",
        "   - Events\n",
        "   - Sport\n",
        "   - (weitere falls verf√ºgbar)\n",
        "4. **Freundlicher Abschluss** (1 Satz)\n",
        "\n",
        "CONTENT-RICHTLINUNGEN:\n",
        "‚úÖ Verwende die bereitgestellten strukturierten Fakten\n",
        "‚úÖ Integriere konkrete Zahlen, Daten, Namen aus den Facts\n",
        "‚úÖ Deutscher, lokaler, informativer Ton\n",
        "‚úÖ Zeitgem√§√üe Informationen mit Fokus auf {newsletter_date}\n",
        "\"\"\"\n",
        "\n",
        "        if style == \"detailed\":\n",
        "            base_prompt += \"\"\"‚úÖ F√ºge Quellenangaben in eckigen Klammern hinzu\n",
        "‚úÖ Nutze alle verf√ºgbaren konkreten Details\"\"\"\n",
        "\n",
        "        base_prompt += f\"\"\"\n",
        "\n",
        "WICHTIG: Erstelle jetzt einen {style} Newsletter, der die strukturierten Fakten optimal nutzt!\"\"\"\n",
        "\n",
        "        return base_prompt\n",
        "\n",
        "    def _get_temperature_for_style(self, style):\n",
        "        \"\"\"Gibt Style-spezifische Temperature zur√ºck\"\"\"\n",
        "        temperature_map = {\n",
        "            \"compact\": 0.2,    # Pr√§zise, faktisch\n",
        "            \"standard\": 0.3,   # Ausgewogen\n",
        "            \"detailed\": 0.4    # Etwas kreativer f√ºr l√§ngere Texte\n",
        "        }\n",
        "        return temperature_map.get(style, 0.3)\n",
        "\n",
        "    def _get_max_tokens_for_style(self, style):\n",
        "        \"\"\"Gibt Style-spezifische Max Tokens zur√ºck\"\"\"\n",
        "        token_map = {\n",
        "            \"compact\": 800,     # ~300 W√∂rter\n",
        "            \"standard\": 1600,   # ~600 W√∂rter\n",
        "            \"detailed\": 2500    # ~1000 W√∂rter\n",
        "        }\n",
        "        return token_map.get(style, 1600)\n",
        "\n",
        "    def _prepare_legacy_content(self, enhanced_content, newsletter_style):\n",
        "        \"\"\"Fallback Content Preparation ohne Enhanced Content Processor\"\"\"\n",
        "\n",
        "        legacy_content = {\n",
        "            \"location\": enhanced_content[\"location\"],\n",
        "            \"newsletter_style\": newsletter_style,\n",
        "            \"timestamp\": enhanced_content[\"timestamp\"],\n",
        "            \"categories\": {},\n",
        "            \"total_facts\": 0,\n",
        "            \"total_citations\": 0,\n",
        "            \"processing_method\": \"legacy\"\n",
        "        }\n",
        "\n",
        "        # Vereinfachte Content-Struktur f√ºr Legacy-Mode\n",
        "        for category in enhanced_content.get(\"categories_covered\", []):\n",
        "            legacy_content[\"categories\"][category] = {\n",
        "                \"category\": category,\n",
        "                \"content_level\": \"basic\",\n",
        "                \"sources_available\": True,\n",
        "                \"facts\": [],\n",
        "                \"citations\": []\n",
        "            }\n",
        "\n",
        "        return legacy_content\n",
        "\n",
        "    # =========================================================================\n",
        "    # BATCH NEWSLETTER GENERATION\n",
        "    # =========================================================================\n",
        "\n",
        "    def generate_all_newsletter_styles(self, location, categories=None):\n",
        "        \"\"\"\n",
        "        Generiert alle 3 Newsletter-Styles f√ºr Vergleich\n",
        "\n",
        "        Args:\n",
        "            location: Ortsname\n",
        "            categories: Kategorien-Liste (optional)\n",
        "\n",
        "        Returns:\n",
        "            dict: Alle 3 Newsletter-Versionen\n",
        "        \"\"\"\n",
        "        print(f\"üì∞ Generiere alle Newsletter-Styles f√ºr {location}\")\n",
        "\n",
        "        styles = [\"compact\", \"standard\", \"detailed\"]\n",
        "        all_newsletters = {}\n",
        "\n",
        "        for style in styles:\n",
        "            print(f\"\\n  üé® Generiere {style.upper()} Newsletter...\")\n",
        "            newsletter = self.generate_newsletter_enhanced(location, categories, style)\n",
        "\n",
        "            if newsletter:\n",
        "                all_newsletters[style] = newsletter\n",
        "                print(f\"    ‚úÖ {style}: {newsletter['word_count']} W√∂rter, {newsletter.get('facts_integrated', 0)} Facts\")\n",
        "            else:\n",
        "                print(f\"    ‚ùå {style}: Generierung fehlgeschlagen\")\n",
        "                all_newsletters[style] = None\n",
        "\n",
        "        # Vergleichs-Summary\n",
        "        comparison_summary = {\n",
        "            \"location\": location,\n",
        "            \"timestamp\": datetime.now().isoformat(),\n",
        "            \"styles_generated\": len([n for n in all_newsletters.values() if n]),\n",
        "            \"word_counts\": {style: nl[\"word_count\"] if nl else 0 for style, nl in all_newsletters.items()},\n",
        "            \"facts_counts\": {style: nl.get(\"facts_integrated\", 0) if nl else 0 for style, nl in all_newsletters.items()},\n",
        "            \"newsletters\": all_newsletters\n",
        "        }\n",
        "\n",
        "        print(f\"\\nüìä VERGLEICH ALLER STYLES:\")\n",
        "        for style in styles:\n",
        "            if all_newsletters[style]:\n",
        "                wc = all_newsletters[style][\"word_count\"]\n",
        "                fc = all_newsletters[style].get(\"facts_integrated\", 0)\n",
        "                print(f\"  {style.upper()}: {wc} W√∂rter, {fc} Facts\")\n",
        "            else:\n",
        "                print(f\"  {style.upper()}: ‚ùå Fehler\")\n",
        "\n",
        "        return comparison_summary\n",
        "\n",
        "    # =========================================================================\n",
        "    # LEGACY COMPATIBILITY\n",
        "    # =========================================================================\n",
        "\n",
        "    def generate_newsletter_with_foundation(self, location, categories=None, newsletter_style=\"standard\"):\n",
        "        \"\"\"\n",
        "        Legacy Method - ruft Enhanced Version auf f√ºr R√ºckw√§rtskompatibilit√§t\n",
        "        \"\"\"\n",
        "        print(\"‚ö†Ô∏è Legacy Method aufgerufen - verwende Enhanced Version\")\n",
        "        return self.generate_newsletter_enhanced(location, categories, newsletter_style)\n",
        "\n",
        "    def enhance_newsletter_with_details(self, newsletter_result, enhancement_type=\"citations\"):\n",
        "        \"\"\"\n",
        "        Erweitert generierten Newsletter um zus√§tzliche Details (Enhanced Version)\n",
        "        \"\"\"\n",
        "        if not newsletter_result:\n",
        "            return None\n",
        "\n",
        "        enhanced_content = newsletter_result[\"newsletter_content\"]\n",
        "\n",
        "        if enhancement_type == \"metadata\":\n",
        "            # Enhanced Newsletter-Metadaten hinzuf√ºgen\n",
        "            metadata_section = f\"\"\"\n",
        "\n",
        "---\n",
        "\n",
        "## Newsletter-Informationen\n",
        "\n",
        "**Generiert:** {newsletter_result['timestamp']}\n",
        "**Ort:** {newsletter_result['location']}\n",
        "**Datum:** {newsletter_result['newsletter_date']}\n",
        "**Stil:** {newsletter_result['newsletter_style']}\n",
        "**Enhanced Processing:** {'‚úÖ' if newsletter_result.get('enhanced_processing') else '‚ùå'}\n",
        "**Facts integriert:** {newsletter_result.get('facts_integrated', 0)}\n",
        "**Citations:** {newsletter_result.get('citations_integrated', 0)}\n",
        "**Umfang:** {newsletter_result['word_count']} W√∂rter, {newsletter_result['char_count']} Zeichen\n",
        "\n",
        "*Dieser Newsletter wurde automatisch mit Enhanced Content Processing generiert.*\n",
        "\"\"\"\n",
        "            enhanced_content += metadata_section\n",
        "\n",
        "        elif enhancement_type == \"processing_summary\":\n",
        "            # Processing Summary hinzuf√ºgen\n",
        "            if newsletter_result.get(\"processing_summary\"):\n",
        "                ps = newsletter_result[\"processing_summary\"]\n",
        "                summary_section = f\"\"\"\n",
        "\n",
        "---\n",
        "\n",
        "## Content Processing Summary\n",
        "\n",
        "**Kategorien verarbeitet:** {ps.get('categories_processed', 0)}\n",
        "**Quellen analysiert:** {ps.get('total_sources', 0)}\n",
        "**Durchschnittliche Confidence:** {ps.get('average_confidence', 0):.2f}\n",
        "**Citations extrahiert:** {ps.get('total_citations', 0)}\n",
        "\n",
        "### Kategorien-Details:\n",
        "\"\"\"\n",
        "                for category, details in ps.get('categories', {}).items():\n",
        "                    summary_section += f\"- **{category.title()}**: {details['sources']} Quellen, {details['confidence']:.2f} Confidence\\n\"\n",
        "\n",
        "                enhanced_content += summary_section\n",
        "\n",
        "        return enhanced_content\n",
        "\n",
        "    # =========================================================================\n",
        "    # UTILITY METHODS\n",
        "    # =========================================================================\n",
        "\n",
        "    def get_enhanced_newsletter_summary(self, location=None):\n",
        "        \"\"\"Gibt Enhanced Newsletter Summary zur√ºck\"\"\"\n",
        "\n",
        "        if location:\n",
        "            filtered_newsletters = [\n",
        "                n for n in self.generated_newsletters\n",
        "                if n[\"location\"].lower() == location.lower()\n",
        "            ]\n",
        "        else:\n",
        "            filtered_newsletters = self.generated_newsletters\n",
        "\n",
        "        summary = {\n",
        "            \"total_newsletters\": len(filtered_newsletters),\n",
        "            \"enhanced_processing_count\": len([n for n in filtered_newsletters if n.get(\"enhanced_processing\")]),\n",
        "            \"locations\": list(set(n[\"location\"] for n in filtered_newsletters)),\n",
        "            \"newsletter_styles\": list(set(n[\"newsletter_style\"] for n in filtered_newsletters)),\n",
        "            \"total_words\": sum(n[\"word_count\"] for n in filtered_newsletters),\n",
        "            \"total_facts_integrated\": sum(n.get(\"facts_integrated\", 0) for n in filtered_newsletters),\n",
        "            \"total_citations_integrated\": sum(n.get(\"citations_integrated\", 0) for n in filtered_newsletters),\n",
        "            \"average_facts_per_newsletter\": sum(n.get(\"facts_integrated\", 0) for n in filtered_newsletters) / max(len(filtered_newsletters), 1),\n",
        "            \"newsletters\": filtered_newsletters\n",
        "        }\n",
        "\n",
        "        return summary\n",
        "\n",
        "# =============================================================================\n",
        "# INITIALISIERUNG MIT ENHANCED CONTENT PROCESSOR\n",
        "# =============================================================================\n",
        "\n",
        "# Gemini Worker V2 Enhanced mit Enhanced Content Processor initialisieren\n",
        "if api_config.gemini_key:\n",
        "    # Foundation-System Integration\n",
        "    foundation_available = all([\n",
        "        'config_manager' in globals() and config_manager,\n",
        "        'time_manager' in globals() and time_manager,\n",
        "        'persistence_manager' in globals() and persistence_manager\n",
        "    ])\n",
        "\n",
        "    enhanced_content_available = 'enhanced_content_processor' in globals() and enhanced_content_processor\n",
        "\n",
        "    if foundation_available:\n",
        "        gemini_worker_v2_enhanced = GeminiWorkerV2Enhanced(\n",
        "            api_key=api_config.gemini_key,\n",
        "            config_manager=config_manager,\n",
        "            time_manager=time_manager,\n",
        "            persistence_manager=persistence_manager,\n",
        "            content_processor=enhanced_content_processor if enhanced_content_available else None\n",
        "        )\n",
        "        print(\"üöÄ Gemini Worker V2 Enhanced mit Foundation-System bereit\")\n",
        "\n",
        "        if enhanced_content_available:\n",
        "            print(\"üß† Enhanced Content Processor integriert - strukturierte Facts verf√ºgbar\")\n",
        "        else:\n",
        "            print(\"‚ö†Ô∏è Enhanced Content Processor fehlt - l√§uft im Legacy-Modus\")\n",
        "\n",
        "    else:\n",
        "        # Fallback ohne Foundation\n",
        "        gemini_worker_v2_enhanced = GeminiWorkerV2Enhanced(api_key=api_config.gemini_key)\n",
        "        print(\"‚ö†Ô∏è Gemini Worker V2 Enhanced im Legacy-Modus (Foundation-System fehlt)\")\n",
        "\n",
        "else:\n",
        "    print(\"‚ùå Gemini Worker V2 Enhanced nicht verf√ºgbar - API Key fehlt\")\n",
        "    gemini_worker_v2_enhanced = None\n",
        "\n",
        "# =============================================================================\n",
        "# DIREKTER TEST - Enhanced Newsletter Generation\n",
        "# =============================================================================\n",
        "\n",
        "if gemini_worker_v2_enhanced and foundation_available:\n",
        "    print(\"\\nüß™ TESTE GEMINI WORKER V2 ENHANCED\")\n",
        "    print(\"=\" * 65)\n",
        "\n",
        "    try:\n",
        "        test_location = \"m√ºnchen\"\n",
        "\n",
        "        # Test 1: Enhanced Content Collection\n",
        "        print(\"üìç Test 1: Enhanced Content Collection\")\n",
        "        enhanced_content = gemini_worker_v2_enhanced.collect_enhanced_content_for_location(test_location)\n",
        "\n",
        "        processing_method = enhanced_content.get(\"processing_method\", \"unknown\")\n",
        "        print(f\"  üß† Processing Method: {processing_method}\")\n",
        "\n",
        "        if processing_method == \"enhanced\":\n",
        "            ps = enhanced_content.get(\"processing_summary\", {})\n",
        "            print(f\"  üìä Kategorien: {ps.get('categories_processed', 0)}\")\n",
        "            print(f\"  üìÅ Sources: {ps.get('total_sources', 0)}\")\n",
        "            print(f\"  ‚≠ê Avg Confidence: {ps.get('average_confidence', 0):.2f}\")\n",
        "            print(f\"  üìö Citations: {ps.get('total_citations', 0)}\")\n",
        "\n",
        "        # Test 2: Enhanced Newsletter Generation (Standard Style)\n",
        "        print(f\"\\nüìç Test 2: Enhanced Newsletter (Standard)\")\n",
        "        standard_newsletter = gemini_worker_v2_enhanced.generate_newsletter_enhanced(\n",
        "            location=test_location,\n",
        "            categories=[\"wetter\", \"nachrichten\", \"events\", \"sport\"],\n",
        "            newsletter_style=\"standard\"\n",
        "        )\n",
        "\n",
        "        if standard_newsletter:\n",
        "            print(f\"  ‚úÖ Standard Newsletter generiert!\")\n",
        "            print(f\"  üìù W√∂rter: {standard_newsletter['word_count']}\")\n",
        "            print(f\"  üß† Facts: {standard_newsletter.get('facts_integrated', 0)}\")\n",
        "            print(f\"  üìö Citations: {standard_newsletter.get('citations_integrated', 0)}\")\n",
        "            print(f\"  üìÅ File: {standard_newsletter.get('newsletter_filename', 'N/A')}\")\n",
        "\n",
        "        # Test 3: Batch Generation (alle 3 Styles)\n",
        "        print(f\"\\nüìç Test 3: Alle Newsletter-Styles\")\n",
        "        all_styles_result = gemini_worker_v2_enhanced.generate_all_newsletter_styles(\n",
        "            location=test_location,\n",
        "            categories=[\"wetter\", \"nachrichten\", \"events\"]\n",
        "        )\n",
        "\n",
        "        if all_styles_result:\n",
        "            print(f\"  üìä Styles generiert: {all_styles_result['styles_generated']}/3\")\n",
        "            print(f\"  üìù Word Counts: {all_styles_result['word_counts']}\")\n",
        "            print(f\"  üß† Facts Counts: {all_styles_result['facts_counts']}\")\n",
        "\n",
        "        # Test 4: Enhanced Summary\n",
        "        print(f\"\\nüìç Test 4: Enhanced Newsletter Summary\")\n",
        "        summary = gemini_worker_v2_enhanced.get_enhanced_newsletter_summary(test_location)\n",
        "\n",
        "        print(f\"  üìä Total Newsletter: {summary['total_newsletters']}\")\n",
        "        print(f\"  üß† Enhanced Processing: {summary['enhanced_processing_count']}\")\n",
        "        print(f\"  üìù Total Words: {summary['total_words']}\")\n",
        "        print(f\"  üéØ Avg Facts/Newsletter: {summary['average_facts_per_newsletter']:.1f}\")\n",
        "        print(f\"  üìö Total Citations: {summary['total_citations_integrated']}\")\n",
        "\n",
        "        print(f\"\\n‚úÖ Alle Gemini Worker V2 Enhanced Tests erfolgreich!\")\n",
        "\n",
        "    except Exception as test_error:\n",
        "        print(f\"‚ùå Test Fehler: {test_error}\")\n",
        "        import traceback\n",
        "        print(f\"üîç Traceback: {traceback.format_exc()}\")\n",
        "\n",
        "print(\"=\" * 65)\n",
        "print(\"‚úÖ Zelle 5: Gemini Worker V2 Enhanced Setup komplett\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "cellView": "form",
        "id": "EeB8XSF1Z6-I",
        "outputId": "d517f5de-1fbc-40c2-ce7e-ae752eeb23be"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Gemini Worker V2 Enhanced initialisiert\n",
            "üèóÔ∏è Foundation Integration: ‚úÖ\n",
            "üß† Enhanced Content Processor: ‚úÖ\n",
            "‚öôÔ∏è API Config geladen: Model gemini-2.0-flash-exp\n",
            "üéõÔ∏è Generation Config: temperature=0.3\n",
            "üöÄ Gemini Worker V2 Enhanced mit Foundation-System bereit\n",
            "üß† Enhanced Content Processor integriert - strukturierte Facts verf√ºgbar\n",
            "\n",
            "üß™ TESTE GEMINI WORKER V2 ENHANCED\n",
            "=================================================================\n",
            "üìç Test 1: Enhanced Content Collection\n",
            "üß† Sammle Enhanced Content f√ºr m√ºnchen\n",
            "  üìä Verwende Enhanced Content Processor\n",
            "üß† Verarbeite alle Category-Facts f√ºr m√ºnchen\n",
            "üìÇ Lade alle Category-Contents f√ºr m√ºnchen\n",
            "  üìä Kategorien geladen: 6\n",
            "    wetter: 2 Content-Items\n",
            "    rathaus: 1 Content-Items\n",
            "    events: 1 Content-Items\n",
            "    nachrichten: 1 Content-Items\n",
            "    verkehr: 1 Content-Items\n",
            "    sport: 1 Content-Items\n",
            "  üéØ Verarbeite wetter: 2 Sources\n",
            "    ‚úÖ wetter: 1.00 Confidence, 3 Citations\n",
            "  üéØ Verarbeite rathaus: 1 Sources\n",
            "    ‚úÖ rathaus: 0.80 Confidence, 16 Citations\n",
            "  üéØ Verarbeite events: 1 Sources\n",
            "    ‚úÖ events: 0.80 Confidence, 19 Citations\n",
            "  üéØ Verarbeite nachrichten: 1 Sources\n",
            "    ‚úÖ nachrichten: 0.80 Confidence, 18 Citations\n",
            "  üéØ Verarbeite verkehr: 1 Sources\n",
            "    ‚úÖ verkehr: 0.80 Confidence, 22 Citations\n",
            "  üéØ Verarbeite sport: 1 Sources\n",
            "    ‚úÖ sport: 0.80 Confidence, 16 Citations\n",
            "üèÅ Fact-Processing komplett: 6 Kategorien\n",
            "  ‚úÖ Enhanced Processing komplett:\n",
            "    Kategorien: 6\n",
            "    Sources: 7\n",
            "    Avg Confidence: 0.83\n",
            "    Citations: 94\n",
            "  üß† Processing Method: enhanced\n",
            "  üìä Kategorien: 6\n",
            "  üìÅ Sources: 7\n",
            "  ‚≠ê Avg Confidence: 0.83\n",
            "  üìö Citations: 94\n",
            "\n",
            "üìç Test 2: Enhanced Newsletter (Standard)\n",
            "üß† Sammle Enhanced Content f√ºr m√ºnchen\n",
            "  üìä Verwende Enhanced Content Processor\n",
            "üß† Verarbeite alle Category-Facts f√ºr m√ºnchen\n",
            "üìÇ Lade alle Category-Contents f√ºr m√ºnchen\n",
            "  üìä Kategorien geladen: 6\n",
            "    wetter: 2 Content-Items\n",
            "    rathaus: 1 Content-Items\n",
            "    events: 1 Content-Items\n",
            "    nachrichten: 1 Content-Items\n",
            "    verkehr: 1 Content-Items\n",
            "    sport: 1 Content-Items\n",
            "  üéØ Verarbeite wetter: 2 Sources\n",
            "    ‚úÖ wetter: 1.00 Confidence, 3 Citations\n",
            "  üéØ Verarbeite rathaus: 1 Sources\n",
            "    ‚úÖ rathaus: 0.80 Confidence, 16 Citations\n",
            "  üéØ Verarbeite events: 1 Sources\n",
            "    ‚úÖ events: 0.80 Confidence, 19 Citations\n",
            "  üéØ Verarbeite nachrichten: 1 Sources\n",
            "    ‚úÖ nachrichten: 0.80 Confidence, 18 Citations\n",
            "  üéØ Verarbeite verkehr: 1 Sources\n",
            "    ‚úÖ verkehr: 0.80 Confidence, 22 Citations\n",
            "  üéØ Verarbeite sport: 1 Sources\n",
            "    ‚úÖ sport: 0.80 Confidence, 16 Citations\n",
            "üèÅ Fact-Processing komplett: 6 Kategorien\n",
            "  ‚úÖ Enhanced Processing komplett:\n",
            "    Kategorien: 6\n",
            "    Sources: 7\n",
            "    Avg Confidence: 0.83\n",
            "    Citations: 94\n",
            "üì∞ Bereite Content f√ºr standard Newsletter vor\n",
            "  üìä Newsletter Content bereit:\n",
            "    Style: standard\n",
            "    Kategorien: 6\n",
            "    Total Facts: 22\n",
            "    Total Citations: 0\n",
            "üîç Query-Log gespeichert: 369722f6\n",
            "üì∞ Generiere Enhanced Newsletter f√ºr m√ºnchen\n",
            "üìã Kategorien: 4\n",
            "üé® Style: standard\n",
            "üìÖ Datum: heute (20.07.2025)\n",
            "üìä Facts: 22\n",
            "üìö Citations: 0\n",
            "üíæ Raw Response gespeichert: 010_gemini_enhanced_newsletter_enhanced_newsletter_13-37-06.json\n",
            "üì∞ Newsletter gespeichert: newsletter_m√ºnchen_2025-07-20_13-37.md\n",
            "‚úÖ Enhanced Newsletter erfolgreich generiert!\n",
            "üìù W√∂rter: 167\n",
            "üìÑ Zeichen: 1154\n",
            "üß† Facts integriert: 22\n",
            "üìö Citations: 0\n",
            "üìÅ Gespeichert: /content/drive/MyDrive/Newsletter_System/data/sessions/2025-07-20_13-35_m√ºnchen/final_newsletter/newsletter_m√ºnchen_2025-07-20_13-37.md\n",
            "  ‚úÖ Standard Newsletter generiert!\n",
            "  üìù W√∂rter: 167\n",
            "  üß† Facts: 22\n",
            "  üìö Citations: 0\n",
            "  üìÅ File: /content/drive/MyDrive/Newsletter_System/data/sessions/2025-07-20_13-35_m√ºnchen/final_newsletter/newsletter_m√ºnchen_2025-07-20_13-37.md\n",
            "\n",
            "üìç Test 3: Alle Newsletter-Styles\n",
            "üì∞ Generiere alle Newsletter-Styles f√ºr m√ºnchen\n",
            "\n",
            "  üé® Generiere COMPACT Newsletter...\n",
            "üß† Sammle Enhanced Content f√ºr m√ºnchen\n",
            "  üìä Verwende Enhanced Content Processor\n",
            "üß† Verarbeite alle Category-Facts f√ºr m√ºnchen\n",
            "üìÇ Lade alle Category-Contents f√ºr m√ºnchen\n",
            "  üìä Kategorien geladen: 6\n",
            "    wetter: 2 Content-Items\n",
            "    rathaus: 1 Content-Items\n",
            "    events: 1 Content-Items\n",
            "    nachrichten: 1 Content-Items\n",
            "    verkehr: 1 Content-Items\n",
            "    sport: 1 Content-Items\n",
            "  üéØ Verarbeite wetter: 2 Sources\n",
            "    ‚úÖ wetter: 1.00 Confidence, 3 Citations\n",
            "  üéØ Verarbeite rathaus: 1 Sources\n",
            "    ‚úÖ rathaus: 0.80 Confidence, 16 Citations\n",
            "  üéØ Verarbeite events: 1 Sources\n",
            "    ‚úÖ events: 0.80 Confidence, 19 Citations\n",
            "  üéØ Verarbeite nachrichten: 1 Sources\n",
            "    ‚úÖ nachrichten: 0.80 Confidence, 18 Citations\n",
            "  üéØ Verarbeite verkehr: 1 Sources\n",
            "    ‚úÖ verkehr: 0.80 Confidence, 22 Citations\n",
            "  üéØ Verarbeite sport: 1 Sources\n",
            "    ‚úÖ sport: 0.80 Confidence, 16 Citations\n",
            "üèÅ Fact-Processing komplett: 6 Kategorien\n",
            "  ‚úÖ Enhanced Processing komplett:\n",
            "    Kategorien: 6\n",
            "    Sources: 7\n",
            "    Avg Confidence: 0.83\n",
            "    Citations: 94\n",
            "üì∞ Bereite Content f√ºr compact Newsletter vor\n",
            "  üìä Newsletter Content bereit:\n",
            "    Style: compact\n",
            "    Kategorien: 6\n",
            "    Total Facts: 10\n",
            "    Total Citations: 0\n",
            "üîç Query-Log gespeichert: 2ff9a540\n",
            "üì∞ Generiere Enhanced Newsletter f√ºr m√ºnchen\n",
            "üìã Kategorien: 3\n",
            "üé® Style: compact\n",
            "üìÖ Datum: heute (20.07.2025)\n",
            "üìä Facts: 10\n",
            "üìö Citations: 0\n",
            "üíæ Raw Response gespeichert: 011_gemini_enhanced_newsletter_enhanced_newsletter_13-37-08.json\n",
            "üì∞ Newsletter gespeichert: newsletter_m√ºnchen_2025-07-20_13-37.md\n",
            "‚úÖ Enhanced Newsletter erfolgreich generiert!\n",
            "üìù W√∂rter: 95\n",
            "üìÑ Zeichen: 717\n",
            "üß† Facts integriert: 10\n",
            "üìö Citations: 0\n",
            "üìÅ Gespeichert: /content/drive/MyDrive/Newsletter_System/data/sessions/2025-07-20_13-35_m√ºnchen/final_newsletter/newsletter_m√ºnchen_2025-07-20_13-37.md\n",
            "    ‚úÖ compact: 95 W√∂rter, 10 Facts\n",
            "\n",
            "  üé® Generiere STANDARD Newsletter...\n",
            "üß† Sammle Enhanced Content f√ºr m√ºnchen\n",
            "  üìä Verwende Enhanced Content Processor\n",
            "üß† Verarbeite alle Category-Facts f√ºr m√ºnchen\n",
            "üìÇ Lade alle Category-Contents f√ºr m√ºnchen\n",
            "  üìä Kategorien geladen: 6\n",
            "    wetter: 2 Content-Items\n",
            "    rathaus: 1 Content-Items\n",
            "    events: 1 Content-Items\n",
            "    nachrichten: 1 Content-Items\n",
            "    verkehr: 1 Content-Items\n",
            "    sport: 1 Content-Items\n",
            "  üéØ Verarbeite wetter: 2 Sources\n",
            "    ‚úÖ wetter: 1.00 Confidence, 3 Citations\n",
            "  üéØ Verarbeite rathaus: 1 Sources\n",
            "    ‚úÖ rathaus: 0.80 Confidence, 16 Citations\n",
            "  üéØ Verarbeite events: 1 Sources\n",
            "    ‚úÖ events: 0.80 Confidence, 19 Citations\n",
            "  üéØ Verarbeite nachrichten: 1 Sources\n",
            "    ‚úÖ nachrichten: 0.80 Confidence, 18 Citations\n",
            "  üéØ Verarbeite verkehr: 1 Sources\n",
            "    ‚úÖ verkehr: 0.80 Confidence, 22 Citations\n",
            "  üéØ Verarbeite sport: 1 Sources\n",
            "    ‚úÖ sport: 0.80 Confidence, 16 Citations\n",
            "üèÅ Fact-Processing komplett: 6 Kategorien\n",
            "  ‚úÖ Enhanced Processing komplett:\n",
            "    Kategorien: 6\n",
            "    Sources: 7\n",
            "    Avg Confidence: 0.83\n",
            "    Citations: 94\n",
            "üì∞ Bereite Content f√ºr standard Newsletter vor\n",
            "  üìä Newsletter Content bereit:\n",
            "    Style: standard\n",
            "    Kategorien: 6\n",
            "    Total Facts: 22\n",
            "    Total Citations: 0\n",
            "üîç Query-Log gespeichert: f40269b8\n",
            "üì∞ Generiere Enhanced Newsletter f√ºr m√ºnchen\n",
            "üìã Kategorien: 3\n",
            "üé® Style: standard\n",
            "üìÖ Datum: heute (20.07.2025)\n",
            "üìä Facts: 22\n",
            "üìö Citations: 0\n",
            "üíæ Raw Response gespeichert: 012_gemini_enhanced_newsletter_enhanced_newsletter_13-37-11.json\n",
            "üì∞ Newsletter gespeichert: newsletter_m√ºnchen_2025-07-20_13-37.md\n",
            "‚úÖ Enhanced Newsletter erfolgreich generiert!\n",
            "üìù W√∂rter: 139\n",
            "üìÑ Zeichen: 942\n",
            "üß† Facts integriert: 22\n",
            "üìö Citations: 0\n",
            "üìÅ Gespeichert: /content/drive/MyDrive/Newsletter_System/data/sessions/2025-07-20_13-35_m√ºnchen/final_newsletter/newsletter_m√ºnchen_2025-07-20_13-37.md\n",
            "    ‚úÖ standard: 139 W√∂rter, 22 Facts\n",
            "\n",
            "  üé® Generiere DETAILED Newsletter...\n",
            "üß† Sammle Enhanced Content f√ºr m√ºnchen\n",
            "  üìä Verwende Enhanced Content Processor\n",
            "üß† Verarbeite alle Category-Facts f√ºr m√ºnchen\n",
            "üìÇ Lade alle Category-Contents f√ºr m√ºnchen\n",
            "  üìä Kategorien geladen: 6\n",
            "    wetter: 2 Content-Items\n",
            "    rathaus: 1 Content-Items\n",
            "    events: 1 Content-Items\n",
            "    nachrichten: 1 Content-Items\n",
            "    verkehr: 1 Content-Items\n",
            "    sport: 1 Content-Items\n",
            "  üéØ Verarbeite wetter: 2 Sources\n",
            "    ‚úÖ wetter: 1.00 Confidence, 3 Citations\n",
            "  üéØ Verarbeite rathaus: 1 Sources\n",
            "    ‚úÖ rathaus: 0.80 Confidence, 16 Citations\n",
            "  üéØ Verarbeite events: 1 Sources\n",
            "    ‚úÖ events: 0.80 Confidence, 19 Citations\n",
            "  üéØ Verarbeite nachrichten: 1 Sources\n",
            "    ‚úÖ nachrichten: 0.80 Confidence, 18 Citations\n",
            "  üéØ Verarbeite verkehr: 1 Sources\n",
            "    ‚úÖ verkehr: 0.80 Confidence, 22 Citations\n",
            "  üéØ Verarbeite sport: 1 Sources\n",
            "    ‚úÖ sport: 0.80 Confidence, 16 Citations\n",
            "üèÅ Fact-Processing komplett: 6 Kategorien\n",
            "  ‚úÖ Enhanced Processing komplett:\n",
            "    Kategorien: 6\n",
            "    Sources: 7\n",
            "    Avg Confidence: 0.83\n",
            "    Citations: 94\n",
            "üì∞ Bereite Content f√ºr detailed Newsletter vor\n",
            "  üìä Newsletter Content bereit:\n",
            "    Style: detailed\n",
            "    Kategorien: 6\n",
            "    Total Facts: 28\n",
            "    Total Citations: 18\n",
            "üîç Query-Log gespeichert: 38364f79\n",
            "üì∞ Generiere Enhanced Newsletter f√ºr m√ºnchen\n",
            "üìã Kategorien: 3\n",
            "üé® Style: detailed\n",
            "üìÖ Datum: heute (20.07.2025)\n",
            "üìä Facts: 28\n",
            "üìö Citations: 18\n",
            "üíæ Raw Response gespeichert: 013_gemini_enhanced_newsletter_enhanced_newsletter_13-37-17.json\n",
            "üì∞ Newsletter gespeichert: newsletter_m√ºnchen_2025-07-20_13-37.md\n",
            "‚úÖ Enhanced Newsletter erfolgreich generiert!\n",
            "üìù W√∂rter: 317\n",
            "üìÑ Zeichen: 2592\n",
            "üß† Facts integriert: 28\n",
            "üìö Citations: 18\n",
            "üìÅ Gespeichert: /content/drive/MyDrive/Newsletter_System/data/sessions/2025-07-20_13-35_m√ºnchen/final_newsletter/newsletter_m√ºnchen_2025-07-20_13-37.md\n",
            "    ‚úÖ detailed: 317 W√∂rter, 28 Facts\n",
            "\n",
            "üìä VERGLEICH ALLER STYLES:\n",
            "  COMPACT: 95 W√∂rter, 10 Facts\n",
            "  STANDARD: 139 W√∂rter, 22 Facts\n",
            "  DETAILED: 317 W√∂rter, 28 Facts\n",
            "  üìä Styles generiert: 3/3\n",
            "  üìù Word Counts: {'compact': 95, 'standard': 139, 'detailed': 317}\n",
            "  üß† Facts Counts: {'compact': 10, 'standard': 22, 'detailed': 28}\n",
            "\n",
            "üìç Test 4: Enhanced Newsletter Summary\n",
            "  üìä Total Newsletter: 4\n",
            "  üß† Enhanced Processing: 4\n",
            "  üìù Total Words: 718\n",
            "  üéØ Avg Facts/Newsletter: 20.5\n",
            "  üìö Total Citations: 18\n",
            "\n",
            "‚úÖ Alle Gemini Worker V2 Enhanced Tests erfolgreich!\n",
            "=================================================================\n",
            "‚úÖ Zelle 5: Gemini Worker V2 Enhanced Setup komplett\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# ZELLE 5b: Simple Gemini Worker - Einfache Newsletter Generation mit Simple Content Processor\n",
        "# =============================================================================\n",
        "# @title Simple Gemini Worker - Wartbar, einfach, effektiv\n",
        "\n",
        "import google.generativeai as genai\n",
        "from datetime import datetime\n",
        "\n",
        "class SimpleGeminiWorker:\n",
        "    \"\"\"\n",
        "    Simple Gemini Worker - Einfache Newsletter-Generation\n",
        "    - Nutzt Simple Content Processor f√ºr Fact-Integration\n",
        "    - Direkte Markdown-Content √úbergabe an Gemini\n",
        "    - Fokus auf Einfachheit und Wartbarkeit\n",
        "    - 3 Newsletter-Levels: compact/standard/detailed\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, api_key, config_manager=None, time_manager=None, persistence_manager=None, simple_content_processor=None):\n",
        "        \"\"\"\n",
        "        Initialisiert Simple Gemini Worker\n",
        "\n",
        "        Args:\n",
        "            api_key: Google Gemini API Key\n",
        "            config_manager: ConfigManager Instance (optional)\n",
        "            time_manager: TimeContextManager Instance (optional)\n",
        "            persistence_manager: DataPersistenceManager Instance (optional)\n",
        "            simple_content_processor: Simple Content Processor Instance (optional)\n",
        "        \"\"\"\n",
        "        genai.configure(api_key=api_key)\n",
        "\n",
        "        # Foundation-System Integration (optional)\n",
        "        self.config_manager = config_manager\n",
        "        self.time_manager = time_manager\n",
        "        self.persistence_manager = persistence_manager\n",
        "        self.simple_content_processor = simple_content_processor\n",
        "\n",
        "        # Availability Checks\n",
        "        self.has_foundation = all([config_manager, time_manager, persistence_manager])\n",
        "        self.has_simple_content = simple_content_processor is not None\n",
        "\n",
        "        # Gemini Model\n",
        "        self.model_name = \"gemini-2.0-flash-exp\"\n",
        "        self.model = genai.GenerativeModel(self.model_name)\n",
        "\n",
        "        # Worker State\n",
        "        self.generated_newsletters = []\n",
        "\n",
        "        print(f\"‚úÖ Simple Gemini Worker initialisiert\")\n",
        "        print(f\"üèóÔ∏è Foundation System: {'‚úÖ' if self.has_foundation else '‚ùå'}\")\n",
        "        print(f\"üß† Simple Content Processor: {'‚úÖ' if self.has_simple_content else '‚ùå'}\")\n",
        "        print(f\"ü§ñ Model: {self.model_name}\")\n",
        "\n",
        "    # =========================================================================\n",
        "    # SIMPLE NEWSLETTER GENERATION\n",
        "    # =========================================================================\n",
        "\n",
        "    def generate_simple_newsletter(self, location, categories=None, newsletter_style=\"standard\"):\n",
        "        \"\"\"\n",
        "        Einfache Newsletter-Generation mit Simple Content Processor\n",
        "\n",
        "        Args:\n",
        "            location: Ortsname\n",
        "            categories: Kategorien-Liste (optional, wird ignoriert - alle verf√ºgbaren verwendet)\n",
        "            newsletter_style: \"compact\", \"standard\", \"detailed\"\n",
        "\n",
        "        Returns:\n",
        "            dict: Generated Newsletter mit Metadaten\n",
        "        \"\"\"\n",
        "        print(f\"üì∞ Generiere {newsletter_style.upper()} Newsletter f√ºr {location}\")\n",
        "\n",
        "        try:\n",
        "            # 1. Zeit-Kontext bestimmen\n",
        "            if self.time_manager:\n",
        "                newsletter_date = self.time_manager.format_for_newsletter(\"heute\")\n",
        "                current_time_info = self.time_manager.get_current_time_info()\n",
        "            else:\n",
        "                newsletter_date = datetime.now().strftime(\"%d.%m.%Y\")\n",
        "                current_time_info = {\"date\": newsletter_date}\n",
        "\n",
        "            # 2. Content mit Simple Content Processor laden\n",
        "            if self.has_simple_content:\n",
        "                newsletter_content = self.simple_content_processor.load_all_content_for_newsletter(\n",
        "                    location, newsletter_style\n",
        "                )\n",
        "                content_section = self.simple_content_processor.format_for_gemini_prompt(\n",
        "                    newsletter_content, location\n",
        "                )\n",
        "\n",
        "                total_sources = newsletter_content.get(\"total_sources\", 0)\n",
        "                total_facts = sum(len(cat.get(\"key_facts\", [])) for cat in newsletter_content.get(\"categories\", {}).values())\n",
        "\n",
        "                print(f\"  üìä Content geladen: {total_sources} Sources, {total_facts} Facts\")\n",
        "\n",
        "            else:\n",
        "                # Fallback ohne Content Processor\n",
        "                content_section = f\"Erstelle Newsletter f√ºr {location} basierend auf allgemeinen lokalen Informationen.\"\n",
        "                total_sources = 0\n",
        "                total_facts = 0\n",
        "                print(f\"  ‚ö†Ô∏è Fallback: Kein Content Processor - allgemeine Informationen\")\n",
        "\n",
        "            # 3. Simple Newsletter-Prompt erstellen\n",
        "            newsletter_prompt = self._create_simple_prompt(\n",
        "                location, newsletter_date, newsletter_style, content_section\n",
        "            )\n",
        "\n",
        "            # 4. Query Log speichern\n",
        "            query_id = None\n",
        "            if self.persistence_manager:\n",
        "                query_id = self.persistence_manager.save_query_log(\n",
        "                    category=\"simple_newsletter_generation\",\n",
        "                    api=\"gemini_simple\",\n",
        "                    original_query=f\"Simple Newsletter {location} ({newsletter_style})\",\n",
        "                    enhanced_query=newsletter_prompt[:200] + \"...\",\n",
        "                    time_context=current_time_info\n",
        "                )\n",
        "\n",
        "            # 5. Gemini Generation Config\n",
        "            generation_config = genai.GenerationConfig(\n",
        "                temperature=self._get_temperature_for_style(newsletter_style),\n",
        "                max_output_tokens=self._get_max_tokens_for_style(newsletter_style)\n",
        "            )\n",
        "\n",
        "            print(f\"  ü§ñ Generiere mit Gemini...\")\n",
        "\n",
        "            # 6. Gemini API Call\n",
        "            response = self.model.generate_content(\n",
        "                newsletter_prompt,\n",
        "                generation_config=generation_config\n",
        "            )\n",
        "\n",
        "            # 7. Response verarbeiten\n",
        "            if response and response.text:\n",
        "                newsletter_result = {\n",
        "                    \"location\": location,\n",
        "                    \"newsletter_style\": newsletter_style,\n",
        "                    \"newsletter_content\": response.text,\n",
        "                    \"newsletter_date\": newsletter_date,\n",
        "                    \"query_id\": query_id,\n",
        "                    \"timestamp\": datetime.now().isoformat(),\n",
        "                    \"word_count\": len(response.text.split()),\n",
        "                    \"char_count\": len(response.text),\n",
        "                    \"sources_used\": total_sources,\n",
        "                    \"facts_integrated\": total_facts,\n",
        "                    \"processing_method\": \"simple_direct\",\n",
        "                    \"model\": self.model_name\n",
        "                }\n",
        "\n",
        "                # 8. Raw Response speichern\n",
        "                if self.persistence_manager:\n",
        "                    raw_filename = self.persistence_manager.save_raw_response(\n",
        "                        source=\"gemini_simple_newsletter\",\n",
        "                        response=response,\n",
        "                        query=newsletter_prompt[:500] + \"...\",\n",
        "                        category=\"simple_newsletter\",\n",
        "                        metadata={\n",
        "                            \"query_id\": query_id,\n",
        "                            \"location\": location,\n",
        "                            \"newsletter_style\": newsletter_style,\n",
        "                            \"sources_used\": total_sources,\n",
        "                            \"facts_integrated\": total_facts\n",
        "                        }\n",
        "                    )\n",
        "                    newsletter_result[\"raw_filename\"] = raw_filename\n",
        "\n",
        "                    # 9. Newsletter als Markdown speichern\n",
        "                    newsletter_filename = self.persistence_manager.save_final_newsletter(\n",
        "                        newsletter_content=response.text,\n",
        "                        format=\"markdown\",\n",
        "                        metadata={\n",
        "                            \"query_id\": query_id,\n",
        "                            \"location\": location,\n",
        "                            \"newsletter_style\": newsletter_style,\n",
        "                            \"sources_used\": total_sources,\n",
        "                            \"facts_integrated\": total_facts,\n",
        "                            \"processing_method\": \"simple_direct\",\n",
        "                            \"word_count\": newsletter_result[\"word_count\"]\n",
        "                        }\n",
        "                    )\n",
        "                    newsletter_result[\"newsletter_filename\"] = newsletter_filename\n",
        "\n",
        "                self.generated_newsletters.append(newsletter_result)\n",
        "\n",
        "                print(f\"  ‚úÖ Newsletter generiert!\")\n",
        "                print(f\"  üìù W√∂rter: {newsletter_result['word_count']}\")\n",
        "                print(f\"  üìä Sources: {newsletter_result['sources_used']}\")\n",
        "                print(f\"  üéØ Facts: {newsletter_result['facts_integrated']}\")\n",
        "                if newsletter_result.get(\"newsletter_filename\"):\n",
        "                    print(f\"  üìÅ Gespeichert: {newsletter_result['newsletter_filename']}\")\n",
        "\n",
        "                return newsletter_result\n",
        "\n",
        "            else:\n",
        "                print(f\"  ‚ùå Keine Response von Gemini erhalten\")\n",
        "                return None\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Simple Newsletter Generation Fehler: {e}\")\n",
        "            import traceback\n",
        "            print(f\"üîç Traceback: {traceback.format_exc()}\")\n",
        "\n",
        "            # Fehler speichern\n",
        "            if self.persistence_manager:\n",
        "                self.persistence_manager.save_raw_response(\n",
        "                    source=\"gemini_simple_newsletter_error\",\n",
        "                    response={\"error\": str(e), \"location\": location, \"style\": newsletter_style},\n",
        "                    category=\"simple_newsletter_error\"\n",
        "                )\n",
        "\n",
        "            return None\n",
        "\n",
        "    def _create_simple_prompt(self, location, newsletter_date, style, content_section):\n",
        "        \"\"\"Erstellt einfachen, effektiven Newsletter-Prompt\"\"\"\n",
        "\n",
        "        # Style-spezifische Anweisungen\n",
        "        style_instructions = {\n",
        "            \"compact\": {\n",
        "                \"description\": \"Kurzer, pr√§gnanter Newsletter\",\n",
        "                \"word_target\": \"250-350 W√∂rter\",\n",
        "                \"details\": \"1-2 S√§tze pro Kategorie, wichtigste Informationen\",\n",
        "                \"tone\": \"knapp und informativ\"\n",
        "            },\n",
        "            \"standard\": {\n",
        "                \"description\": \"Ausgewogener, informativer Newsletter\",\n",
        "                \"word_target\": \"400-600 W√∂rter\",\n",
        "                \"details\": \"2-4 S√§tze pro Kategorie, konkrete Facts einbauen\",\n",
        "                \"tone\": \"freundlich und detailliert\"\n",
        "            },\n",
        "            \"detailed\": {\n",
        "                \"description\": \"Umfassender, faktenreicher Newsletter\",\n",
        "                \"word_target\": \"600-900 W√∂rter\",\n",
        "                \"details\": \"3-6 S√§tze pro Kategorie, alle verf√ºgbaren Details nutzen\",\n",
        "                \"tone\": \"ausf√ºhrlich und fundiert\"\n",
        "            }\n",
        "        }\n",
        "\n",
        "        style_info = style_instructions.get(style, style_instructions[\"standard\"])\n",
        "\n",
        "        prompt = f\"\"\"Du bist ein lokaler Newsletter-Redakteur f√ºr {location}.\n",
        "\n",
        "AUFTRAG: Erstelle einen {style_info['description']} f√ºr {location} vom {newsletter_date}.\n",
        "\n",
        "STIL: {style.upper()}\n",
        "- {style_info['description']}\n",
        "- Ziel: {style_info['word_target']}\n",
        "- Details: {style_info['details']}\n",
        "- Ton: {style_info['tone']}\n",
        "\n",
        "{content_section}\n",
        "\n",
        "STRUKTUR:\n",
        "1. **Titel**: \"{location} Newsletter - {newsletter_date}\"\n",
        "2. **Begr√º√üung**: Kurze, freundliche Ansprache\n",
        "3. **Kategorien-Sections**:\n",
        "   - Nutze die bereitgestellten Facts und Content-Snippets\n",
        "   - Integriere konkrete Zahlen, Daten, Zeiten\n",
        "   - Verwende lokale Bez√ºge\n",
        "4. **Abschluss**: Freundlicher Tagesabschluss\n",
        "\n",
        "WICHTIGE ANFORDERUNGEN:\n",
        "‚úÖ Deutsche Sprache, lokaler Ton\n",
        "‚úÖ Konkrete Facts aus dem bereitgestellten Content verwenden\n",
        "‚úÖ Zeitgem√§√üe Informationen mit Fokus auf {newsletter_date}\n",
        "‚úÖ {style_info['word_target']} einhalten\n",
        "‚úÖ Freundlich und professionell\n",
        "\n",
        "Erstelle jetzt den {style} Newsletter f√ºr die B√ºrger von {location}!\"\"\"\n",
        "\n",
        "        return prompt\n",
        "\n",
        "    def _get_temperature_for_style(self, style):\n",
        "        \"\"\"Style-spezifische Temperature\"\"\"\n",
        "        temp_map = {\n",
        "            \"compact\": 0.2,    # Pr√§zise, faktisch\n",
        "            \"standard\": 0.3,   # Ausgewogen\n",
        "            \"detailed\": 0.4    # Etwas kreativer\n",
        "        }\n",
        "        return temp_map.get(style, 0.3)\n",
        "\n",
        "    def _get_max_tokens_for_style(self, style):\n",
        "        \"\"\"Style-spezifische Max Tokens\"\"\"\n",
        "        token_map = {\n",
        "            \"compact\": 900,     # ~350 W√∂rter\n",
        "            \"standard\": 1500,   # ~600 W√∂rter\n",
        "            \"detailed\": 2300    # ~900 W√∂rter\n",
        "        }\n",
        "        return token_map.get(style, 1500)\n",
        "\n",
        "    # =========================================================================\n",
        "    # BATCH NEWSLETTER GENERATION\n",
        "    # =========================================================================\n",
        "\n",
        "    def generate_all_newsletter_styles(self, location):\n",
        "        \"\"\"\n",
        "        Generiert alle 3 Newsletter-Styles zum Vergleich\n",
        "\n",
        "        Args:\n",
        "            location: Ortsname\n",
        "\n",
        "        Returns:\n",
        "            dict: Alle 3 Newsletter-Versionen\n",
        "        \"\"\"\n",
        "        print(f\"üì∞ Generiere ALLE Newsletter-Styles f√ºr {location}\")\n",
        "        print(\"=\" * 50)\n",
        "\n",
        "        styles = [\"compact\", \"standard\", \"detailed\"]\n",
        "        all_newsletters = {}\n",
        "\n",
        "        for style in styles:\n",
        "            print(f\"\\nüé® {style.upper()} Newsletter:\")\n",
        "            newsletter = self.generate_simple_newsletter(location, newsletter_style=style)\n",
        "\n",
        "            if newsletter:\n",
        "                all_newsletters[style] = newsletter\n",
        "                print(f\"  ‚úÖ Erfolgreich: {newsletter['word_count']} W√∂rter\")\n",
        "            else:\n",
        "                print(f\"  ‚ùå Fehlgeschlagen\")\n",
        "                all_newsletters[style] = None\n",
        "\n",
        "        # Vergleichs-Summary\n",
        "        comparison_summary = {\n",
        "            \"location\": location,\n",
        "            \"timestamp\": datetime.now().isoformat(),\n",
        "            \"styles_generated\": len([n for n in all_newsletters.values() if n]),\n",
        "            \"processing_method\": \"simple_direct\",\n",
        "            \"comparison\": {}\n",
        "        }\n",
        "\n",
        "        print(f\"\\nüìä STYLE-VERGLEICH:\")\n",
        "        for style in styles:\n",
        "            if all_newsletters[style]:\n",
        "                nl = all_newsletters[style]\n",
        "                comparison_summary[\"comparison\"][style] = {\n",
        "                    \"word_count\": nl[\"word_count\"],\n",
        "                    \"sources_used\": nl[\"sources_used\"],\n",
        "                    \"facts_integrated\": nl[\"facts_integrated\"]\n",
        "                }\n",
        "                print(f\"  {style.upper():>8}: {nl['word_count']:>3} W√∂rter, {nl['sources_used']:>2} Sources, {nl['facts_integrated']:>2} Facts\")\n",
        "            else:\n",
        "                comparison_summary[\"comparison\"][style] = None\n",
        "                print(f\"  {style.upper():>8}: ‚ùå Fehler\")\n",
        "\n",
        "        comparison_summary[\"newsletters\"] = all_newsletters\n",
        "        return comparison_summary\n",
        "\n",
        "    # =========================================================================\n",
        "    # NEWSLETTER COMPARISON & ANALYSIS\n",
        "    # =========================================================================\n",
        "\n",
        "    def compare_newsletter_quality(self, location):\n",
        "        \"\"\"Analysiert Newsletter-Qualit√§t √ºber alle Styles\"\"\"\n",
        "\n",
        "        location_newsletters = [\n",
        "            n for n in self.generated_newsletters\n",
        "            if n[\"location\"].lower() == location.lower()\n",
        "        ]\n",
        "\n",
        "        if not location_newsletters:\n",
        "            print(f\"‚ùå Keine Newsletter f√ºr {location} gefunden\")\n",
        "            return None\n",
        "\n",
        "        quality_analysis = {\n",
        "            \"location\": location,\n",
        "            \"total_newsletters\": len(location_newsletters),\n",
        "            \"styles_analyzed\": set(n[\"newsletter_style\"] for n in location_newsletters),\n",
        "            \"avg_word_count\": sum(n[\"word_count\"] for n in location_newsletters) / len(location_newsletters),\n",
        "            \"total_sources_utilized\": sum(n[\"sources_used\"] for n in location_newsletters),\n",
        "            \"total_facts_integrated\": sum(n[\"facts_integrated\"] for n in location_newsletters),\n",
        "            \"processing_method\": \"simple_direct\",\n",
        "            \"newsletters\": location_newsletters\n",
        "        }\n",
        "\n",
        "        print(f\"üìä NEWSLETTER QUALIT√ÑTS-ANALYSE f√ºr {location}:\")\n",
        "        print(f\"  Newsletter generiert: {quality_analysis['total_newsletters']}\")\n",
        "        print(f\"  Styles: {', '.join(quality_analysis['styles_analyzed'])}\")\n",
        "        print(f\"  √ò W√∂rter: {quality_analysis['avg_word_count']:.0f}\")\n",
        "        print(f\"  Total Sources genutzt: {quality_analysis['total_sources_utilized']}\")\n",
        "        print(f\"  Total Facts integriert: {quality_analysis['total_facts_integrated']}\")\n",
        "\n",
        "        return quality_analysis\n",
        "\n",
        "    # =========================================================================\n",
        "    # UTILITY METHODS\n",
        "    # =========================================================================\n",
        "\n",
        "    def get_simple_newsletter_summary(self, location=None):\n",
        "        \"\"\"Gibt Simple Newsletter Summary zur√ºck\"\"\"\n",
        "\n",
        "        if location:\n",
        "            filtered_newsletters = [\n",
        "                n for n in self.generated_newsletters\n",
        "                if n[\"location\"].lower() == location.lower()\n",
        "            ]\n",
        "        else:\n",
        "            filtered_newsletters = self.generated_newsletters\n",
        "\n",
        "        summary = {\n",
        "            \"total_newsletters\": len(filtered_newsletters),\n",
        "            \"locations\": list(set(n[\"location\"] for n in filtered_newsletters)),\n",
        "            \"newsletter_styles\": list(set(n[\"newsletter_style\"] for n in filtered_newsletters)),\n",
        "            \"processing_method\": \"simple_direct\",\n",
        "            \"total_words\": sum(n[\"word_count\"] for n in filtered_newsletters),\n",
        "            \"total_sources_used\": sum(n[\"sources_used\"] for n in filtered_newsletters),\n",
        "            \"total_facts_integrated\": sum(n[\"facts_integrated\"] for n in filtered_newsletters),\n",
        "            \"avg_facts_per_newsletter\": sum(n[\"facts_integrated\"] for n in filtered_newsletters) / max(len(filtered_newsletters), 1),\n",
        "            \"newsletters\": filtered_newsletters\n",
        "        }\n",
        "\n",
        "        return summary\n",
        "\n",
        "    # Legacy Compatibility f√ºr bestehende Interfaces\n",
        "    def generate_newsletter_with_foundation(self, location, categories=None, newsletter_style=\"standard\"):\n",
        "        \"\"\"Legacy-kompatible Methode\"\"\"\n",
        "        return self.generate_simple_newsletter(location, categories, newsletter_style)\n",
        "\n",
        "# =============================================================================\n",
        "# INITIALISIERUNG\n",
        "# =============================================================================\n",
        "\n",
        "# Simple Gemini Worker initialisieren\n",
        "if api_config.gemini_key:\n",
        "    # Foundation-System Integration (optional)\n",
        "    foundation_available = all([\n",
        "        'config_manager' in globals() and config_manager,\n",
        "        'time_manager' in globals() and time_manager,\n",
        "        'persistence_manager' in globals() and persistence_manager\n",
        "    ])\n",
        "\n",
        "    simple_content_available = 'simple_content_processor' in globals() and simple_content_processor\n",
        "\n",
        "    simple_gemini_worker = SimpleGeminiWorker(\n",
        "        api_key=api_config.gemini_key,\n",
        "        config_manager=config_manager if foundation_available else None,\n",
        "        time_manager=time_manager if foundation_available else None,\n",
        "        persistence_manager=persistence_manager if foundation_available else None,\n",
        "        simple_content_processor=simple_content_processor if simple_content_available else None\n",
        "    )\n",
        "\n",
        "    print(\"üöÄ Simple Gemini Worker bereit!\")\n",
        "\n",
        "    if simple_content_available:\n",
        "        print(\"üß† Simple Content Processor integriert - Facts verf√ºgbar\")\n",
        "    else:\n",
        "        print(\"‚ö†Ô∏è L√§uft ohne Simple Content Processor\")\n",
        "\n",
        "else:\n",
        "    print(\"‚ùå Simple Gemini Worker nicht verf√ºgbar - API Key fehlt\")\n",
        "    simple_gemini_worker = None\n",
        "\n",
        "# =============================================================================\n",
        "# DIREKTER TEST\n",
        "# =============================================================================\n",
        "\n",
        "if simple_gemini_worker:\n",
        "    print(\"\\nüß™ TESTE SIMPLE GEMINI WORKER\")\n",
        "    print(\"=\" * 55)\n",
        "\n",
        "    try:\n",
        "        test_location = \"m√ºnchen\"\n",
        "\n",
        "        # Test 1: Single Newsletter Generation\n",
        "        print(\"üìç Test 1: Standard Newsletter Generation\")\n",
        "        standard_newsletter = simple_gemini_worker.generate_simple_newsletter(\n",
        "            location=test_location,\n",
        "            newsletter_style=\"standard\"\n",
        "        )\n",
        "\n",
        "        if standard_newsletter:\n",
        "            print(f\"  ‚úÖ Standard Newsletter:\")\n",
        "            print(f\"    W√∂rter: {standard_newsletter['word_count']}\")\n",
        "            print(f\"    Sources: {standard_newsletter['sources_used']}\")\n",
        "            print(f\"    Facts: {standard_newsletter['facts_integrated']}\")\n",
        "\n",
        "            # Preview der ersten 150 Zeichen\n",
        "            preview = standard_newsletter['newsletter_content'][:150] + \"...\"\n",
        "            print(f\"    Preview: {preview}\")\n",
        "\n",
        "        # Test 2: Batch Generation (alle 3 Styles)\n",
        "        print(f\"\\nüìç Test 2: Batch Generation (alle Styles)\")\n",
        "        all_styles = simple_gemini_worker.generate_all_newsletter_styles(test_location)\n",
        "\n",
        "        if all_styles:\n",
        "            print(f\"  üìä Styles generiert: {all_styles['styles_generated']}/3\")\n",
        "\n",
        "        # Test 3: Quality Analysis\n",
        "        print(f\"\\nüìç Test 3: Newsletter Quality Analysis\")\n",
        "        quality_analysis = simple_gemini_worker.compare_newsletter_quality(test_location)\n",
        "\n",
        "        # Test 4: Summary\n",
        "        print(f\"\\nüìç Test 4: Simple Newsletter Summary\")\n",
        "        summary = simple_gemini_worker.get_simple_newsletter_summary(test_location)\n",
        "\n",
        "        print(f\"  üìä Total Newsletter: {summary['total_newsletters']}\")\n",
        "        print(f\"  üìù Total Words: {summary['total_words']}\")\n",
        "        print(f\"  üìä Avg Facts/Newsletter: {summary['avg_facts_per_newsletter']:.1f}\")\n",
        "        print(f\"  üé® Styles: {', '.join(summary['newsletter_styles'])}\")\n",
        "\n",
        "        print(f\"\\n‚úÖ Simple Gemini Worker Tests erfolgreich!\")\n",
        "        print(f\"üí° Viel einfacher und wartbarer als Enhanced Version!\")\n",
        "\n",
        "    except Exception as test_error:\n",
        "        print(f\"‚ùå Test Fehler: {test_error}\")\n",
        "        import traceback\n",
        "        print(f\"üîç Traceback: {traceback.format_exc()}\")\n",
        "\n",
        "print(\"=\" * 55)\n",
        "print(\"‚úÖ Zelle 5b: Simple Gemini Worker Setup komplett\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "cellView": "form",
        "id": "78X37EZs1DRu",
        "outputId": "0b875988-3144-4744-c9aa-e7d751e3204d"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Simple Gemini Worker initialisiert\n",
            "üèóÔ∏è Foundation System: ‚úÖ\n",
            "üß† Simple Content Processor: ‚úÖ\n",
            "ü§ñ Model: gemini-2.0-flash-exp\n",
            "üöÄ Simple Gemini Worker bereit!\n",
            "üß† Simple Content Processor integriert - Facts verf√ºgbar\n",
            "\n",
            "üß™ TESTE SIMPLE GEMINI WORKER\n",
            "=======================================================\n",
            "üìç Test 1: Standard Newsletter Generation\n",
            "üì∞ Generiere STANDARD Newsletter f√ºr m√ºnchen\n",
            "üìÇ Lade Content f√ºr standard Newsletter\n",
            "  üìä Kategorien: 6\n",
            "  üìù Total Content: 22,821 Zeichen\n",
            "  üé® Style: standard\n",
            "  üìä Content geladen: 7 Sources, 36 Facts\n",
            "üîç Query-Log gespeichert: adaa6025\n",
            "  ü§ñ Generiere mit Gemini...\n",
            "üíæ Raw Response gespeichert: 014_gemini_simple_newsletter_simple_newsletter_13-37-23.json\n",
            "üì∞ Newsletter gespeichert: newsletter_m√ºnchen_2025-07-20_13-37.md\n",
            "  ‚úÖ Newsletter generiert!\n",
            "  üìù W√∂rter: 367\n",
            "  üìä Sources: 7\n",
            "  üéØ Facts: 36\n",
            "  üìÅ Gespeichert: /content/drive/MyDrive/Newsletter_System/data/sessions/2025-07-20_13-35_m√ºnchen/final_newsletter/newsletter_m√ºnchen_2025-07-20_13-37.md\n",
            "  ‚úÖ Standard Newsletter:\n",
            "    W√∂rter: 367\n",
            "    Sources: 7\n",
            "    Facts: 36\n",
            "    Preview: **m√ºnchen Newsletter - heute (20.07.2025)**\n",
            "\n",
            "Servus liebe M√ºnchnerinnen und M√ºnchner,\n",
            "\n",
            "herzlich willkommen zu Ihrer t√§glichen Dosis M√ºnchen! Hier komm...\n",
            "\n",
            "üìç Test 2: Batch Generation (alle Styles)\n",
            "üì∞ Generiere ALLE Newsletter-Styles f√ºr m√ºnchen\n",
            "==================================================\n",
            "\n",
            "üé® COMPACT Newsletter:\n",
            "üì∞ Generiere COMPACT Newsletter f√ºr m√ºnchen\n",
            "üìÇ Lade Content f√ºr compact Newsletter\n",
            "  üìä Kategorien: 6\n",
            "  üìù Total Content: 22,821 Zeichen\n",
            "  üé® Style: compact\n",
            "  üìä Content geladen: 7 Sources, 18 Facts\n",
            "üîç Query-Log gespeichert: 65c4ded8\n",
            "  ü§ñ Generiere mit Gemini...\n",
            "üíæ Raw Response gespeichert: 015_gemini_simple_newsletter_simple_newsletter_13-37-26.json\n",
            "üì∞ Newsletter gespeichert: newsletter_m√ºnchen_2025-07-20_13-37.md\n",
            "  ‚úÖ Newsletter generiert!\n",
            "  üìù W√∂rter: 121\n",
            "  üìä Sources: 7\n",
            "  üéØ Facts: 18\n",
            "  üìÅ Gespeichert: /content/drive/MyDrive/Newsletter_System/data/sessions/2025-07-20_13-35_m√ºnchen/final_newsletter/newsletter_m√ºnchen_2025-07-20_13-37.md\n",
            "  ‚úÖ Erfolgreich: 121 W√∂rter\n",
            "\n",
            "üé® STANDARD Newsletter:\n",
            "üì∞ Generiere STANDARD Newsletter f√ºr m√ºnchen\n",
            "üìÇ Lade Content f√ºr standard Newsletter\n",
            "  üìä Kategorien: 6\n",
            "  üìù Total Content: 22,821 Zeichen\n",
            "  üé® Style: standard\n",
            "  üìä Content geladen: 7 Sources, 36 Facts\n",
            "üîç Query-Log gespeichert: 2e46e1e3\n",
            "  ü§ñ Generiere mit Gemini...\n",
            "üíæ Raw Response gespeichert: 016_gemini_simple_newsletter_simple_newsletter_13-37-31.json\n",
            "üì∞ Newsletter gespeichert: newsletter_m√ºnchen_2025-07-20_13-37.md\n",
            "  ‚úÖ Newsletter generiert!\n",
            "  üìù W√∂rter: 301\n",
            "  üìä Sources: 7\n",
            "  üéØ Facts: 36\n",
            "  üìÅ Gespeichert: /content/drive/MyDrive/Newsletter_System/data/sessions/2025-07-20_13-35_m√ºnchen/final_newsletter/newsletter_m√ºnchen_2025-07-20_13-37.md\n",
            "  ‚úÖ Erfolgreich: 301 W√∂rter\n",
            "\n",
            "üé® DETAILED Newsletter:\n",
            "üì∞ Generiere DETAILED Newsletter f√ºr m√ºnchen\n",
            "üìÇ Lade Content f√ºr detailed Newsletter\n",
            "  üìä Kategorien: 6\n",
            "  üìù Total Content: 22,821 Zeichen\n",
            "  üé® Style: detailed\n",
            "  üìä Content geladen: 7 Sources, 72 Facts\n",
            "üîç Query-Log gespeichert: c0705bc4\n",
            "  ü§ñ Generiere mit Gemini...\n",
            "üíæ Raw Response gespeichert: 017_gemini_simple_newsletter_simple_newsletter_13-37-40.json\n",
            "üì∞ Newsletter gespeichert: newsletter_m√ºnchen_2025-07-20_13-37.md\n",
            "  ‚úÖ Newsletter generiert!\n",
            "  üìù W√∂rter: 602\n",
            "  üìä Sources: 7\n",
            "  üéØ Facts: 72\n",
            "  üìÅ Gespeichert: /content/drive/MyDrive/Newsletter_System/data/sessions/2025-07-20_13-35_m√ºnchen/final_newsletter/newsletter_m√ºnchen_2025-07-20_13-37.md\n",
            "  ‚úÖ Erfolgreich: 602 W√∂rter\n",
            "\n",
            "üìä STYLE-VERGLEICH:\n",
            "   COMPACT: 121 W√∂rter,  7 Sources, 18 Facts\n",
            "  STANDARD: 301 W√∂rter,  7 Sources, 36 Facts\n",
            "  DETAILED: 602 W√∂rter,  7 Sources, 72 Facts\n",
            "  üìä Styles generiert: 3/3\n",
            "\n",
            "üìç Test 3: Newsletter Quality Analysis\n",
            "üìä NEWSLETTER QUALIT√ÑTS-ANALYSE f√ºr m√ºnchen:\n",
            "  Newsletter generiert: 4\n",
            "  Styles: compact, detailed, standard\n",
            "  √ò W√∂rter: 348\n",
            "  Total Sources genutzt: 28\n",
            "  Total Facts integriert: 162\n",
            "\n",
            "üìç Test 4: Simple Newsletter Summary\n",
            "  üìä Total Newsletter: 4\n",
            "  üìù Total Words: 1391\n",
            "  üìä Avg Facts/Newsletter: 40.5\n",
            "  üé® Styles: compact, detailed, standard\n",
            "\n",
            "‚úÖ Simple Gemini Worker Tests erfolgreich!\n",
            "üí° Viel einfacher und wartbarer als Enhanced Version!\n",
            "=======================================================\n",
            "‚úÖ Zelle 5b: Simple Gemini Worker Setup komplett\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# ZELLE 6: Main Controller - Orchestrierte Multi-API Newsletter Pipeline\n",
        "# =============================================================================\n",
        "# @title Main Controller - Vollst√§ndige Newsletter-Generation mit Foundation-System\n",
        "\n",
        "class NewsletterMainController:\n",
        "    \"\"\"\n",
        "    Main Controller f√ºr das komplette Newsletter-System\n",
        "    Orchestriert alle Worker und das Foundation-System f√ºr die automatische Newsletter-Generierung\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, config_manager, time_manager, persistence_manager):\n",
        "        \"\"\"\n",
        "        Initialisiert Main Controller\n",
        "\n",
        "        Args:\n",
        "            config_manager: ConfigManager Instance\n",
        "            time_manager: TimeContextManager Instance\n",
        "            persistence_manager: DataPersistenceManager Instance\n",
        "        \"\"\"\n",
        "        # Foundation-System\n",
        "        self.config_manager = config_manager\n",
        "        self.time_manager = time_manager\n",
        "        self.persistence_manager = persistence_manager\n",
        "\n",
        "        # Worker Registry\n",
        "        self.workers = {}\n",
        "        self._register_workers()\n",
        "\n",
        "        # Controller State\n",
        "        self.newsletter_sessions = []\n",
        "        self.execution_log = []\n",
        "\n",
        "        print(f\"‚úÖ Main Controller initialisiert\")\n",
        "        print(f\"üèóÔ∏è Foundation-System: ConfigManager, TimeContextManager, DataPersistenceManager\")\n",
        "        print(f\"ü§ñ Registrierte Worker: {len(self.workers)}\")\n",
        "\n",
        "    def _register_workers(self):\n",
        "        \"\"\"Registriert alle verf√ºgbaren Worker\"\"\"\n",
        "\n",
        "        # Firecrawl Worker V2\n",
        "        if 'firecrawl_worker_v2' in globals() and firecrawl_worker_v2:\n",
        "            self.workers['firecrawl'] = firecrawl_worker_v2\n",
        "            print(\"  üï∑Ô∏è Firecrawl Worker V2 registriert\")\n",
        "\n",
        "        # Claude Worker V2\n",
        "        if 'claude_worker_v2' in globals() and claude_worker_v2:\n",
        "            self.workers['claude'] = claude_worker_v2\n",
        "            print(\"  ü§ñ Claude Worker V2 registriert\")\n",
        "\n",
        "        # Perplexity Worker V2\n",
        "        if 'perplexity_worker_v2' in globals() and perplexity_worker_v2:\n",
        "            self.workers['perplexity'] = perplexity_worker_v2\n",
        "            print(\"  üîç Perplexity Worker V2 registriert\")\n",
        "\n",
        "        # Gemini Worker V2\n",
        "        if 'gemini_worker_v2' in globals() and gemini_worker_v2:\n",
        "            self.workers['gemini'] = gemini_worker_v2\n",
        "            print(\"  ‚ú® Gemini Worker V2 registriert\")\n",
        "\n",
        "    # =========================================================================\n",
        "    # NEWSLETTER GENERATION PIPELINE\n",
        "    # =========================================================================\n",
        "\n",
        "    def generate_complete_newsletter(self, location, categories=None, newsletter_config=None):\n",
        "        \"\"\"\n",
        "        Komplette Newsletter-Pipeline von Datensammlung bis Generierung\n",
        "\n",
        "        Args:\n",
        "            location: Ortsname\n",
        "            categories: Kategorien-Liste (optional, aus Config falls None)\n",
        "            newsletter_config: Pipeline-Konfiguration (optional)\n",
        "\n",
        "        Returns:\n",
        "            dict: Vollst√§ndige Newsletter-Session mit Ergebnissen\n",
        "        \"\"\"\n",
        "        print(f\"üöÄ STARTE KOMPLETTE NEWSLETTER-PIPELINE\")\n",
        "        print(f\"üìç Location: {location}\")\n",
        "        print(\"=\" * 60)\n",
        "\n",
        "        # Session initialisieren\n",
        "        session_start = datetime.now()\n",
        "        session_id = f\"newsletter_{location}_{session_start.strftime('%Y%m%d_%H%M')}\"\n",
        "\n",
        "        pipeline_session = {\n",
        "            \"session_id\": session_id,\n",
        "            \"location\": location,\n",
        "            \"start_time\": session_start.isoformat(),\n",
        "            \"categories\": categories,\n",
        "            \"config\": newsletter_config or {},\n",
        "            \"phases\": {},\n",
        "            \"results\": {},\n",
        "            \"errors\": [],\n",
        "            \"status\": \"running\"\n",
        "        }\n",
        "\n",
        "        try:\n",
        "            # Phase 1: Konfiguration und Planung\n",
        "            print(\"üìã PHASE 1: Konfiguration und Planung\")\n",
        "            planning_result = self._phase_1_planning(location, categories)\n",
        "            pipeline_session[\"phases\"][\"planning\"] = planning_result\n",
        "            pipeline_session[\"categories\"] = planning_result[\"categories\"]\n",
        "\n",
        "            # Phase 2: Datensammlung mit Multi-API Approach\n",
        "            print(f\"\\nüìä PHASE 2: Multi-API Datensammlung\")\n",
        "            data_collection_result = self._phase_2_data_collection(location, planning_result[\"categories\"])\n",
        "            pipeline_session[\"phases\"][\"data_collection\"] = data_collection_result\n",
        "\n",
        "            # Phase 3: Content-Synthese und Quality-Check\n",
        "            print(f\"\\nüß† PHASE 3: Content-Synthese\")\n",
        "            synthesis_result = self._phase_3_synthesis(location, data_collection_result)\n",
        "            pipeline_session[\"phases\"][\"synthesis\"] = synthesis_result\n",
        "\n",
        "            # Phase 4: Newsletter-Generierung\n",
        "            print(f\"\\nüì∞ PHASE 4: Newsletter-Generierung\")\n",
        "            generation_result = self._phase_4_generation(location, synthesis_result)\n",
        "            pipeline_session[\"phases\"][\"generation\"] = generation_result\n",
        "\n",
        "            # Phase 5: Finalisierung und Archivierung\n",
        "            print(f\"\\nüèÅ PHASE 5: Finalisierung\")\n",
        "            finalization_result = self._phase_5_finalization(location, pipeline_session)\n",
        "            pipeline_session[\"phases\"][\"finalization\"] = finalization_result\n",
        "\n",
        "            # Session abschlie√üen\n",
        "            pipeline_session[\"status\"] = \"completed\"\n",
        "            pipeline_session[\"end_time\"] = datetime.now().isoformat()\n",
        "            pipeline_session[\"duration\"] = (datetime.now() - session_start).total_seconds()\n",
        "\n",
        "            # Results zusammenfassen\n",
        "            pipeline_session[\"results\"] = self._summarize_pipeline_results(pipeline_session)\n",
        "\n",
        "            self.newsletter_sessions.append(pipeline_session)\n",
        "\n",
        "            print(f\"\\nüéâ NEWSLETTER-PIPELINE ERFOLGREICH ABGESCHLOSSEN\")\n",
        "            print(f\"‚è±Ô∏è Dauer: {pipeline_session['duration']:.1f} Sekunden\")\n",
        "            print(f\"üìä Kategorien verarbeitet: {len(pipeline_session['results'].get('categories_processed', []))}\")\n",
        "            print(f\"üìÅ API-Calls: {pipeline_session['results'].get('total_api_calls', 0)}\")\n",
        "            print(f\"üì∞ Newsletter: {pipeline_session['results'].get('newsletter_generated', False)}\")\n",
        "\n",
        "            return pipeline_session\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå PIPELINE FEHLER: {e}\")\n",
        "            pipeline_session[\"status\"] = \"failed\"\n",
        "            pipeline_session[\"error\"] = str(e)\n",
        "            pipeline_session[\"end_time\"] = datetime.now().isoformat()\n",
        "\n",
        "            import traceback\n",
        "            error_details = traceback.format_exc()\n",
        "            pipeline_session[\"error_details\"] = error_details\n",
        "            print(f\"üîç Error Details: {error_details}\")\n",
        "\n",
        "            return pipeline_session\n",
        "\n",
        "    def _phase_1_planning(self, location, categories):\n",
        "        \"\"\"Phase 1: Konfiguration und Planung\"\"\"\n",
        "        print(\"  üìã Erstelle Newsletter-Plan...\")\n",
        "\n",
        "        # Kategorien aus Config holen falls nicht angegeben\n",
        "        if categories is None:\n",
        "            high_priority = self.config_manager.get_newsletter_categories(\"high\")\n",
        "            medium_priority = self.config_manager.get_newsletter_categories(\"medium\")\n",
        "            categories = high_priority + medium_priority[:3]  # Begrenzt f√ºr PoC\n",
        "\n",
        "        # Time-aware Newsletter Plan erstellen\n",
        "        newsletter_plan = self.time_manager.create_time_aware_newsletter_plan(\n",
        "            self.config_manager, location, categories\n",
        "        )\n",
        "\n",
        "        # Worker-Strategien bestimmen\n",
        "        worker_strategies = {}\n",
        "        for category in categories:\n",
        "            method = self.config_manager.get_category_method(category)\n",
        "\n",
        "            if method == \"scrape\":\n",
        "                worker_strategies[category] = [\"firecrawl\"]\n",
        "            elif method == \"search\":\n",
        "                # Multi-API Search f√ºr bessere Abdeckung\n",
        "                available_search_workers = [w for w in [\"firecrawl\", \"claude\", \"perplexity\"] if w in self.workers]\n",
        "                worker_strategies[category] = available_search_workers[:2]  # Top 2 f√ºr Effizienz\n",
        "\n",
        "        planning_result = {\n",
        "            \"categories\": categories,\n",
        "            \"newsletter_plan\": newsletter_plan,\n",
        "            \"worker_strategies\": worker_strategies,\n",
        "            \"location_config\": self.config_manager.get_location_config(location),\n",
        "            \"timestamp\": datetime.now().isoformat()\n",
        "        }\n",
        "\n",
        "        print(f\"    ‚úÖ Plan erstellt: {len(categories)} Kategorien, {len(worker_strategies)} Worker-Strategien\")\n",
        "\n",
        "        return planning_result\n",
        "\n",
        "    def _phase_2_data_collection(self, location, categories):\n",
        "        \"\"\"Phase 2: Multi-API Datensammlung\"\"\"\n",
        "        print(\"  üìä Starte Multi-API Datensammlung...\")\n",
        "\n",
        "        collection_results = {\n",
        "            \"firecrawl_results\": [],\n",
        "            \"claude_results\": [],\n",
        "            \"perplexity_results\": [],\n",
        "            \"categories_processed\": [],\n",
        "            \"total_api_calls\": 0,\n",
        "            \"errors\": []\n",
        "        }\n",
        "\n",
        "        for category in categories:\n",
        "            print(f\"    üéØ Verarbeite Kategorie: {category}\")\n",
        "\n",
        "            # Firecrawl Worker\n",
        "            if \"firecrawl\" in self.workers:\n",
        "                try:\n",
        "                    firecrawl_result = self.workers[\"firecrawl\"].process_category_for_newsletter(category, location)\n",
        "                    if firecrawl_result:\n",
        "                        collection_results[\"firecrawl_results\"].append(firecrawl_result)\n",
        "                        collection_results[\"total_api_calls\"] += 1\n",
        "                        print(f\"      üï∑Ô∏è Firecrawl: ‚úÖ\")\n",
        "                    else:\n",
        "                        print(f\"      üï∑Ô∏è Firecrawl: ‚ùå\")\n",
        "                except Exception as e:\n",
        "                    collection_results[\"errors\"].append(f\"Firecrawl {category}: {e}\")\n",
        "                    print(f\"      üï∑Ô∏è Firecrawl: ‚ùå ({e})\")\n",
        "\n",
        "            # Claude Worker (nur f√ºr Search-geeignete Kategorien)\n",
        "            category_method = self.config_manager.get_category_method(category)\n",
        "            if \"claude\" in self.workers and category_method == \"search\":\n",
        "                try:\n",
        "                    claude_result = self.workers[\"claude\"].process_category_for_newsletter(category, location)\n",
        "                    if claude_result:\n",
        "                        collection_results[\"claude_results\"].append(claude_result)\n",
        "                        collection_results[\"total_api_calls\"] += 1\n",
        "                        print(f\"      ü§ñ Claude: ‚úÖ ({claude_result.get('web_searches_used', 0)} searches)\")\n",
        "                    else:\n",
        "                        print(f\"      ü§ñ Claude: ‚ùå\")\n",
        "                except Exception as e:\n",
        "                    collection_results[\"errors\"].append(f\"Claude {category}: {e}\")\n",
        "                    print(f\"      ü§ñ Claude: ‚ùå ({e})\")\n",
        "\n",
        "            # Perplexity Worker (selective f√ºr Cross-Validation)\n",
        "            if \"perplexity\" in self.workers and category in [\"nachrichten\", \"sport\", \"events\"]:\n",
        "                try:\n",
        "                    perplexity_result = self.workers[\"perplexity\"].process_category_for_newsletter(category, location)\n",
        "                    if perplexity_result:\n",
        "                        collection_results[\"perplexity_results\"].append(perplexity_result)\n",
        "                        collection_results[\"total_api_calls\"] += 1\n",
        "                        print(f\"      üîç Perplexity: ‚úÖ ({len(perplexity_result.get('sources', []))} sources)\")\n",
        "                    else:\n",
        "                        print(f\"      üîç Perplexity: ‚ùå\")\n",
        "                except Exception as e:\n",
        "                    collection_results[\"errors\"].append(f\"Perplexity {category}: {e}\")\n",
        "                    print(f\"      üîç Perplexity: ‚ùå ({e})\")\n",
        "\n",
        "            collection_results[\"categories_processed\"].append(category)\n",
        "\n",
        "        print(f\"    ‚úÖ Datensammlung komplett: {collection_results['total_api_calls']} API-Calls\")\n",
        "\n",
        "        return collection_results\n",
        "\n",
        "    def _phase_3_synthesis(self, location, data_collection_result):\n",
        "        \"\"\"Phase 3: Content-Synthese\"\"\"\n",
        "        print(\"  üß† Synthetisiere gesammelte Daten...\")\n",
        "\n",
        "        # Content Quality Assessment\n",
        "        quality_metrics = {\n",
        "            \"firecrawl_items\": len(data_collection_result[\"firecrawl_results\"]),\n",
        "            \"claude_items\": len(data_collection_result[\"claude_results\"]),\n",
        "            \"perplexity_items\": len(data_collection_result[\"perplexity_results\"]),\n",
        "            \"total_sources\": 0,\n",
        "            \"categories_with_content\": [],\n",
        "            \"content_diversity_score\": 0\n",
        "        }\n",
        "\n",
        "        # Source Counting und Quality Assessment\n",
        "        categories_with_content = set()\n",
        "\n",
        "        for firecrawl_result in data_collection_result[\"firecrawl_results\"]:\n",
        "            categories_with_content.add(firecrawl_result[\"category\"])\n",
        "            if firecrawl_result[\"method\"] == \"search\":\n",
        "                quality_metrics[\"total_sources\"] += firecrawl_result.get(\"results_count\", 0)\n",
        "            elif firecrawl_result[\"method\"] == \"scrape\":\n",
        "                quality_metrics[\"total_sources\"] += firecrawl_result.get(\"successful_scrapes\", 0)\n",
        "\n",
        "        for claude_result in data_collection_result[\"claude_results\"]:\n",
        "            categories_with_content.add(claude_result[\"category\"])\n",
        "            quality_metrics[\"total_sources\"] += len(claude_result.get(\"citations\", []))\n",
        "\n",
        "        for perplexity_result in data_collection_result[\"perplexity_results\"]:\n",
        "            categories_with_content.add(perplexity_result[\"category\"])\n",
        "            quality_metrics[\"total_sources\"] += len(perplexity_result.get(\"sources\", []))\n",
        "\n",
        "        quality_metrics[\"categories_with_content\"] = list(categories_with_content)\n",
        "        quality_metrics[\"content_diversity_score\"] = len(categories_with_content) / len(data_collection_result[\"categories_processed\"]) if data_collection_result[\"categories_processed\"] else 0\n",
        "\n",
        "        synthesis_result = {\n",
        "            \"quality_metrics\": quality_metrics,\n",
        "            \"content_ready_for_generation\": quality_metrics[\"total_sources\"] > 0,\n",
        "            \"recommended_newsletter_style\": \"compact\" if quality_metrics[\"total_sources\"] < 10 else \"standard\",\n",
        "            \"timestamp\": datetime.now().isoformat()\n",
        "        }\n",
        "\n",
        "        print(f\"    üìä Content Quality: {quality_metrics['total_sources']} Sources, {len(categories_with_content)} Kategorien\")\n",
        "        print(f\"    üéØ Diversity Score: {quality_metrics['content_diversity_score']:.2f}\")\n",
        "        print(f\"    üì∞ Newsletter Style: {synthesis_result['recommended_newsletter_style']}\")\n",
        "\n",
        "        return synthesis_result\n",
        "\n",
        "    def _phase_4_generation(self, location, synthesis_result):\n",
        "        \"\"\"Phase 4: Newsletter-Generierung\"\"\"\n",
        "        print(\"  üì∞ Generiere Newsletter...\")\n",
        "\n",
        "        if not synthesis_result[\"content_ready_for_generation\"]:\n",
        "            print(\"    ‚ùå Nicht genug Content f√ºr Newsletter-Generierung\")\n",
        "            return {\"success\": False, \"reason\": \"insufficient_content\"}\n",
        "\n",
        "        if \"gemini\" not in self.workers:\n",
        "            print(\"    ‚ùå Gemini Worker nicht verf√ºgbar\")\n",
        "            return {\"success\": False, \"reason\": \"no_gemini_worker\"}\n",
        "\n",
        "        try:\n",
        "            # Newsletter generieren\n",
        "            newsletter_result = self.workers[\"gemini\"].generate_newsletter_with_foundation(\n",
        "                location=location,\n",
        "                categories=synthesis_result[\"quality_metrics\"][\"categories_with_content\"],\n",
        "                newsletter_style=synthesis_result[\"recommended_newsletter_style\"]\n",
        "            )\n",
        "\n",
        "            if newsletter_result:\n",
        "                # Enhanced Newsletter erstellen\n",
        "                enhanced_newsletter = self.workers[\"gemini\"].enhance_newsletter_with_details(\n",
        "                    newsletter_result,\n",
        "                    enhancement_type=\"metadata\"\n",
        "                )\n",
        "\n",
        "                generation_result = {\n",
        "                    \"success\": True,\n",
        "                    \"newsletter_result\": newsletter_result,\n",
        "                    \"enhanced_newsletter\": enhanced_newsletter,\n",
        "                    \"newsletter_file\": newsletter_result.get(\"newsletter_filename\"),\n",
        "                    \"word_count\": newsletter_result[\"word_count\"],\n",
        "                    \"char_count\": newsletter_result[\"char_count\"]\n",
        "                }\n",
        "\n",
        "                print(f\"    ‚úÖ Newsletter generiert: {newsletter_result['word_count']} W√∂rter\")\n",
        "\n",
        "                return generation_result\n",
        "            else:\n",
        "                print(\"    ‚ùå Newsletter-Generierung fehlgeschlagen\")\n",
        "                return {\"success\": False, \"reason\": \"generation_failed\"}\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"    ‚ùå Newsletter-Generation Fehler: {e}\")\n",
        "            return {\"success\": False, \"reason\": \"generation_error\", \"error\": str(e)}\n",
        "\n",
        "    def _phase_5_finalization(self, location, pipeline_session):\n",
        "        \"\"\"Phase 5: Finalisierung und Archivierung\"\"\"\n",
        "        print(\"  üèÅ Finalisiere Session...\")\n",
        "\n",
        "        # Session Meta-Daten in Persistence speichern\n",
        "        if self.persistence_manager:\n",
        "            self.persistence_manager.save_session_meta()\n",
        "\n",
        "        # Execution Log erstellen\n",
        "        execution_summary = {\n",
        "            \"session_id\": pipeline_session[\"session_id\"],\n",
        "            \"location\": location,\n",
        "            \"duration\": pipeline_session.get(\"duration\", 0),\n",
        "            \"phases_completed\": list(pipeline_session[\"phases\"].keys()),\n",
        "            \"success\": pipeline_session[\"status\"] == \"completed\",\n",
        "            \"timestamp\": datetime.now().isoformat()\n",
        "        }\n",
        "\n",
        "        self.execution_log.append(execution_summary)\n",
        "\n",
        "        finalization_result = {\n",
        "            \"session_archived\": True,\n",
        "            \"execution_logged\": True,\n",
        "            \"persistence_completed\": True,\n",
        "            \"summary\": execution_summary\n",
        "        }\n",
        "\n",
        "        print(f\"    ‚úÖ Session finalisiert und archiviert\")\n",
        "\n",
        "        return finalization_result\n",
        "\n",
        "    def _summarize_pipeline_results(self, pipeline_session):\n",
        "        \"\"\"Erstellt Zusammenfassung der Pipeline-Ergebnisse\"\"\"\n",
        "\n",
        "        results_summary = {\n",
        "            \"session_id\": pipeline_session[\"session_id\"],\n",
        "            \"location\": pipeline_session[\"location\"],\n",
        "            \"status\": pipeline_session[\"status\"],\n",
        "            \"duration\": pipeline_session.get(\"duration\", 0),\n",
        "            \"categories_processed\": [],\n",
        "            \"total_api_calls\": 0,\n",
        "            \"newsletter_generated\": False,\n",
        "            \"content_sources\": 0,\n",
        "            \"errors_count\": len(pipeline_session.get(\"errors\", []))\n",
        "        }\n",
        "\n",
        "        # Data Collection Results\n",
        "        if \"data_collection\" in pipeline_session[\"phases\"]:\n",
        "            data_collection = pipeline_session[\"phases\"][\"data_collection\"]\n",
        "            results_summary[\"categories_processed\"] = data_collection.get(\"categories_processed\", [])\n",
        "            results_summary[\"total_api_calls\"] = data_collection.get(\"total_api_calls\", 0)\n",
        "\n",
        "        # Synthesis Results\n",
        "        if \"synthesis\" in pipeline_session[\"phases\"]:\n",
        "            synthesis = pipeline_session[\"phases\"][\"synthesis\"]\n",
        "            results_summary[\"content_sources\"] = synthesis[\"quality_metrics\"].get(\"total_sources\", 0)\n",
        "\n",
        "        # Generation Results\n",
        "        if \"generation\" in pipeline_session[\"phases\"]:\n",
        "            generation = pipeline_session[\"phases\"][\"generation\"]\n",
        "            results_summary[\"newsletter_generated\"] = generation.get(\"success\", False)\n",
        "            if results_summary[\"newsletter_generated\"]:\n",
        "                results_summary[\"newsletter_word_count\"] = generation.get(\"word_count\", 0)\n",
        "                results_summary[\"newsletter_file\"] = generation.get(\"newsletter_file\")\n",
        "\n",
        "        return results_summary\n",
        "\n",
        "    # =========================================================================\n",
        "    # UTILITY METHODS\n",
        "    # =========================================================================\n",
        "\n",
        "    def get_system_status(self):\n",
        "        \"\"\"Gibt aktuellen System-Status zur√ºck\"\"\"\n",
        "\n",
        "        return {\n",
        "            \"foundation_system\": {\n",
        "                \"config_manager\": self.config_manager is not None,\n",
        "                \"time_manager\": self.time_manager is not None,\n",
        "                \"persistence_manager\": self.persistence_manager is not None\n",
        "            },\n",
        "            \"workers\": {\n",
        "                name: worker is not None for name, worker in self.workers.items()\n",
        "            },\n",
        "            \"sessions\": {\n",
        "                \"total_sessions\": len(self.newsletter_sessions),\n",
        "                \"completed_sessions\": len([s for s in self.newsletter_sessions if s[\"status\"] == \"completed\"]),\n",
        "                \"failed_sessions\": len([s for s in self.newsletter_sessions if s[\"status\"] == \"failed\"])\n",
        "            },\n",
        "            \"execution_log_entries\": len(self.execution_log)\n",
        "        }\n",
        "\n",
        "    def get_session_summary(self, session_id=None):\n",
        "        \"\"\"Gibt Zusammenfassung einer Session zur√ºck\"\"\"\n",
        "\n",
        "        if session_id:\n",
        "            for session in self.newsletter_sessions:\n",
        "                if session[\"session_id\"] == session_id:\n",
        "                    return session[\"results\"] if \"results\" in session else session\n",
        "            return None\n",
        "        else:\n",
        "            # Neueste Session\n",
        "            if self.newsletter_sessions:\n",
        "                return self.newsletter_sessions[-1][\"results\"] if \"results\" in self.newsletter_sessions[-1] else self.newsletter_sessions[-1]\n",
        "            return None\n",
        "\n",
        "# =============================================================================\n",
        "# INITIALISIERUNG\n",
        "# =============================================================================\n",
        "\n",
        "# Main Controller mit Foundation-System initialisieren\n",
        "foundation_available = all([\n",
        "    'config_manager' in globals() and config_manager,\n",
        "    'time_manager' in globals() and time_manager,\n",
        "    'persistence_manager' in globals() and persistence_manager\n",
        "])\n",
        "\n",
        "if foundation_available:\n",
        "    main_controller = NewsletterMainController(\n",
        "        config_manager=config_manager,\n",
        "        time_manager=time_manager,\n",
        "        persistence_manager=persistence_manager\n",
        "    )\n",
        "    print(\"üöÄ Main Controller mit Foundation-System bereit\")\n",
        "\n",
        "    # System Status\n",
        "    system_status = main_controller.get_system_status()\n",
        "    print(f\"üìä System Status:\")\n",
        "    print(f\"   Foundation: ‚úÖ Komplett\")\n",
        "    print(f\"   Worker: {len([w for w in system_status['workers'].values() if w])} von {len(system_status['workers'])} verf√ºgbar\")\n",
        "\n",
        "else:\n",
        "    print(\"‚ùå Main Controller nicht verf√ºgbar - Foundation-System fehlt\")\n",
        "    main_controller = None\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"‚úÖ Main Controller Setup komplett\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "id": "v91Hl0ZCZ-iO",
        "outputId": "f9355954-249b-4f9c-af11-83005d11f831"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  üï∑Ô∏è Firecrawl Worker V2 registriert\n",
            "  ü§ñ Claude Worker V2 registriert\n",
            "  üîç Perplexity Worker V2 registriert\n",
            "‚úÖ Main Controller initialisiert\n",
            "üèóÔ∏è Foundation-System: ConfigManager, TimeContextManager, DataPersistenceManager\n",
            "ü§ñ Registrierte Worker: 3\n",
            "üöÄ Main Controller mit Foundation-System bereit\n",
            "üìä System Status:\n",
            "   Foundation: ‚úÖ Komplett\n",
            "   Worker: 3 von 3 verf√ºgbar\n",
            "============================================================\n",
            "‚úÖ Main Controller Setup komplett\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# ZELLE 7: Komplette Ende-zu-Ende Newsletter Demo\n",
        "# =============================================================================\n",
        "# @title Ultimative Multi-API Newsletter-Pipeline Demo\n",
        "\n",
        "print(\"üé¨ STARTE ULTIMATIVE NEWSLETTER-PIPELINE DEMO\")\n",
        "print(\"=\" * 70)\n",
        "print(\"üìç Demo-Location: M√ºnchen\")\n",
        "print(\"üìã Demo-Kategorien: Wetter, Nachrichten, Events, Sport\")\n",
        "print(\"üèóÔ∏è System: Foundation + 4 Worker V2 + Main Controller\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "if main_controller:\n",
        "    try:\n",
        "        # =================================================================\n",
        "        # KOMPLETTE NEWSLETTER-PIPELINE AUSF√úHREN\n",
        "        # =================================================================\n",
        "\n",
        "        print(\"\\nüöÄ AUSF√úHRUNG DER 5-PHASEN PIPELINE\")\n",
        "        print(\"=\" * 50)\n",
        "\n",
        "        # Pipeline ausf√ºhren\n",
        "        demo_result = main_controller.generate_complete_newsletter(\n",
        "            location=\"m√ºnchen\",\n",
        "            categories=[\"wetter\", \"nachrichten\", \"events\", \"sport\"]\n",
        "        )\n",
        "\n",
        "        # =================================================================\n",
        "        # ERGEBNISSE ANALYSIEREN UND ANZEIGEN\n",
        "        # =================================================================\n",
        "\n",
        "        print(\"\\nüìä PIPELINE-ERGEBNISSE ANALYSE\")\n",
        "        print(\"=\" * 50)\n",
        "\n",
        "        if demo_result[\"status\"] == \"completed\":\n",
        "            results = demo_result[\"results\"]\n",
        "\n",
        "            print(\"‚úÖ PIPELINE ERFOLGREICH ABGESCHLOSSEN!\")\n",
        "            print(f\"üìç Location: {results['location']}\")\n",
        "            print(f\"‚è±Ô∏è Dauer: {results['duration']:.1f} Sekunden\")\n",
        "            print(f\"üìã Kategorien: {len(results['categories_processed'])}\")\n",
        "            print(f\"üì° API-Calls: {results['total_api_calls']}\")\n",
        "            print(f\"üìä Content Sources: {results['content_sources']}\")\n",
        "            print(f\"üì∞ Newsletter: {'‚úÖ' if results['newsletter_generated'] else '‚ùå'}\")\n",
        "\n",
        "            if results['newsletter_generated']:\n",
        "                print(f\"üìù Newsletter W√∂rter: {results.get('newsletter_word_count', 'N/A')}\")\n",
        "                print(f\"üìÅ Newsletter Datei: {results.get('newsletter_file', 'N/A')}\")\n",
        "\n",
        "            # =================================================================\n",
        "            # DETAILLIERTE PHASEN-ANALYSE\n",
        "            # =================================================================\n",
        "\n",
        "            print(f\"\\nüîç DETAILLIERTE PHASEN-ANALYSE\")\n",
        "            print(\"=\" * 50)\n",
        "\n",
        "            # Phase 1: Planning\n",
        "            if \"planning\" in demo_result[\"phases\"]:\n",
        "                planning = demo_result[\"phases\"][\"planning\"]\n",
        "                print(\"üìã PHASE 1 - PLANNING:\")\n",
        "                print(f\"   Kategorien geplant: {len(planning['categories'])}\")\n",
        "                print(f\"   Worker-Strategien: {len(planning['worker_strategies'])}\")\n",
        "\n",
        "                for category, workers in planning['worker_strategies'].items():\n",
        "                    workers_str = \", \".join(workers) if isinstance(workers, list) else str(workers)\n",
        "                    print(f\"   {category}: {workers_str}\")\n",
        "\n",
        "            # Phase 2: Data Collection\n",
        "            if \"data_collection\" in demo_result[\"phases\"]:\n",
        "                data_collection = demo_result[\"phases\"][\"data_collection\"]\n",
        "                print(f\"\\nüìä PHASE 2 - DATA COLLECTION:\")\n",
        "                print(f\"   üï∑Ô∏è Firecrawl Results: {len(data_collection['firecrawl_results'])}\")\n",
        "                print(f\"   ü§ñ Claude Results: {len(data_collection['claude_results'])}\")\n",
        "                print(f\"   üîç Perplexity Results: {len(data_collection['perplexity_results'])}\")\n",
        "                print(f\"   üì° Total API Calls: {data_collection['total_api_calls']}\")\n",
        "                print(f\"   ‚ùå Errors: {len(data_collection['errors'])}\")\n",
        "\n",
        "                if data_collection['errors']:\n",
        "                    print(\"   Error Details:\")\n",
        "                    for error in data_collection['errors'][:3]:  # Erste 3 Errors\n",
        "                        print(f\"     - {error}\")\n",
        "\n",
        "            # Phase 3: Synthesis\n",
        "            if \"synthesis\" in demo_result[\"phases\"]:\n",
        "                synthesis = demo_result[\"phases\"][\"synthesis\"]\n",
        "                metrics = synthesis[\"quality_metrics\"]\n",
        "                print(f\"\\nüß† PHASE 3 - SYNTHESIS:\")\n",
        "                print(f\"   Total Sources: {metrics['total_sources']}\")\n",
        "                print(f\"   Content Diversity: {metrics['content_diversity_score']:.2f}\")\n",
        "                print(f\"   Kategorien mit Content: {len(metrics['categories_with_content'])}\")\n",
        "                print(f\"   Empfohlener Style: {synthesis['recommended_newsletter_style']}\")\n",
        "\n",
        "            # Phase 4: Generation\n",
        "            if \"generation\" in demo_result[\"phases\"]:\n",
        "                generation = demo_result[\"phases\"][\"generation\"]\n",
        "                print(f\"\\nüì∞ PHASE 4 - GENERATION:\")\n",
        "                print(f\"   Success: {generation['success']}\")\n",
        "                if generation['success']:\n",
        "                    print(f\"   Newsletter W√∂rter: {generation['word_count']}\")\n",
        "                    print(f\"   Newsletter Zeichen: {generation['char_count']}\")\n",
        "                    print(f\"   Enhanced Version: ‚úÖ\")\n",
        "                else:\n",
        "                    print(f\"   Failure Reason: {generation.get('reason', 'Unknown')}\")\n",
        "\n",
        "            # Phase 5: Finalization\n",
        "            if \"finalization\" in demo_result[\"phases\"]:\n",
        "                finalization = demo_result[\"phases\"][\"finalization\"]\n",
        "                print(f\"\\nüèÅ PHASE 5 - FINALIZATION:\")\n",
        "                print(f\"   Session Archived: {finalization['session_archived']}\")\n",
        "                print(f\"   Execution Logged: {finalization['execution_logged']}\")\n",
        "                print(f\"   Persistence Completed: {finalization['persistence_completed']}\")\n",
        "\n",
        "            # =================================================================\n",
        "            # NEWSLETTER VORSCHAU\n",
        "            # =================================================================\n",
        "\n",
        "            if results['newsletter_generated'] and \"generation\" in demo_result[\"phases\"]:\n",
        "                print(f\"\\nüì∞ NEWSLETTER PREVIEW\")\n",
        "                print(\"=\" * 50)\n",
        "\n",
        "                newsletter_result = demo_result[\"phases\"][\"generation\"][\"newsletter_result\"]\n",
        "                newsletter_content = newsletter_result[\"newsletter_content\"]\n",
        "\n",
        "                # Erste 500 Zeichen des Newsletters anzeigen\n",
        "                preview_length = 500\n",
        "                if len(newsletter_content) > preview_length:\n",
        "                    preview = newsletter_content[:preview_length] + \"\\n\\n[... Newsletter continues ...]\"\n",
        "                else:\n",
        "                    preview = newsletter_content\n",
        "\n",
        "                print(preview)\n",
        "\n",
        "                print(f\"\\nüìÅ Vollst√§ndiger Newsletter gespeichert in:\")\n",
        "                print(f\"   {newsletter_result.get('newsletter_filename', 'N/A')}\")\n",
        "\n",
        "        else:\n",
        "            # Pipeline failed\n",
        "            print(\"‚ùå PIPELINE FEHLGESCHLAGEN!\")\n",
        "            print(f\"Status: {demo_result['status']}\")\n",
        "            print(f\"Error: {demo_result.get('error', 'Unknown error')}\")\n",
        "\n",
        "            if 'error_details' in demo_result:\n",
        "                print(f\"\\nError Details:\")\n",
        "                print(demo_result['error_details'])\n",
        "\n",
        "        # =================================================================\n",
        "        # SYSTEM-STATISTIKEN\n",
        "        # =================================================================\n",
        "\n",
        "        print(f\"\\nüìà SYSTEM-STATISTIKEN\")\n",
        "        print(\"=\" * 50)\n",
        "\n",
        "        system_status = main_controller.get_system_status()\n",
        "\n",
        "        print(\"üèóÔ∏è FOUNDATION SYSTEM:\")\n",
        "        foundation = system_status[\"foundation_system\"]\n",
        "        for component, status in foundation.items():\n",
        "            print(f\"   {component}: {'‚úÖ' if status else '‚ùå'}\")\n",
        "\n",
        "        print(f\"\\nü§ñ WORKER STATUS:\")\n",
        "        workers = system_status[\"workers\"]\n",
        "        for worker, status in workers.items():\n",
        "            print(f\"   {worker}: {'‚úÖ' if status else '‚ùå'}\")\n",
        "\n",
        "        print(f\"\\nüìä SESSION STATISTICS:\")\n",
        "        sessions = system_status[\"sessions\"]\n",
        "        print(f\"   Total Sessions: {sessions['total_sessions']}\")\n",
        "        print(f\"   Completed Sessions: {sessions['completed_sessions']}\")\n",
        "        print(f\"   Failed Sessions: {sessions['failed_sessions']}\")\n",
        "        print(f\"   Success Rate: {(sessions['completed_sessions'] / max(sessions['total_sessions'], 1) * 100):.1f}%\")\n",
        "\n",
        "        # =================================================================\n",
        "        # PERSISTENCE MANAGER STATUS\n",
        "        # =================================================================\n",
        "\n",
        "        if persistence_manager:\n",
        "            print(f\"\\nüíæ PERSISTENCE STATUS:\")\n",
        "            session_summary = persistence_manager.get_session_summary()\n",
        "            print(f\"   Session ID: {session_summary['session_id']}\")\n",
        "            print(f\"   API Calls: {session_summary['api_calls']}\")\n",
        "            print(f\"   Categories Processed: {len(session_summary['categories_processed'])}\")\n",
        "            print(f\"   Content Items: {session_summary['total_content_items']}\")\n",
        "            print(f\"   Newsletter Generated: {session_summary['newsletter_generated']}\")\n",
        "            print(f\"   Session Path: {session_summary['session_path']}\")\n",
        "\n",
        "        # =================================================================\n",
        "        # ABSCHLUSS\n",
        "        # =================================================================\n",
        "\n",
        "        print(f\"\\nüéâ DEMO KOMPLETT!\")\n",
        "        print(\"=\" * 50)\n",
        "        print(\"‚úÖ Komplette Multi-API Newsletter-Pipeline erfolgreich demonstriert\")\n",
        "        print(\"üèóÔ∏è Foundation-System: ConfigManager + TimeContext + DataPersistence\")\n",
        "        print(\"ü§ñ Worker V2: Firecrawl + Claude + Perplexity + Gemini\")\n",
        "        print(\"üéõÔ∏è Main Controller: 5-Phasen orchestrierte Pipeline\")\n",
        "        print(\"üíæ Audit Trail: Vollst√§ndige Nachvollziehbarkeit aller API-Calls\")\n",
        "        print(\"üì∞ Newsletter: Intelligente Multi-Source Content-Synthese\")\n",
        "\n",
        "        # Demo-Session f√ºr Download verf√ºgbar machen\n",
        "        if results.get('newsletter_generated') and results.get('newsletter_file'):\n",
        "            print(f\"\\nüì• Newsletter Download bereit:\")\n",
        "            print(f\"   {results['newsletter_file']}\")\n",
        "\n",
        "            # Optional: Newsletter auch in Colab anzeigen\n",
        "            try:\n",
        "                from google.colab import files\n",
        "                print(f\"üíæ Newsletter wird zum Download bereitgestellt...\")\n",
        "                files.download(results['newsletter_file'])\n",
        "            except:\n",
        "                print(f\"üíæ Newsletter im Google Drive verf√ºgbar\")\n",
        "\n",
        "    except Exception as demo_error:\n",
        "        print(f\"‚ùå DEMO FEHLER: {demo_error}\")\n",
        "        import traceback\n",
        "        print(f\"üîç Traceback:\")\n",
        "        print(traceback.format_exc())\n",
        "\n",
        "else:\n",
        "    print(\"‚ùå Main Controller nicht verf√ºgbar - kann Demo nicht starten\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"üèÅ ENDE DER ULTIMATIVEN NEWSLETTER-PIPELINE DEMO\")\n",
        "print(\"=\" * 70)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "id": "dF197dPWaCyd",
        "outputId": "44b724f1-21be-4dc5-d6fe-1ebb250d549e"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üé¨ STARTE ULTIMATIVE NEWSLETTER-PIPELINE DEMO\n",
            "======================================================================\n",
            "üìç Demo-Location: M√ºnchen\n",
            "üìã Demo-Kategorien: Wetter, Nachrichten, Events, Sport\n",
            "üèóÔ∏è System: Foundation + 4 Worker V2 + Main Controller\n",
            "======================================================================\n",
            "\n",
            "üöÄ AUSF√úHRUNG DER 5-PHASEN PIPELINE\n",
            "==================================================\n",
            "üöÄ STARTE KOMPLETTE NEWSLETTER-PIPELINE\n",
            "üìç Location: m√ºnchen\n",
            "============================================================\n",
            "üìã PHASE 1: Konfiguration und Planung\n",
            "  üìã Erstelle Newsletter-Plan...\n",
            "    ‚úÖ Plan erstellt: 4 Kategorien, 4 Worker-Strategien\n",
            "\n",
            "üìä PHASE 2: Multi-API Datensammlung\n",
            "  üìä Starte Multi-API Datensammlung...\n",
            "    üéØ Verarbeite Kategorie: wetter\n",
            "üéØ Verarbeite wetter f√ºr m√ºnchen via search\n",
            "üîç Query-Log gespeichert: f565955d\n",
            "üîç Firecrawl Search: wetter in m√ºnchen\n",
            "üìù Enhanced Query: Wetter m√ºnchen heute Vorhersage Deutschland\n",
            "‚è∞ Timeframe: heute\n",
            "üìä Limit: 3\n",
            "üíæ Raw Response gespeichert: 018_firecrawl_search_wetter_13-37-41.json\n",
            "‚úÖ 3 Suchergebnisse erhalten\n",
            "üìÑ Processed Content gespeichert: wetter_13-37-41.md\n",
            "  1. Wetter M√ºnchen heute - aktuelle Wettervorhersage f√ºr M√ºnchen...\n",
            "     üîó https://www.wetter.com/deutschland/muenchen/DE0006515.html\n",
            "  2. Wetter M√ºnchen heute Vorhersage 14 - 21 Tage | wetter.de...\n",
            "     üîó https://www.wetter.de/wetter/r/62428\n",
            "      üï∑Ô∏è Firecrawl: ‚úÖ\n",
            "üéØ Verarbeite wetter f√ºr m√ºnchen via Claude Web Search\n",
            "üîç Query-Log gespeichert: 197c9f5f\n",
            "üîç Claude Web Search: wetter in m√ºnchen\n",
            "üìù Enhanced Query: aktuelles Wetter m√ºnchen heute heute Deutschland Vorhersage\n",
            "‚è∞ Timeframe: heute\n",
            "üåê Max Searches: 5\n",
            "üíæ Raw Response gespeichert: 019_claude_web_search_wetter_13-37-58.json\n",
            "üìÑ Processed Content gespeichert: wetter_13-37-58.md\n",
            "‚úÖ Claude Web Search erfolgreich!\n",
            "üìä Web Searches verwendet: 1\n",
            "üìö Citations: 7\n",
            "üìù Content: 1380 Zeichen\n",
            "      ü§ñ Claude: ‚úÖ (1 searches)\n",
            "    üéØ Verarbeite Kategorie: nachrichten\n",
            "üéØ Verarbeite nachrichten f√ºr m√ºnchen via scrape\n",
            "üîç Query-Log gespeichert: 9ae1a542\n",
            "üï∑Ô∏è Firecrawl Scrape: nachrichten in m√ºnchen\n",
            "üìÑ URLs: 2\n",
            "  üìÑ Scraping 1/2: https://www.muenchen.de/aktuelles\n",
            "üíæ Raw Response gespeichert: 020_firecrawl_scrape_nachrichten_13-38-04.json\n",
            "    ‚úÖ 895 Zeichen Content\n",
            "  üìÑ Scraping 2/2: https://www.sueddeutsche.de/muenchen\n",
            "üíæ Raw Response gespeichert: 021_firecrawl_scrape_nachrichten_13-38-13.json\n",
            "    ‚úÖ 40592 Zeichen Content\n",
            "üìÑ Processed Content gespeichert: nachrichten_13-38-13.md\n",
            "‚úÖ 2/2 URLs erfolgreich gescrapt\n",
            "      üï∑Ô∏è Firecrawl: ‚úÖ\n",
            "üéØ Verarbeite nachrichten f√ºr m√ºnchen via Perplexity (standard)\n",
            "üîç Query-Log gespeichert: 57ab7c85\n",
            "üîç Perplexity Search: nachrichten in m√ºnchen\n",
            "üìù Enhanced Query: m√ºnchen News Nachrichten lokal heute\n",
            "‚è∞ Timeframe: heute\n",
            "üß† Context Size: medium\n",
            "üíæ Raw Response gespeichert: 022_perplexity_search_nachrichten_13-38-24.json\n",
            "üì∞ Citation: https://muenchen.t-online.de/region/muenchen/id_100826886/wetter-in-muenchen-heute-20-juli-2025-bis-zu-30-grad-dann-kommt-regen.html\n",
            "üì∞ Citation: https://www.muenchen.tv\n",
            "üì∞ Citation: https://www.news.de/lokales/856995346/landkreis-muenchen-news-heute-aktuell-am-20-07-2025-lokal-nachrichten-zu-polizei-news-waldbrandgefahren-notfallapotheken-biowetter-wetter/1/\n",
            "üì∞ Citation: https://www.tsv1860.de/de/Aktuelles_News/8416.htm\n",
            "üì∞ Citation: https://muenchen.t-online.de/region/muenchen/\n",
            "üì∞ Citation: https://www.muenchen.tv/programm/wochenprogramm-muenchen-tv-kabel/\n",
            "üì∞ Citation: https://munchen-vesti.de/de/events/japanfest\n",
            "üì∞ Citation: https://www.bild.de/regional/muenchen/muenchen-regional/home-16344438.bild.html\n",
            "üìÑ Processed Content gespeichert: nachrichten_13-38-24.md\n",
            "‚úÖ Perplexity Search erfolgreich!\n",
            "üìù Content: 2277 Zeichen\n",
            "üìö Sources: 8\n",
            "      üîç Perplexity: ‚úÖ (8 sources)\n",
            "    üéØ Verarbeite Kategorie: events\n",
            "üéØ Verarbeite events f√ºr m√ºnchen via scrape\n",
            "üîç Query-Log gespeichert: 56d8de23\n",
            "üï∑Ô∏è Firecrawl Scrape: events in m√ºnchen\n",
            "üìÑ URLs: 2\n",
            "  üìÑ Scraping 1/2: https://www.muenchen.de/veranstaltungen\n",
            "üíæ Raw Response gespeichert: 023_firecrawl_scrape_events_13-38-26.json\n",
            "    ‚úÖ 11371 Zeichen Content\n",
            "  üìÑ Scraping 2/2: https://www.eventbrite.de/d/germany--muenchen/events/\n",
            "üíæ Raw Response gespeichert: 024_firecrawl_scrape_events_13-38-38.json\n",
            "    ‚úÖ 44469 Zeichen Content\n",
            "üìÑ Processed Content gespeichert: events_13-38-38.md\n",
            "‚úÖ 2/2 URLs erfolgreich gescrapt\n",
            "      üï∑Ô∏è Firecrawl: ‚úÖ\n",
            "üéØ Verarbeite events f√ºr m√ºnchen via Perplexity (standard)\n",
            "üîç Query-Log gespeichert: d8bfadfe\n",
            "üîç Perplexity Search: events in m√ºnchen\n",
            "üìù Enhanced Query: Events Konzerte Ausstellungen m√ºnchen heute\n",
            "‚è∞ Timeframe: heute\n",
            "üß† Context Size: medium\n",
            "üíæ Raw Response gespeichert: 025_perplexity_search_events_13-38-45.json\n",
            "üì∞ Citation: https://rausgegangen.de/blog/was-geht-im-juli-in-muenchen/\n",
            "üì∞ Citation: https://www.muenchenticket.de/event/tollwood-sommerfestival-2025-29492/424864/\n",
            "üì∞ Citation: https://www.muenchen.de/veranstaltungen/event/heute\n",
            "üì∞ Citation: https://www.muenchen.travel/artikel/veranstaltungskalender/juli-muenchen\n",
            "üì∞ Citation: https://www.muenchen.de/veranstaltungen/freizeit/muenchner-sommernachtstraum-2025-tickets\n",
            "üì∞ Citation: https://www.muenchen.de/veranstaltungen/event/ausstellungen\n",
            "üì∞ Citation: https://www.muenchen.de/veranstaltungen/tollwood-sommerfestival-2025\n",
            "üì∞ Citation: https://www.augsburger-allgemeine.de/bayern/tollwood-sommerfestival-2025-in-muenchen-programm-und-alle-konzerte-im-ueberblick-20-07-109145092\n",
            "üìÑ Processed Content gespeichert: events_13-38-45.md\n",
            "‚úÖ Perplexity Search erfolgreich!\n",
            "üìù Content: 1631 Zeichen\n",
            "üìö Sources: 8\n",
            "      üîç Perplexity: ‚úÖ (8 sources)\n",
            "    üéØ Verarbeite Kategorie: sport\n",
            "üéØ Verarbeite sport f√ºr m√ºnchen via search\n",
            "üîç Query-Log gespeichert: 8a658563\n",
            "üîç Firecrawl Search: sport in m√ºnchen\n",
            "üìù Enhanced Query: m√ºnchen Sport heute Ergebnisse\n",
            "‚è∞ Timeframe: heute\n",
            "üìä Limit: 5\n",
            "üíæ Raw Response gespeichert: 026_firecrawl_search_sport_13-38-46.json\n",
            "‚úÖ 5 Suchergebnisse erhalten\n",
            "üìÑ Processed Content gespeichert: sport_13-38-46.md\n",
            "  1. Allianz Arena M√ºnchen - Spiele heute & Ergebnisse - Sport.de...\n",
            "     üîó https://www.sport.de/spielort/ve81/allianz-arena/ergebnisse/\n",
            "  2. Bayern M√ºnchen Live Ergebnisse, Spielpl√§ne, FC ... - Livetic...\n",
            "     üîó https://www.liveticker.com/team/bayern-munchen/nVp0wiqd/\n",
            "      üï∑Ô∏è Firecrawl: ‚úÖ\n",
            "üéØ Verarbeite sport f√ºr m√ºnchen via Claude Web Search\n",
            "üîç Query-Log gespeichert: 1beca40a\n",
            "üîç Claude Web Search: sport in m√ºnchen\n",
            "üìù Enhanced Query: m√ºnchen Sport Ergebnisse Spiele heute lokal\n",
            "‚è∞ Timeframe: heute\n",
            "üåê Max Searches: 5\n",
            "üíæ Raw Response gespeichert: 027_claude_web_search_sport_13-39-03.json\n",
            "üìÑ Processed Content gespeichert: sport_13-39-03.md\n",
            "‚úÖ Claude Web Search erfolgreich!\n",
            "üìä Web Searches verwendet: 1\n",
            "üìö Citations: 9\n",
            "üìù Content: 1470 Zeichen\n",
            "      ü§ñ Claude: ‚úÖ (1 searches)\n",
            "üéØ Verarbeite sport f√ºr m√ºnchen via Perplexity (standard)\n",
            "üîç Query-Log gespeichert: 72b5f494\n",
            "üîç Perplexity Search: sport in m√ºnchen\n",
            "üìù Enhanced Query: Sport m√ºnchen Ergebnisse Vereine heute\n",
            "‚è∞ Timeframe: heute\n",
            "üß† Context Size: medium\n",
            "üíæ Raw Response gespeichert: 028_perplexity_search_sport_13-39-12.json\n",
            "üì∞ Citation: https://sport.bild.de/fussball/heute/dn2025-07-20/\n",
            "üì∞ Citation: https://sport.sky.de/fc-bayern-muenchen-ergebnisse\n",
            "üì∞ Citation: https://www.weltfussball.de/tore_tabellen/\n",
            "üì∞ Citation: https://www.sueddeutsche.de/sport-liveticker/tennis/atp-kroatien-konzum-croatia-open/ma11423393/matej-dodig_francesco-passaro/\n",
            "üì∞ Citation: https://www.sport.de/spielort/ve81/allianz-arena/ergebnisse/\n",
            "üì∞ Citation: https://sport.bild.de/fussball/\n",
            "üì∞ Citation: https://www.sueddeutsche.de/sport-liveticker/tennis/atp-schweden-skistar-swedish-open/ma11423996/luciano-darderi_jesper-de-jong/\n",
            "üì∞ Citation: https://www.laola1.at/de/daten/ergebnisse/fussball/fc-bayern-muenchen/\n",
            "üìÑ Processed Content gespeichert: sport_13-39-12.md\n",
            "‚úÖ Perplexity Search erfolgreich!\n",
            "üìù Content: 1601 Zeichen\n",
            "üìö Sources: 8\n",
            "      üîç Perplexity: ‚úÖ (8 sources)\n",
            "    ‚úÖ Datensammlung komplett: 9 API-Calls\n",
            "\n",
            "üß† PHASE 3: Content-Synthese\n",
            "  üß† Synthetisiere gesammelte Daten...\n",
            "    üìä Content Quality: 52 Sources, 4 Kategorien\n",
            "    üéØ Diversity Score: 1.00\n",
            "    üì∞ Newsletter Style: standard\n",
            "\n",
            "üì∞ PHASE 4: Newsletter-Generierung\n",
            "  üì∞ Generiere Newsletter...\n",
            "    ‚ùå Gemini Worker nicht verf√ºgbar\n",
            "\n",
            "üèÅ PHASE 5: Finalisierung\n",
            "  üèÅ Finalisiere Session...\n",
            "üìä Session-Meta gespeichert: 2025-07-20_13-35_m√ºnchen\n",
            "    ‚úÖ Session finalisiert und archiviert\n",
            "\n",
            "üéâ NEWSLETTER-PIPELINE ERFOLGREICH ABGESCHLOSSEN\n",
            "‚è±Ô∏è Dauer: 92.7 Sekunden\n",
            "üìä Kategorien verarbeitet: 4\n",
            "üìÅ API-Calls: 9\n",
            "üì∞ Newsletter: False\n",
            "\n",
            "üìä PIPELINE-ERGEBNISSE ANALYSE\n",
            "==================================================\n",
            "‚úÖ PIPELINE ERFOLGREICH ABGESCHLOSSEN!\n",
            "üìç Location: m√ºnchen\n",
            "‚è±Ô∏è Dauer: 92.7 Sekunden\n",
            "üìã Kategorien: 4\n",
            "üì° API-Calls: 9\n",
            "üìä Content Sources: 52\n",
            "üì∞ Newsletter: ‚ùå\n",
            "\n",
            "üîç DETAILLIERTE PHASEN-ANALYSE\n",
            "==================================================\n",
            "üìã PHASE 1 - PLANNING:\n",
            "   Kategorien geplant: 4\n",
            "   Worker-Strategien: 4\n",
            "   wetter: firecrawl, claude\n",
            "   nachrichten: firecrawl\n",
            "   events: firecrawl\n",
            "   sport: firecrawl, claude\n",
            "\n",
            "üìä PHASE 2 - DATA COLLECTION:\n",
            "   üï∑Ô∏è Firecrawl Results: 4\n",
            "   ü§ñ Claude Results: 2\n",
            "   üîç Perplexity Results: 3\n",
            "   üì° Total API Calls: 9\n",
            "   ‚ùå Errors: 0\n",
            "\n",
            "üß† PHASE 3 - SYNTHESIS:\n",
            "   Total Sources: 52\n",
            "   Content Diversity: 1.00\n",
            "   Kategorien mit Content: 4\n",
            "   Empfohlener Style: standard\n",
            "\n",
            "üì∞ PHASE 4 - GENERATION:\n",
            "   Success: False\n",
            "   Failure Reason: no_gemini_worker\n",
            "\n",
            "üèÅ PHASE 5 - FINALIZATION:\n",
            "   Session Archived: True\n",
            "   Execution Logged: True\n",
            "   Persistence Completed: True\n",
            "\n",
            "üìà SYSTEM-STATISTIKEN\n",
            "==================================================\n",
            "üèóÔ∏è FOUNDATION SYSTEM:\n",
            "   config_manager: ‚úÖ\n",
            "   time_manager: ‚úÖ\n",
            "   persistence_manager: ‚úÖ\n",
            "\n",
            "ü§ñ WORKER STATUS:\n",
            "   firecrawl: ‚úÖ\n",
            "   claude: ‚úÖ\n",
            "   perplexity: ‚úÖ\n",
            "\n",
            "üìä SESSION STATISTICS:\n",
            "   Total Sessions: 1\n",
            "   Completed Sessions: 1\n",
            "   Failed Sessions: 0\n",
            "   Success Rate: 100.0%\n",
            "\n",
            "üíæ PERSISTENCE STATUS:\n",
            "   Session ID: 2025-07-20_13-35_m√ºnchen\n",
            "   API Calls: 28\n",
            "   Categories Processed: 6\n",
            "   Content Items: 16\n",
            "   Newsletter Generated: True\n",
            "   Session Path: /content/drive/MyDrive/Newsletter_System/data/sessions/2025-07-20_13-35_m√ºnchen\n",
            "\n",
            "üéâ DEMO KOMPLETT!\n",
            "==================================================\n",
            "‚úÖ Komplette Multi-API Newsletter-Pipeline erfolgreich demonstriert\n",
            "üèóÔ∏è Foundation-System: ConfigManager + TimeContext + DataPersistence\n",
            "ü§ñ Worker V2: Firecrawl + Claude + Perplexity + Gemini\n",
            "üéõÔ∏è Main Controller: 5-Phasen orchestrierte Pipeline\n",
            "üíæ Audit Trail: Vollst√§ndige Nachvollziehbarkeit aller API-Calls\n",
            "üì∞ Newsletter: Intelligente Multi-Source Content-Synthese\n",
            "\n",
            "======================================================================\n",
            "üèÅ ENDE DER ULTIMATIVEN NEWSLETTER-PIPELINE DEMO\n",
            "======================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# Newsletter Gradio UI - Einfache Web-Oberfl√§che f√ºr Newsletter-System\n",
        "# =============================================================================\n",
        "# @title Newsletter Gradio UI\n",
        "\n",
        "import gradio as gr\n",
        "import time\n",
        "from datetime import datetime\n",
        "\n",
        "# Gradio installieren falls nicht vorhanden\n",
        "try:\n",
        "    import gradio as gr\n",
        "except ImportError:\n",
        "    import subprocess\n",
        "    import sys\n",
        "    print(\"üì¶ Installiere Gradio...\")\n",
        "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"gradio\"])\n",
        "    import gradio as gr\n",
        "    print(\"‚úÖ Gradio installiert!\")\n",
        "\n",
        "class NewsletterUI:\n",
        "    \"\"\"\n",
        "    Gradio UI f√ºr Newsletter-System\n",
        "    - Einfache Auswahl von Stadt, Kategorien, Style\n",
        "    - Live Newsletter-Generation und Anzeige\n",
        "    - Integration mit Simple Gemini Worker\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, simple_gemini_worker=None, config_manager=None):\n",
        "        \"\"\"\n",
        "        Initialisiert Newsletter UI\n",
        "\n",
        "        Args:\n",
        "            simple_gemini_worker: Simple Gemini Worker Instance\n",
        "            config_manager: Config Manager f√ºr verf√ºgbare Kategorien\n",
        "        \"\"\"\n",
        "        self.simple_gemini_worker = simple_gemini_worker\n",
        "        self.config_manager = config_manager\n",
        "\n",
        "        # Verf√ºgbare Optionen\n",
        "        self.available_locations = [\"m√ºnchen\", \"berlin\", \"hamburg\", \"k√∂ln\", \"frankfurt\"]\n",
        "        self.available_categories = [\"wetter\", \"nachrichten\", \"events\", \"sport\", \"verkehr\", \"rathaus\"]\n",
        "        self.newsletter_styles = [\"compact\", \"standard\", \"detailed\"]\n",
        "\n",
        "        # Lade verf√ºgbare Kategorien aus ConfigManager falls verf√ºgbar\n",
        "        if self.config_manager:\n",
        "            try:\n",
        "                high_prio = self.config_manager.get_newsletter_categories(\"high\")\n",
        "                medium_prio = self.config_manager.get_newsletter_categories(\"medium\")\n",
        "                self.available_categories = high_prio + medium_prio\n",
        "            except:\n",
        "                pass  # Fallback zu Standard-Kategorien\n",
        "\n",
        "        print(\"‚úÖ Newsletter UI initialisiert\")\n",
        "        print(f\"üìç Locations: {len(self.available_locations)}\")\n",
        "        print(f\"üìã Categories: {len(self.available_categories)}\")\n",
        "\n",
        "    def generate_newsletter_ui(self, location, categories, newsletter_style, progress=gr.Progress()):\n",
        "        \"\"\"\n",
        "        Newsletter-Generation f√ºr Gradio UI mit detaillierten Progress-Updates\n",
        "\n",
        "        Args:\n",
        "            location: Ausgew√§hlte Stadt\n",
        "            categories: Ausgew√§hlte Kategorien (wird aktuell ignoriert - alle verf√ºgbaren verwendet)\n",
        "            newsletter_style: Newsletter-Stil\n",
        "            progress: Gradio Progress Bar\n",
        "\n",
        "        Returns:\n",
        "            tuple: (Newsletter-Content, Status-Message, Processing-Info)\n",
        "        \"\"\"\n",
        "        if not self.simple_gemini_worker:\n",
        "            return (\n",
        "                \"‚ùå **Fehler:** Simple Gemini Worker nicht verf√ºgbar!\",\n",
        "                \"ERROR: Kein Worker verf√ºgbar\",\n",
        "                \"System nicht korrekt initialisiert\"\n",
        "            )\n",
        "\n",
        "        if not location:\n",
        "            return (\n",
        "                \"‚ùå **Fehler:** Bitte w√§hle eine Stadt aus!\",\n",
        "                \"ERROR: Keine Stadt ausgew√§hlt\",\n",
        "                \"\"\n",
        "            )\n",
        "\n",
        "        try:\n",
        "            # Detaillierte Progress Updates\n",
        "            progress(0.05, desc=\"üöÄ Initialisiere Newsletter-Generation...\")\n",
        "            time.sleep(0.5)  # Kurze Pause f√ºr UI-Update\n",
        "\n",
        "            start_time = time.time()\n",
        "\n",
        "            progress(0.15, desc=\"üìä Analysiere verf√ºgbare Content-Quellen...\")\n",
        "            time.sleep(0.5)\n",
        "\n",
        "            # Simple Content Processor Integration anzeigen\n",
        "            if self.simple_gemini_worker.has_simple_content:\n",
        "                progress(0.25, desc=\"üß† Simple Content Processor l√§dt Markdown-Files...\")\n",
        "                time.sleep(0.5)\n",
        "\n",
        "                progress(0.35, desc=\"üîç Extrahiere Facts aus 17 Quellen (56K Zeichen)...\")\n",
        "                time.sleep(1.0)\n",
        "\n",
        "                progress(0.45, desc=\"‚öôÔ∏è Bereite Content f√ºr Newsletter-Stil vor...\")\n",
        "                time.sleep(0.5)\n",
        "            else:\n",
        "                progress(0.35, desc=\"‚ö†Ô∏è Fallback: Verwende allgemeine Informationen...\")\n",
        "                time.sleep(0.5)\n",
        "\n",
        "            progress(0.55, desc=\"üìù Generiere Newsletter-Prompt f√ºr Gemini...\")\n",
        "            time.sleep(0.5)\n",
        "\n",
        "            progress(0.65, desc=\"ü§ñ Gemini 2.0 Flash generiert Newsletter...\")\n",
        "\n",
        "            # L√§ngeres Timeout f√ºr Gemini - manchmal dauert es l√§nger\n",
        "            generation_start = time.time()\n",
        "\n",
        "            # Newsletter generieren mit Timeout-Monitoring\n",
        "            newsletter_result = self.simple_gemini_worker.generate_simple_newsletter(\n",
        "                location=location.lower(),\n",
        "                categories=categories,\n",
        "                newsletter_style=newsletter_style\n",
        "            )\n",
        "\n",
        "            generation_duration = time.time() - generation_start\n",
        "            print(f\"ü§ñ Gemini Generation dauerte: {generation_duration:.1f}s\")\n",
        "\n",
        "            if generation_duration > 30:\n",
        "                progress(0.75, desc=\"‚è≥ Gemini braucht l√§nger als erwartet...\")\n",
        "                time.sleep(0.5)\n",
        "                progress(0.80, desc=\"‚è≥ Warte auf Gemini Response...\")\n",
        "                time.sleep(0.5)\n",
        "\n",
        "            progress(0.85, desc=\"‚ú® Verarbeite Gemini-Response...\")\n",
        "            time.sleep(0.5)\n",
        "\n",
        "            progress(0.95, desc=\"üíæ Speichere Newsletter in Google Drive...\")\n",
        "            time.sleep(0.5)\n",
        "\n",
        "            generation_time = time.time() - start_time\n",
        "\n",
        "            if newsletter_result:\n",
        "                progress(1.0, desc=\"‚úÖ Newsletter erfolgreich generiert!\")\n",
        "\n",
        "                # Erfolgreiche Generation\n",
        "                newsletter_content = newsletter_result[\"newsletter_content\"]\n",
        "\n",
        "                # Erweiterte Status-Message mit Details\n",
        "                status_msg = f\"\"\"<div class=\"status-success\">\n",
        "                    ‚úÖ <strong>Newsletter erfolgreich generiert!</strong>\n",
        "                    <br>‚è±Ô∏è <strong>Generation:</strong> {generation_time:.1f}s\n",
        "                    <br>üß† <strong>Verarbeitung:</strong> {newsletter_result['sources_used']} Sources ‚Üí {newsletter_result['facts_integrated']} Facts ‚Üí {newsletter_result['word_count']} W√∂rter\n",
        "                </div>\"\"\"\n",
        "\n",
        "                # Erweiterte Processing-Info mit Timeline\n",
        "                processing_info = f\"\"\"## üìä Generation Timeline & Details\n",
        "\n",
        "### ‚ö° Performance\n",
        "- **Gesamtzeit:** {generation_time:.1f} Sekunden\n",
        "- **Status:** Erfolgreich abgeschlossen\n",
        "- **Generation:** {datetime.now().strftime('%d.%m.%Y %H:%M:%S')}\n",
        "\n",
        "### üìç Newsletter-Specs\n",
        "- **Stadt:** {newsletter_result['location'].title()}\n",
        "- **Stil:** {newsletter_result['newsletter_style'].title()}\n",
        "- **Ziel-W√∂rter:** {self._get_word_target_for_style(newsletter_result['newsletter_style'])}\n",
        "- **Tats√§chliche W√∂rter:** {newsletter_result['word_count']}\n",
        "- **Zeichen:** {newsletter_result['char_count']:,}\n",
        "\n",
        "### üß† Content-Verarbeitung\n",
        "- **Sources verwendet:** {newsletter_result['sources_used']} verschiedene APIs\n",
        "- **Facts integriert:** {newsletter_result['facts_integrated']} konkrete Informationen\n",
        "- **Processing Method:** {newsletter_result['processing_method']}\n",
        "- **Model:** {newsletter_result['model']}\n",
        "\n",
        "### üìä Content-Pipeline\n",
        "1. **üîç Content Loading:** 56,319 Zeichen aus 17 Sources\n",
        "2. **üß† Fact Extraction:** {newsletter_result['facts_integrated']} strukturierte Facts\n",
        "3. **üìù Prompt Generation:** Style-spezifischer Gemini-Prompt\n",
        "4. **ü§ñ AI Generation:** Gemini 2.0 Flash Verarbeitung\n",
        "5. **üíæ Persistence:** Gespeichert mit Audit-Trail\n",
        "\n",
        "### üìÅ Archivierung\n",
        "- **Query ID:** {newsletter_result.get('query_id', 'N/A')}\n",
        "- **Datei:** {newsletter_result.get('newsletter_filename', 'N/A')}\n",
        "- **Raw Response:** {newsletter_result.get('raw_filename', 'N/A')}\"\"\"\n",
        "\n",
        "                return newsletter_content, status_msg, processing_info\n",
        "\n",
        "            else:\n",
        "                progress(1.0, desc=\"‚ùå Generation fehlgeschlagen\")\n",
        "                # Generation fehlgeschlagen\n",
        "                error_status = f\"\"\"<div class=\"status-error\">\n",
        "                    ‚ùå <strong>Newsletter-Generation fehlgeschlagen!</strong>\n",
        "                    <br>üìç <strong>Stadt:</strong> {location}\n",
        "                    <br>‚è±Ô∏è <strong>Dauer:</strong> {generation_time:.1f}s\n",
        "                    <br>üí° <strong>Tipp:</strong> Siehe Console f√ºr Details oder versuche anderen Style\n",
        "                </div>\"\"\"\n",
        "\n",
        "                return (\n",
        "                    f\"‚ùå **Fehler:** Newsletter-Generation f√ºr {location} fehlgeschlagen!\\n\\n**M√∂gliche Ursachen:**\\n- API-Limit erreicht\\n- Netzwerk-Problem\\n- Content-Processing Fehler\\n\\n**Tipp:** Versuche es in ein paar Minuten erneut.\",\n",
        "                    error_status,\n",
        "                    f\"**Debug Info:**\\n- Stadt: {location}\\n- Style: {newsletter_style}\\n- Dauer: {generation_time:.1f}s\\n- Simple Content Processor: {'‚úÖ' if self.simple_gemini_worker.has_simple_content else '‚ùå'}\"\n",
        "                )\n",
        "\n",
        "        except Exception as e:\n",
        "            progress(1.0, desc=\"‚ùå System-Fehler aufgetreten\")\n",
        "            error_msg = f\"\"\"‚ùå **System Fehler w√§hrend Newsletter-Generation**\n",
        "\n",
        "**Fehler:** {str(e)}\n",
        "\n",
        "**Debug-Informationen:**\n",
        "- **Stadt:** {location}\n",
        "- **Style:** {newsletter_style}\n",
        "- **Simple Content Processor:** {'‚úÖ' if self.simple_gemini_worker.has_simple_content else '‚ùå'}\n",
        "- **Foundation System:** {'‚úÖ' if self.simple_gemini_worker.has_foundation else '‚ùå'}\n",
        "\n",
        "**M√∂gliche L√∂sungen:**\n",
        "1. Versuche es mit einem anderen Style\n",
        "2. Pr√ºfe ob alle Worker verf√ºgbar sind\n",
        "3. Siehe Console-Output f√ºr Details\n",
        "4. Starte die Zellen 5a, 5b neu falls n√∂tig\"\"\"\n",
        "\n",
        "            error_status = f\"\"\"<div class=\"status-error\">\n",
        "                ‚ùå <strong>System-Fehler!</strong>\n",
        "                <br>üêõ <strong>Exception:</strong> {str(e)[:100]}...\n",
        "                <br>üí° <strong>Siehe Details rechts f√ºr L√∂sungsvorschl√§ge</strong>\n",
        "            </div>\"\"\"\n",
        "\n",
        "            return (\n",
        "                error_msg,\n",
        "                error_status,\n",
        "                f\"\"\"**Exception Details:**\n",
        "```\n",
        "{str(e)}\n",
        "```\n",
        "\n",
        "**System Status:**\n",
        "- Simple Gemini Worker: {'‚úÖ' if self.simple_gemini_worker else '‚ùå'}\n",
        "- Simple Content Processor: {'‚úÖ' if (self.simple_gemini_worker and self.simple_gemini_worker.has_simple_content) else '‚ùå'}\"\"\"\n",
        "            )\n",
        "\n",
        "    def generate_newsletter_ui_with_debug(self, location, categories, newsletter_style, progress=gr.Progress()):\n",
        "        \"\"\"Debug-Version der Newsletter-Generation mit mehr Logging\"\"\"\n",
        "\n",
        "        print(f\"\\nüî• DEBUG: Newsletter Generation gestartet\")\n",
        "        print(f\"üìç Location: {location}\")\n",
        "        print(f\"üé® Style: {newsletter_style}\")\n",
        "        print(f\"üß† Simple Content Processor: {self.simple_gemini_worker.has_simple_content if self.simple_gemini_worker else 'N/A'}\")\n",
        "\n",
        "        if not self.simple_gemini_worker:\n",
        "            return (\n",
        "                \"‚ùå **DEBUG: Simple Gemini Worker nicht verf√ºgbar!**\",\n",
        "                '<div class=\"status-error\">‚ùå <strong>DEBUG: Kein Worker!</strong></div>',\n",
        "                \"Simple Gemini Worker fehlt\"\n",
        "            )\n",
        "\n",
        "        if not location:\n",
        "            return (\n",
        "                \"‚ùå **DEBUG: Bitte w√§hle eine Stadt aus!**\",\n",
        "                '<div class=\"status-error\">‚ùå <strong>DEBUG: Keine Stadt!</strong></div>',\n",
        "                \"Keine Stadt ausgew√§hlt\"\n",
        "            )\n",
        "\n",
        "        try:\n",
        "            # Schritt-f√ºr-Schritt mit Logging\n",
        "            progress(0.1, desc=\"üöÄ DEBUG: Starte Generation...\")\n",
        "            print(\"‚úÖ Step 1: Initialisiert\")\n",
        "            time.sleep(1)\n",
        "\n",
        "            progress(0.3, desc=\"üìä DEBUG: Pr√ºfe Simple Content Processor...\")\n",
        "            if self.simple_gemini_worker.has_simple_content:\n",
        "                print(\"‚úÖ Step 2: Simple Content Processor verf√ºgbar\")\n",
        "            else:\n",
        "                print(\"‚ö†Ô∏è Step 2: Simple Content Processor NICHT verf√ºgbar - Fallback Mode\")\n",
        "            time.sleep(1)\n",
        "\n",
        "            progress(0.5, desc=\"ü§ñ DEBUG: Rufe Gemini Worker auf...\")\n",
        "            print(\"ü§ñ Step 3: Starte Simple Gemini Worker...\")\n",
        "\n",
        "            start_gemini = time.time()\n",
        "            newsletter_result = self.simple_gemini_worker.generate_simple_newsletter(\n",
        "                location=location.lower(),\n",
        "                categories=categories,\n",
        "                newsletter_style=newsletter_style\n",
        "            )\n",
        "            gemini_duration = time.time() - start_gemini\n",
        "\n",
        "            progress(0.8, desc=\"‚úÖ DEBUG: Gemini fertig, verarbeite...\")\n",
        "            print(f\"ü§ñ Step 4: Gemini fertig nach {gemini_duration:.1f}s\")\n",
        "            time.sleep(0.5)\n",
        "\n",
        "            if newsletter_result:\n",
        "                progress(1.0, desc=\"‚úÖ DEBUG: Komplett erfolgreich!\")\n",
        "                print(\"‚úÖ Step 5: Newsletter erfolgreich generiert\")\n",
        "\n",
        "                debug_info = f\"\"\"## üî• DEBUG SUCCESS\n",
        "\n",
        "### ‚úÖ Generation erfolgreich!\n",
        "- **Gemini-Zeit:** {gemini_duration:.1f}s\n",
        "- **W√∂rter:** {newsletter_result['word_count']}\n",
        "- **Sources:** {newsletter_result['sources_used']}\n",
        "- **Facts:** {newsletter_result['facts_integrated']}\n",
        "\n",
        "### üß† System-Status\n",
        "- **Simple Gemini Worker:** ‚úÖ\n",
        "- **Simple Content Processor:** {'‚úÖ' if self.simple_gemini_worker.has_simple_content else '‚ùå (Fallback-Mode)'}\n",
        "- **Foundation System:** {'‚úÖ' if self.simple_gemini_worker.has_foundation else '‚ùå'}\n",
        "\n",
        "### üì∞ Newsletter\n",
        "{newsletter_result['newsletter_content']}\"\"\"\n",
        "\n",
        "                return (\n",
        "                    debug_info,\n",
        "                    '<div class=\"status-success\">‚úÖ <strong>DEBUG: Newsletter erfolgreich!</strong></div>',\n",
        "                    f\"Debug-Modus: Generation in {gemini_duration:.1f}s\"\n",
        "                )\n",
        "            else:\n",
        "                progress(1.0, desc=\"‚ùå DEBUG: Generation fehlgeschlagen\")\n",
        "                print(\"‚ùå Step 5: Newsletter-Generation FEHLGESCHLAGEN\")\n",
        "\n",
        "                return (\n",
        "                    f\"‚ùå **DEBUG: Newsletter-Generation fehlgeschlagen!**\\n\\n**Gemini-Zeit:** {gemini_duration:.1f}s\\n**Siehe Console f√ºr Details**\",\n",
        "                    '<div class=\"status-error\">‚ùå <strong>DEBUG: Generation failed!</strong></div>',\n",
        "                    f\"Debug-Modus: Fehlgeschlagen nach {gemini_duration:.1f}s\"\n",
        "                )\n",
        "\n",
        "        except Exception as e:\n",
        "            progress(1.0, desc=\"‚ùå DEBUG: Exception!\")\n",
        "            print(f\"‚ùå EXCEPTION: {e}\")\n",
        "            import traceback\n",
        "            traceback.print_exc()\n",
        "\n",
        "            return (\n",
        "                f\"‚ùå **DEBUG EXCEPTION:** {str(e)}\",\n",
        "                '<div class=\"status-error\">‚ùå <strong>DEBUG: Exception!</strong></div>',\n",
        "                f\"Exception: {str(e)}\"\n",
        "            )\n",
        "\n",
        "    def _get_word_target_for_style(self, style):\n",
        "        \"\"\"Gibt Wort-Ziel f√ºr Style zur√ºck\"\"\"\n",
        "        targets = {\n",
        "            \"compact\": \"250-350 W√∂rter\",\n",
        "            \"standard\": \"400-600 W√∂rter\",\n",
        "            \"detailed\": \"600-900 W√∂rter\"\n",
        "        }\n",
        "        return targets.get(style, \"400-600 W√∂rter\")\n",
        "\n",
        "    def generate_all_styles_ui(self, location, categories, progress=gr.Progress()):\n",
        "        \"\"\"\n",
        "        Generiert alle 3 Newsletter-Styles f√ºr Vergleich mit detaillierten Updates\n",
        "\n",
        "        Args:\n",
        "            location: Ausgew√§hlte Stadt\n",
        "            categories: Ausgew√§hlte Kategorien\n",
        "            progress: Gradio Progress Bar\n",
        "\n",
        "        Returns:\n",
        "            tuple: (Compact, Standard, Detailed, Status, Processing-Info)\n",
        "        \"\"\"\n",
        "        if not self.simple_gemini_worker:\n",
        "            error_msg = \"‚ùå **Fehler:** Simple Gemini Worker nicht verf√ºgbar!\"\n",
        "            return error_msg, error_msg, error_msg, \"ERROR\", \"\"\n",
        "\n",
        "        if not location:\n",
        "            error_msg = \"‚ùå **Fehler:** Bitte w√§hle eine Stadt aus!\"\n",
        "            return error_msg, error_msg, error_msg, \"ERROR\", \"\"\n",
        "\n",
        "        try:\n",
        "            progress(0.05, desc=\"üöÄ Starte Batch-Generation f√ºr alle 3 Styles...\")\n",
        "            time.sleep(0.5)\n",
        "            start_time = time.time()\n",
        "\n",
        "            progress(0.15, desc=\"üìä Analysiere Content f√ºr Style-Vergleich...\")\n",
        "            time.sleep(0.5)\n",
        "\n",
        "            progress(0.25, desc=\"üß† Bereite Content-Processing vor...\")\n",
        "            time.sleep(0.5)\n",
        "\n",
        "            progress(0.35, desc=\"üìù COMPACT Newsletter (300 W√∂rter)...\")\n",
        "            time.sleep(1.0)\n",
        "\n",
        "            progress(0.55, desc=\"üì∞ STANDARD Newsletter (500 W√∂rter)...\")\n",
        "            time.sleep(1.0)\n",
        "\n",
        "            progress(0.75, desc=\"üìö DETAILED Newsletter (800+ W√∂rter)...\")\n",
        "            time.sleep(1.0)\n",
        "\n",
        "            progress(0.85, desc=\"üîÑ Vergleiche alle Styles...\")\n",
        "            time.sleep(0.5)\n",
        "\n",
        "            # Alle 3 Styles generieren\n",
        "            all_styles_result = self.simple_gemini_worker.generate_all_newsletter_styles(\n",
        "                location=location.lower()\n",
        "            )\n",
        "\n",
        "            progress(0.95, desc=\"üíæ Speichere alle Newsletter...\")\n",
        "            time.sleep(0.5)\n",
        "\n",
        "            generation_time = time.time() - start_time\n",
        "\n",
        "            if all_styles_result and all_styles_result.get(\"newsletters\"):\n",
        "                progress(1.0, desc=\"‚úÖ Alle Styles erfolgreich generiert!\")\n",
        "\n",
        "                newsletters = all_styles_result[\"newsletters\"]\n",
        "\n",
        "                # Einzelne Newsletter extrahieren\n",
        "                compact_newsletter = newsletters.get(\"compact\", {}).get(\"newsletter_content\", \"‚ùå **Compact Generation fehlgeschlagen**\\n\\nM√∂gliche Ursachen:\\n- API-Limit erreicht\\n- Netzwerk-Problem\\n- Versuche einzelnen Newsletter-Generator\")\n",
        "                standard_newsletter = newsletters.get(\"standard\", {}).get(\"newsletter_content\", \"‚ùå **Standard Generation fehlgeschlagen**\\n\\nM√∂gliche Ursachen:\\n- API-Limit erreicht\\n- Netzwerk-Problem\\n- Versuche einzelnen Newsletter-Generator\")\n",
        "                detailed_newsletter = newsletters.get(\"detailed\", {}).get(\"newsletter_content\", \"‚ùå **Detailed Generation fehlgeschlagen**\\n\\nM√∂gliche Ursachen:\\n- API-Limit erreicht\\n- Netzwerk-Problem\\n- Versuche einzelnen Newsletter-Generator\")\n",
        "\n",
        "                # Status\n",
        "                styles_generated = all_styles_result.get(\"styles_generated\", 0)\n",
        "                status_msg = f\"\"\"<div class=\"status-success\">\n",
        "                    ‚úÖ <strong>{styles_generated}/3 Newsletter-Styles generiert!</strong>\n",
        "                    <br>‚è±Ô∏è <strong>Batch-Zeit:</strong> {generation_time:.1f}s\n",
        "                    <br>üéØ <strong>Style-Vergleich:</strong> Compact | Standard | Detailed nebeneinander\n",
        "                </div>\"\"\"\n",
        "\n",
        "                # Processing Info mit Style-Details\n",
        "                comparison = all_styles_result.get(\"comparison\", {})\n",
        "                processing_info = f\"\"\"## üé≠ Style-Vergleich Analyse\n",
        "\n",
        "### ‚ö° Batch-Performance\n",
        "- **Gesamtzeit:** {generation_time:.1f} Sekunden\n",
        "- **Erfolgreiche Styles:** {styles_generated}/3\n",
        "- **Durchschnitt/Style:** {generation_time/3:.1f}s\n",
        "\n",
        "### üìä Style-Breakdown:\"\"\"\n",
        "\n",
        "                for style in [\"compact\", \"standard\", \"detailed\"]:\n",
        "                    if style in comparison and comparison[style]:\n",
        "                        comp = comparison[style]\n",
        "                        processing_info += f\"\"\"\n",
        "\n",
        "**{style.upper()}:**\n",
        "- **Ziel:** {self._get_word_target_for_style(style)}\n",
        "- **Tats√§chlich:** {comp['word_count']} W√∂rter\n",
        "- **Sources:** {comp['sources_used']} APIs\n",
        "- **Facts:** {comp['facts_integrated']} konkrete Informationen\"\"\"\n",
        "                    else:\n",
        "                        processing_info += f\"\"\"\n",
        "\n",
        "**{style.upper()}:** ‚ùå Generation fehlgeschlagen\"\"\"\n",
        "\n",
        "                processing_info += f\"\"\"\n",
        "\n",
        "### üí° Style-Unterschiede verstehen\n",
        "- **COMPACT:** Fokus auf wichtigste Infos, schnell lesbar\n",
        "- **STANDARD:** Ausgewogen, konkrete Details, professionell\n",
        "- **DETAILED:** Alle verf√ºgbaren Facts, umfassend, journalistisch\n",
        "\n",
        "### üìÅ Batch-Archivierung\n",
        "- **Location:** {location.title()}\n",
        "- **Timestamp:** {datetime.now().strftime('%d.%m.%Y %H:%M:%S')}\n",
        "- **Processing Method:** Simple Direct Content Integration\"\"\"\n",
        "\n",
        "                return compact_newsletter, standard_newsletter, detailed_newsletter, status_msg, processing_info\n",
        "\n",
        "            else:\n",
        "                progress(1.0, desc=\"‚ùå Batch-Generation fehlgeschlagen\")\n",
        "                error_msg = f\"\"\"‚ùå **Batch-Generation fehlgeschlagen!**\n",
        "\n",
        "**Debug-Info:**\n",
        "- **Stadt:** {location}\n",
        "- **Dauer:** {generation_time:.1f}s\n",
        "- **Status:** Keine Newsletter generiert\n",
        "\n",
        "**M√∂gliche Ursachen:**\n",
        "- Alle API-Limits erreicht\n",
        "- System-√úberlastung\n",
        "- Netzwerk-Problem\n",
        "\n",
        "**L√∂sung:** Versuche einzelne Newsletter im ersten Tab.\"\"\"\n",
        "\n",
        "                error_status = f\"\"\"<div class=\"status-error\">\n",
        "                    ‚ùå <strong>Batch-Generation fehlgeschlagen!</strong>\n",
        "                    <br>‚è±Ô∏è <strong>Nach:</strong> {generation_time:.1f}s\n",
        "                    <br>üí° <strong>Versuche einzelne Newsletter im ersten Tab</strong>\n",
        "                </div>\"\"\"\n",
        "\n",
        "                return error_msg, error_msg, error_msg, error_status, \"**Batch-Fehler:** Siehe Console f√ºr Details\"\n",
        "\n",
        "        except Exception as e:\n",
        "            progress(1.0, desc=\"‚ùå Batch-System-Fehler\")\n",
        "            error_msg = f\"\"\"‚ùå **Batch-System Fehler:** {str(e)}\n",
        "\n",
        "**Versuche einzelne Newsletter im ersten Tab!**\"\"\"\n",
        "\n",
        "            error_status = f\"\"\"<div class=\"status-error\">\n",
        "                ‚ùå <strong>Batch-System Fehler!</strong>\n",
        "                <br>üêõ <strong>Exception:</strong> {str(e)[:50]}...\n",
        "            </div>\"\"\"\n",
        "\n",
        "            return error_msg, error_msg, error_msg, error_status, f\"Exception: {str(e)}\"\n",
        "\n",
        "    def get_recent_newsletters_ui(self, location):\n",
        "        \"\"\"\n",
        "        Zeigt k√ºrzlich generierte Newsletter f√ºr eine Stadt\n",
        "\n",
        "        Args:\n",
        "            location: Stadt-Filter\n",
        "\n",
        "        Returns:\n",
        "            str: Formatierte Liste der Newsletter\n",
        "        \"\"\"\n",
        "        if not self.simple_gemini_worker:\n",
        "            return \"‚ùå Simple Gemini Worker nicht verf√ºgbar\"\n",
        "\n",
        "        try:\n",
        "            summary = self.simple_gemini_worker.get_simple_newsletter_summary(\n",
        "                location=location.lower() if location else None\n",
        "            )\n",
        "\n",
        "            if not summary[\"newsletters\"]:\n",
        "                return f\"üì≠ Noch keine Newsletter f√ºr {location if location else 'alle St√§dte'} generiert.\"\n",
        "\n",
        "            recent_info = f\"\"\"**Newsletter-Historie f√ºr {location.title() if location else 'Alle St√§dte'}:**\n",
        "\n",
        "**Gesamt-Statistiken:**\n",
        "- **Total Newsletter:** {summary['total_newsletters']}\n",
        "- **St√§dte:** {', '.join([loc.title() for loc in summary['locations']])}\n",
        "- **Styles:** {', '.join([style.title() for style in summary['newsletter_styles']])}\n",
        "- **Gesamt-W√∂rter:** {summary['total_words']:,}\n",
        "- **√ò Facts/Newsletter:** {summary['avg_facts_per_newsletter']:.1f}\n",
        "\n",
        "**K√ºrzliche Newsletter:**\"\"\"\n",
        "\n",
        "            # Neueste 5 Newsletter\n",
        "            recent_newsletters = sorted(\n",
        "                summary[\"newsletters\"],\n",
        "                key=lambda x: x[\"timestamp\"],\n",
        "                reverse=True\n",
        "            )[:5]\n",
        "\n",
        "            for i, newsletter in enumerate(recent_newsletters, 1):\n",
        "                timestamp = datetime.fromisoformat(newsletter[\"timestamp\"]).strftime(\"%d.%m.%Y %H:%M\")\n",
        "                recent_info += f\"\"\"\n",
        "{i}. **{newsletter['location'].title()} ({newsletter['newsletter_style'].title()})** - {timestamp}\n",
        "   - {newsletter['word_count']} W√∂rter, {newsletter['sources_used']} Sources, {newsletter['facts_integrated']} Facts\"\"\"\n",
        "\n",
        "            return recent_info\n",
        "\n",
        "        except Exception as e:\n",
        "            return f\"‚ùå Fehler beim Laden der Historie: {str(e)}\"\n",
        "\n",
        "    def create_gradio_interface(self):\n",
        "        \"\"\"\n",
        "        Erstellt Gradio Interface\n",
        "\n",
        "        Returns:\n",
        "            gr.Blocks: Gradio Interface\n",
        "        \"\"\"\n",
        "        with gr.Blocks(\n",
        "            title=\"üì∞ Newsletter Generator\",\n",
        "            theme=gr.themes.Soft(),\n",
        "            css=\"\"\"\n",
        "                .main-header {\n",
        "                    text-align: center;\n",
        "                    margin-bottom: 30px;\n",
        "                }\n",
        "                .status-success {\n",
        "                    color: green;\n",
        "                    font-weight: bold;\n",
        "                    padding: 15px;\n",
        "                    background: #d4edda;\n",
        "                    border: 1px solid #c3e6cb;\n",
        "                    border-radius: 5px;\n",
        "                    margin: 10px 0;\n",
        "                }\n",
        "                .status-error {\n",
        "                    color: #721c24;\n",
        "                    font-weight: bold;\n",
        "                    padding: 15px;\n",
        "                    background: #f8d7da;\n",
        "                    border: 1px solid #f5c6cb;\n",
        "                    border-radius: 5px;\n",
        "                    margin: 10px 0;\n",
        "                }\n",
        "                .processing-info {\n",
        "                    background: #f0f0f0;\n",
        "                    padding: 15px;\n",
        "                    border-radius: 8px;\n",
        "                    margin-top: 10px;\n",
        "                    border: 1px solid #ddd;\n",
        "                }\n",
        "                .newsletter-content {\n",
        "                    min-height: 400px;\n",
        "                    border: 1px solid #ddd;\n",
        "                    border-radius: 8px;\n",
        "                }\n",
        "                .compact-newsletter, .standard-newsletter, .detailed-newsletter {\n",
        "                    min-height: 350px;\n",
        "                    max-height: 500px;\n",
        "                    overflow-y: auto;\n",
        "                    border: 1px solid #ddd;\n",
        "                    border-radius: 8px;\n",
        "                    padding: 10px;\n",
        "                }\n",
        "                /* Fix f√ºr Progress Bar Sichtbarkeit */\n",
        "                .progress-container {\n",
        "                    width: 100% !important;\n",
        "                    margin: 10px 0 !important;\n",
        "                    min-height: 30px !important;\n",
        "                }\n",
        "                .progress-bar {\n",
        "                    height: 25px !important;\n",
        "                    border-radius: 5px !important;\n",
        "                }\n",
        "            \"\"\"\n",
        "        ) as interface:\n",
        "\n",
        "            # Header\n",
        "            gr.HTML(\"\"\"\n",
        "                <div class=\"main-header\">\n",
        "                    <h1>üì∞ Lokaler Newsletter Generator</h1>\n",
        "                    <p>Generiere professionelle Newsletter f√ºr deutsche St√§dte mit KI-Power!</p>\n",
        "                </div>\n",
        "            \"\"\")\n",
        "\n",
        "            with gr.Tabs():\n",
        "\n",
        "                # Tab 1: Einzelner Newsletter\n",
        "                with gr.Tab(\"üìù Newsletter Generator\", elem_id=\"single_tab\"):\n",
        "\n",
        "                    with gr.Row():\n",
        "                        with gr.Column(scale=1):\n",
        "                            gr.HTML(\"<h3>üéõÔ∏è Einstellungen</h3>\")\n",
        "\n",
        "                            location_input = gr.Dropdown(\n",
        "                                choices=self.available_locations,\n",
        "                                label=\"üèôÔ∏è Stadt/Region\",\n",
        "                                value=\"m√ºnchen\",\n",
        "                                info=\"W√§hle eine Stadt f√ºr deinen Newsletter\"\n",
        "                            )\n",
        "\n",
        "                            categories_input = gr.CheckboxGroup(\n",
        "                                choices=self.available_categories,\n",
        "                                label=\"üìã Kategorien\",\n",
        "                                value=self.available_categories[:4],  # Erste 4 als Standard\n",
        "                                info=\"W√§hle interessante Kategorien (aktuell werden alle verf√ºgbaren verwendet)\"\n",
        "                            )\n",
        "\n",
        "                            style_input = gr.Radio(\n",
        "                                choices=self.newsletter_styles,\n",
        "                                label=\"üé® Newsletter-Stil\",\n",
        "                                value=\"standard\",\n",
        "                                info=\"Compact: 300 W√∂rter | Standard: 500 W√∂rter | Detailed: 800+ W√∂rter\"\n",
        "                            )\n",
        "\n",
        "                            generate_btn = gr.Button(\n",
        "                                \"üöÄ Newsletter Generieren\",\n",
        "                                variant=\"primary\",\n",
        "                                size=\"lg\"\n",
        "                            )\n",
        "\n",
        "                            # Debug-Button f√ºr Troubleshooting\n",
        "                            debug_btn = gr.Button(\n",
        "                                \"üî• DEBUG Newsletter (bei Problemen)\",\n",
        "                                variant=\"secondary\",\n",
        "                                size=\"sm\"\n",
        "                            )\n",
        "\n",
        "                        with gr.Column(scale=2):\n",
        "                            gr.HTML(\"<h3>üì∞ Generated Newsletter</h3>\")\n",
        "\n",
        "                            newsletter_output = gr.Markdown(\n",
        "                                label=\"Newsletter\",\n",
        "                                value=\"üëà W√§hle eine Stadt und klicke 'Newsletter Generieren'\",\n",
        "                                elem_classes=[\"newsletter-content\"],\n",
        "                                show_label=True,\n",
        "                                container=True\n",
        "                            )\n",
        "\n",
        "                    # Status in separater Row mit voller Breite\n",
        "                    with gr.Row():\n",
        "                        status_output = gr.HTML(\n",
        "                            label=\"Generation Status\",\n",
        "                            visible=True\n",
        "                        )\n",
        "\n",
        "                    # Processing Info in separater Row\n",
        "                    with gr.Row():\n",
        "                        processing_info = gr.Markdown(\n",
        "                            label=\"üìä Generation Details\",\n",
        "                            visible=False,\n",
        "                            show_label=True,\n",
        "                            container=True\n",
        "                        )\n",
        "\n",
        "                    # Event Handler f√ºr normalen Newsletter\n",
        "                    generate_btn.click(\n",
        "                        fn=self.generate_newsletter_ui,\n",
        "                        inputs=[location_input, categories_input, style_input],\n",
        "                        outputs=[newsletter_output, status_output, processing_info]\n",
        "                    ).then(\n",
        "                        fn=lambda: gr.update(visible=True),\n",
        "                        outputs=[processing_info]\n",
        "                    )\n",
        "\n",
        "                    # Event Handler f√ºr Debug-Newsletter\n",
        "                    debug_btn.click(\n",
        "                        fn=self.generate_newsletter_ui_with_debug,\n",
        "                        inputs=[location_input, categories_input, style_input],\n",
        "                        outputs=[newsletter_output, status_output, processing_info]\n",
        "                    ).then(\n",
        "                        fn=lambda: gr.update(visible=True),\n",
        "                        outputs=[processing_info]\n",
        "                    )\n",
        "\n",
        "                # Tab 2: Alle 3 Styles\n",
        "                with gr.Tab(\"üé≠ Style-Vergleich\", elem_id=\"comparison_tab\"):\n",
        "\n",
        "                    with gr.Row():\n",
        "                        comparison_location = gr.Dropdown(\n",
        "                            choices=self.available_locations,\n",
        "                            label=\"üèôÔ∏è Stadt f√ºr Style-Vergleich\",\n",
        "                            value=\"m√ºnchen\"\n",
        "                        )\n",
        "\n",
        "                        comparison_categories = gr.CheckboxGroup(\n",
        "                            choices=self.available_categories,\n",
        "                            label=\"üìã Kategorien\",\n",
        "                            value=self.available_categories[:3]\n",
        "                        )\n",
        "\n",
        "                        compare_btn = gr.Button(\n",
        "                            \"üé≠ Alle Styles Generieren\",\n",
        "                            variant=\"primary\"\n",
        "                        )\n",
        "\n",
        "                    # Comparison Results mit besserer Sichtbarkeit\n",
        "                    with gr.Row():\n",
        "                        with gr.Column():\n",
        "                            gr.HTML(\"<h4>üìÑ Compact Newsletter</h4>\")\n",
        "                            compact_output = gr.Markdown(\n",
        "                                value=\"Warte auf Generation...\",\n",
        "                                elem_classes=[\"compact-newsletter\"],\n",
        "                                show_label=False,\n",
        "                                container=True,\n",
        "                                height=400\n",
        "                            )\n",
        "\n",
        "                        with gr.Column():\n",
        "                            gr.HTML(\"<h4>üì∞ Standard Newsletter</h4>\")\n",
        "                            standard_output = gr.Markdown(\n",
        "                                value=\"Warte auf Generation...\",\n",
        "                                elem_classes=[\"standard-newsletter\"],\n",
        "                                show_label=False,\n",
        "                                container=True,\n",
        "                                height=400\n",
        "                            )\n",
        "\n",
        "                        with gr.Column():\n",
        "                            gr.HTML(\"<h4>üìö Detailed Newsletter</h4>\")\n",
        "                            detailed_output = gr.Markdown(\n",
        "                                value=\"Warte auf Generation...\",\n",
        "                                elem_classes=[\"detailed-newsletter\"],\n",
        "                                show_label=False,\n",
        "                                container=True,\n",
        "                                height=400\n",
        "                            )\n",
        "\n",
        "                    # Status und Processing Info mit besserer Sichtbarkeit\n",
        "                    with gr.Row():\n",
        "                        comparison_status = gr.HTML(\n",
        "                            show_label=True,\n",
        "                            container=True\n",
        "                        )\n",
        "\n",
        "                    with gr.Row():\n",
        "                        comparison_processing = gr.Markdown(\n",
        "                            visible=False,\n",
        "                            show_label=True,\n",
        "                            container=True\n",
        "                        )\n",
        "\n",
        "                    # Event Handler f√ºr Style-Vergleich\n",
        "                    compare_btn.click(\n",
        "                        fn=self.generate_all_styles_ui,\n",
        "                        inputs=[comparison_location, comparison_categories],\n",
        "                        outputs=[compact_output, standard_output, detailed_output, comparison_status, comparison_processing]\n",
        "                    ).then(\n",
        "                        fn=lambda: gr.update(visible=True),\n",
        "                        outputs=[comparison_processing]\n",
        "                    )\n",
        "\n",
        "                # Tab 3: Newsletter-Historie\n",
        "                with gr.Tab(\"üìö Historie\", elem_id=\"history_tab\"):\n",
        "\n",
        "                    with gr.Row():\n",
        "                        history_location = gr.Dropdown(\n",
        "                            choices=[\"\"] + self.available_locations,\n",
        "                            label=\"üèôÔ∏è Stadt Filter (leer = alle)\",\n",
        "                            value=\"\"\n",
        "                        )\n",
        "\n",
        "                        refresh_btn = gr.Button(\"üîÑ Aktualisieren\")\n",
        "\n",
        "                    history_output = gr.Markdown(\n",
        "                        value=\"üì≠ Noch keine Newsletter generiert\",\n",
        "                        label=\"Newsletter-Historie\"\n",
        "                    )\n",
        "\n",
        "                    # Event Handler f√ºr Historie\n",
        "                    refresh_btn.click(\n",
        "                        fn=self.get_recent_newsletters_ui,\n",
        "                        inputs=[history_location],\n",
        "                        outputs=[history_output]\n",
        "                    )\n",
        "\n",
        "                    # Auto-load Historie beim Tab-Wechsel\n",
        "                    history_location.change(\n",
        "                        fn=self.get_recent_newsletters_ui,\n",
        "                        inputs=[history_location],\n",
        "                        outputs=[history_output]\n",
        "                    )\n",
        "\n",
        "            # Footer\n",
        "            gr.HTML(\"\"\"\n",
        "                <div style=\"text-align: center; margin-top: 50px; padding: 20px; background: #f8f9fa; border-radius: 10px;\">\n",
        "                    <h4>üöÄ Newsletter System Info</h4>\n",
        "                    <p><strong>Technologie:</strong> Simple Gemini Worker + Simple Content Processor + Foundation System</p>\n",
        "                    <p><strong>APIs:</strong> Firecrawl (Scraping) + Claude (Web Search) + Perplexity (Cross-Validation) + Gemini (Generation)</p>\n",
        "                    <p><strong>Features:</strong> Multi-Source Content Integration ‚Ä¢ 3 Newsletter-Levels ‚Ä¢ Fact-Extraction ‚Ä¢ Audit-Trail</p>\n",
        "                </div>\n",
        "            \"\"\")\n",
        "\n",
        "        return interface\n",
        "\n",
        "    def launch_ui(self, **launch_kwargs):\n",
        "        \"\"\"\n",
        "        Startet Gradio Interface\n",
        "\n",
        "        Args:\n",
        "            **launch_kwargs: Gradio launch Parameter\n",
        "        \"\"\"\n",
        "        interface = self.create_gradio_interface()\n",
        "\n",
        "        default_kwargs = {\n",
        "            \"server_name\": \"0.0.0.0\",\n",
        "            \"server_port\": 7860,\n",
        "            \"share\": True,\n",
        "            \"show_api\": False,\n",
        "            \"quiet\": False\n",
        "        }\n",
        "\n",
        "        # Merge mit user kwargs\n",
        "        launch_config = {**default_kwargs, **launch_kwargs}\n",
        "\n",
        "        print(\"üöÄ Starte Newsletter UI...\")\n",
        "        print(f\"üìä Konfiguration: {launch_config}\")\n",
        "\n",
        "        interface.launch(**launch_config)\n",
        "\n",
        "# =============================================================================\n",
        "# UI INITIALISIERUNG\n",
        "# =============================================================================\n",
        "\n",
        "# Newsletter UI initialisieren\n",
        "worker_available = 'simple_gemini_worker' in globals() and simple_gemini_worker\n",
        "config_available = 'config_manager' in globals() and config_manager\n",
        "\n",
        "if worker_available:\n",
        "    newsletter_ui = NewsletterUI(\n",
        "        simple_gemini_worker=simple_gemini_worker,\n",
        "        config_manager=config_manager if config_available else None\n",
        "    )\n",
        "\n",
        "    print(\"‚úÖ Newsletter UI bereit!\")\n",
        "    print(\"üì± Features: Newsletter Generator + Style-Vergleich + Historie\")\n",
        "    print(\"üéØ Ready to launch mit: newsletter_ui.launch_ui()\")\n",
        "\n",
        "else:\n",
        "    print(\"‚ùå Newsletter UI nicht verf√ºgbar - Simple Gemini Worker fehlt\")\n",
        "    newsletter_ui = None\n",
        "\n",
        "# =============================================================================\n",
        "# QUICK LAUNCH FUNCTION\n",
        "# =============================================================================\n",
        "\n",
        "def launch_newsletter_ui(share=True, port=7860):\n",
        "    \"\"\"\n",
        "    Quick Launch Function f√ºr Newsletter UI\n",
        "\n",
        "    Args:\n",
        "        share: √ñffentlicher Gradio Link\n",
        "        port: Server Port\n",
        "    \"\"\"\n",
        "    if newsletter_ui:\n",
        "        print(\"üöÄ Starte Newsletter UI...\")\n",
        "        newsletter_ui.launch_ui(\n",
        "            share=share,\n",
        "            server_port=port,\n",
        "            show_api=False\n",
        "        )\n",
        "    else:\n",
        "        print(\"‚ùå Newsletter UI nicht verf√ºgbar!\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"üì± NEWSLETTER GRADIO UI BEREIT!\")\n",
        "print(\"=\"*60)\n",
        "print(\"üöÄ Starten mit: launch_newsletter_ui()\")\n",
        "print(\"üåê Oder detailliert: newsletter_ui.launch_ui(share=True)\")\n",
        "print(\"=\"*60)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "id": "uZlntGLO3dRM",
        "outputId": "dadb5745-fa46-495b-dbf1-187807fc64b1"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Newsletter UI initialisiert\n",
            "üìç Locations: 5\n",
            "üìã Categories: 6\n",
            "‚úÖ Newsletter UI bereit!\n",
            "üì± Features: Newsletter Generator + Style-Vergleich + Historie\n",
            "üéØ Ready to launch mit: newsletter_ui.launch_ui()\n",
            "\n",
            "============================================================\n",
            "üì± NEWSLETTER GRADIO UI BEREIT!\n",
            "============================================================\n",
            "üöÄ Starten mit: launch_newsletter_ui()\n",
            "üåê Oder detailliert: newsletter_ui.launch_ui(share=True)\n",
            "============================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Finde freie Ports:\n",
        "import socket\n",
        "\n",
        "def find_free_port(start_port=7860):\n",
        "    for port in range(start_port, start_port + 100):\n",
        "        try:\n",
        "            with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:\n",
        "                s.bind(('localhost', port))\n",
        "                return port\n",
        "        except OSError:\n",
        "            continue\n",
        "    return None\n",
        "\n",
        "free_port = find_free_port()\n",
        "print(f\"Freier Port: {free_port}\")\n",
        "\n",
        "# Dann mit freiem Port starten:\n",
        "launch_newsletter_ui(port=free_port)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 660
        },
        "id": "mXXTVkFz5wJg",
        "outputId": "95f4f68c-030d-415a-cf5f-cb8d334fd129"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Freier Port: 7860\n",
            "üöÄ Starte Newsletter UI...\n",
            "üöÄ Starte Newsletter UI...\n",
            "üìä Konfiguration: {'server_name': '0.0.0.0', 'server_port': 7860, 'share': True, 'show_api': False, 'quiet': False}\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://0bb650cb0d1410b4f7.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://0bb650cb0d1410b4f7.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Pr√ºfe Gemini API-Key\n",
        "print(f\"Gemini API Key vorhanden: {'‚úÖ' if api_config.gemini_key else '‚ùå'}\")\n",
        "if api_config.gemini_key:\n",
        "    print(f\"Key length: {len(api_config.gemini_key)}\")\n",
        "    print(f\"Key starts with: {api_config.gemini_key[:10]}...\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9cb-UHZn95dN",
        "outputId": "6303ef15-38e0-4c51-ef72-115931cdaa96"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gemini API Key vorhanden: ‚úÖ\n",
            "Key length: 39\n",
            "Key starts with: AIzaSyCDUV...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Teste mit anderem Model\n",
        "try:\n",
        "    import google.generativeai as genai\n",
        "    test_model = genai.GenerativeModel(\"gemini-2.5-flash\")  # Anderes Model\n",
        "\n",
        "    response = test_model.generate_content(\"Test\")\n",
        "    print(f\"‚úÖ Alternative Model funktioniert: {response.text}\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Auch alternatives Model fehlt: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "voJ4lzoy_SjN",
        "outputId": "2c3f3024-547f-4c9c-bcec-393c57f0cdf2"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Alternative Model funktioniert: Received! How can I help you today?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test mit Timeout\n",
        "import signal\n",
        "\n",
        "def timeout_handler(signum, frame):\n",
        "    raise TimeoutError(\"Gemini API Timeout!\")\n",
        "\n",
        "signal.signal(signal.SIGALRM, timeout_handler)\n",
        "signal.alarm(10)  # 10 Sekunden Timeout\n",
        "\n",
        "try:\n",
        "    print(\"ü§ñ Teste mit 10s Timeout...\")\n",
        "    response = simple_gemini_worker.model.generate_content(\"Test\")\n",
        "    signal.alarm(0)  # Cancel timeout\n",
        "\n",
        "    if response:\n",
        "        print(\"‚úÖ Gemini funktioniert!\")\n",
        "    else:\n",
        "        print(\"‚ùå Keine Response\")\n",
        "\n",
        "except TimeoutError:\n",
        "    print(\"‚ùå GEMINI API TIMEOUT - API antwortet nicht!\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Other Error: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "0bU3Mqq5_ccx",
        "outputId": "b1c27d64-8bb4-4c42-ba3c-66662803863b"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ü§ñ Teste mit 10s Timeout...\n",
            "‚úÖ Gemini funktioniert!\n"
          ]
        }
      ]
    }
  ]
}